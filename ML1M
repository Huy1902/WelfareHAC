{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322628c0",
   "metadata": {
    "id": "36GFFPEquVlH",
    "papermill": {
     "duration": 0.007841,
     "end_time": "2025-07-22T06:37:12.965495",
     "exception": false,
     "start_time": "2025-07-22T06:37:12.957654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7219c335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:12.979541Z",
     "iopub.status.busy": "2025-07-22T06:37:12.979309Z",
     "iopub.status.idle": "2025-07-22T06:37:16.491375Z",
     "shell.execute_reply": "2025-07-22T06:37:16.490273Z"
    },
    "papermill": {
     "duration": 3.52107,
     "end_time": "2025-07-22T06:37:16.493388",
     "exception": false,
     "start_time": "2025-07-22T06:37:12.972318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n"
     ]
    }
   ],
   "source": [
    "!wandb login --relogin c2aabf528c3a17ca15b2306fdef1f0f0d24798bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61232de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:16.508308Z",
     "iopub.status.busy": "2025-07-22T06:37:16.507916Z",
     "iopub.status.idle": "2025-07-22T06:37:28.023639Z",
     "shell.execute_reply": "2025-07-22T06:37:28.022730Z"
    },
    "id": "lJ3KHm7bdEpB",
    "outputId": "e85fb76f-ac93-4310-ed56-b532d2b2cbc9",
    "papermill": {
     "duration": 11.524261,
     "end_time": "2025-07-22T06:37:28.024939",
     "exception": false,
     "start_time": "2025-07-22T06:37:16.500678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/hac/pytorch/default/1/model_actor\n",
      "/kaggle/input/hac/pytorch/default/1/model_actor_optimizer\n",
      "/kaggle/input/hac/pytorch/default/1/model_critic_optimizer\n",
      "/kaggle/input/hac/pytorch/default/1/model_critic\n",
      "/kaggle/input/ml1m-dataset/user_info.npy\n",
      "/kaggle/input/ml1m-dataset/item_info.npy\n",
      "/kaggle/input/ml1m-dataset/all.csv\n",
      "/kaggle/input/ml1m-dataset/train.csv\n",
      "/kaggle/input/ml1m-dataset/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "from time import time\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0949d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:28.045254Z",
     "iopub.status.busy": "2025-07-22T06:37:28.044852Z",
     "iopub.status.idle": "2025-07-22T06:37:28.303615Z",
     "shell.execute_reply": "2025-07-22T06:37:28.302496Z"
    },
    "papermill": {
     "duration": 0.268886,
     "end_time": "2025-07-22T06:37:28.305010",
     "exception": false,
     "start_time": "2025-07-22T06:37:28.036124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p /kaggle/working/ml1m/agent\n",
    "!mkdir -p /kaggle/working/ml1m/env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b542ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:28.319423Z",
     "iopub.status.busy": "2025-07-22T06:37:28.319150Z",
     "iopub.status.idle": "2025-07-22T06:37:28.442294Z",
     "shell.execute_reply": "2025-07-22T06:37:28.441688Z"
    },
    "id": "batCUlrPrPpR",
    "papermill": {
     "duration": 0.131458,
     "end_time": "2025-07-22T06:37:28.443375",
     "exception": false,
     "start_time": "2025-07-22T06:37:28.311917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Hyperparameter\n",
    "\n",
    "path_to_data = \"/kaggle/input/ml1m-dataset\"\n",
    "path_to_output = \"/kaggle/working/ml1m/\"\n",
    "\n",
    "\n",
    "cuda = 0\n",
    "if cuda >= 0 and torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(cuda)\n",
    "    torch.cuda.set_device(cuda)\n",
    "    device = f\"cuda:{cuda}\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d45ea0a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:28.457606Z",
     "iopub.status.busy": "2025-07-22T06:37:28.457378Z",
     "iopub.status.idle": "2025-07-22T06:37:30.428947Z",
     "shell.execute_reply": "2025-07-22T06:37:30.428299Z"
    },
    "papermill": {
     "duration": 1.979968,
     "end_time": "2025-07-22T06:37:30.430385",
     "exception": false,
     "start_time": "2025-07-22T06:37:28.450417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>slate_of_items</th>\n",
       "      <th>user_mid</th>\n",
       "      <th>user_mid_history</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 2340, 1836, 3408, 280...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[720, 260, 919, 608, 2692, 1961, 2028, 3105, 9...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1962, 2018, 150, 1028, 1097, 914, 1287, 2797,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[661, 2918, 531, 3114, 2791, 2321, 1029, 1197,...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 1, 0, 1, 1]</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[1545, 527, 595, 2687, 745, 588, 1, 2355, 2294...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                     slate_of_items  \\\n",
       "0        1  [3186, 1270, 1721, 1022, 2340, 1836, 3408, 280...   \n",
       "1        1  [720, 260, 919, 608, 2692, 1961, 2028, 3105, 9...   \n",
       "2        1  [1962, 2018, 150, 1028, 1097, 914, 1287, 2797,...   \n",
       "3        1  [661, 2918, 531, 3114, 2791, 2321, 1029, 1197,...   \n",
       "4        1  [1545, 527, 595, 2687, 745, 588, 1, 2355, 2294...   \n",
       "\n",
       "                         user_mid  \\\n",
       "0  [1, 1, 1, 1, 0, 1, 1, 1, 1, 1]   \n",
       "1  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "2  [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "3  [0, 1, 1, 1, 1, 0, 1, 0, 1, 1]   \n",
       "4  [1, 1, 1, 0, 0, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                    user_mid_history  sequence_id  \n",
       "0                                                 []            0  \n",
       "1  [3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...            1  \n",
       "2  [3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...            2  \n",
       "3  [3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...            3  \n",
       "4  [3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>slate_of_items</th>\n",
       "      <th>user_mid</th>\n",
       "      <th>user_mid_history</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4794</td>\n",
       "      <td>[2087, 1073, 951, 1230, 1256, 3362, 1276, 1304...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1923, 3763, 3702, 3693, 2804, 1196, 541, 1197...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1299, 1394, 3342, 1231, 3683, 1199, 1270, 316...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1259, 3072, 3505, 1291, 1674, 2348, 3753, 969...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1200, 1201, 1240, 457, 589, 377, 2951, 2985, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                     slate_of_items  \\\n",
       "0     4794  [2087, 1073, 951, 1230, 1256, 3362, 1276, 1304...   \n",
       "1     4794  [1923, 3763, 3702, 3693, 2804, 1196, 541, 1197...   \n",
       "2     4794  [1299, 1394, 3342, 1231, 3683, 1199, 1270, 316...   \n",
       "3     4794  [1259, 3072, 3505, 1291, 1674, 2348, 3753, 969...   \n",
       "4     4794  [1200, 1201, 1240, 457, 589, 377, 2951, 2985, ...   \n",
       "\n",
       "                         user_mid  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]   \n",
       "1  [1, 1, 1, 0, 1, 1, 1, 1, 1, 1]   \n",
       "2  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1]   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
       "\n",
       "                                    user_mid_history  sequence_id  \n",
       "0  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            4  \n",
       "1  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            5  \n",
       "2  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            6  \n",
       "3  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            7  \n",
       "4  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3953, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6041, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Load data\n",
    "\n",
    "# @title Load data for ml1m\n",
    "item_info = np.load(os.path.join(path_to_data, \"item_info.npy\"))\n",
    "user_info = np.load(os.path.join(path_to_data, \"user_info.npy\"))\n",
    "train = pd.read_csv(os.path.join(path_to_data, \"train.csv\"), sep=\"@\")\n",
    "test = pd.read_csv(os.path.join(path_to_data, \"test.csv\"), sep=\"@\")\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(item_info.shape)\n",
    "display(user_info.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d671a652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.446473Z",
     "iopub.status.busy": "2025-07-22T06:37:30.446257Z",
     "iopub.status.idle": "2025-07-22T06:37:30.477031Z",
     "shell.execute_reply": "2025-07-22T06:37:30.476455Z"
    },
    "papermill": {
     "duration": 0.039733,
     "end_time": "2025-07-22T06:37:30.478149",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.438416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>77906.000000</td>\n",
       "      <td>77906.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2425.262830</td>\n",
       "      <td>19.629194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1377.860511</td>\n",
       "      <td>22.665141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1230.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2383.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3651.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4794.000000</td>\n",
       "      <td>230.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id   sequence_id\n",
       "count  77906.000000  77906.000000\n",
       "mean    2425.262830     19.629194\n",
       "std     1377.860511     22.665141\n",
       "min        1.000000      0.000000\n",
       "25%     1230.000000      4.000000\n",
       "50%     2383.000000     12.000000\n",
       "75%     3651.000000     27.000000\n",
       "max     4794.000000    230.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19477.000000</td>\n",
       "      <td>19477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5426.233917</td>\n",
       "      <td>16.850542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>358.788743</td>\n",
       "      <td>18.521978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4794.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5105.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5443.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5741.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6040.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id   sequence_id\n",
       "count  19477.000000  19477.000000\n",
       "mean    5426.233917     16.850542\n",
       "std      358.788743     18.521978\n",
       "min     4794.000000      0.000000\n",
       "25%     5105.000000      4.000000\n",
       "50%     5443.000000     11.000000\n",
       "75%     5741.000000     23.000000\n",
       "max     6040.000000    126.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.describe())\n",
    "display(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8482fd3a",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.493886Z",
     "iopub.status.busy": "2025-07-22T06:37:30.493661Z",
     "iopub.status.idle": "2025-07-22T06:37:30.502713Z",
     "shell.execute_reply": "2025-07-22T06:37:30.502238Z"
    },
    "id": "6uAs4kp4whrk",
    "papermill": {
     "duration": 0.018086,
     "end_time": "2025-07-22T06:37:30.503672",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.485586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Support function\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def padding_and_clip(sequence, max_len, padding_direction = 'left'):\n",
    "    if len(sequence) < max_len:\n",
    "        sequence = [0] * (max_len - len(sequence)) + sequence if padding_direction == 'left' else sequence + [0] * (max_len - len(sequence))\n",
    "    sequence = sequence[-max_len:] if padding_direction == 'left' else sequence[:max_len]\n",
    "    # print(f\"sequence{sequence}\")\n",
    "    return sequence\n",
    "\n",
    "def get_regularization(*modules):\n",
    "  \"\"\"\n",
    "  Customized L2 regularization\n",
    "  \"\"\"\n",
    "  reg = 0\n",
    "  for m in modules:\n",
    "    for p in m.parameters():\n",
    "      reg = torch.mean(p * p) + reg\n",
    "  return reg\n",
    "\n",
    "def wrap_batch(batch, device):\n",
    "  \"\"\"\n",
    "  Build feed_dict from batch data and move data to device\n",
    "  \"\"\"\n",
    "  for k,val in batch.items():\n",
    "    if type(val).__module__ == np.__name__:\n",
    "        batch[k] = torch.from_numpy(val)\n",
    "    elif torch.is_tensor(val):\n",
    "        batch[k] = val\n",
    "    elif type(val) is list:\n",
    "        batch[k] = torch.tensor(val)\n",
    "    else:\n",
    "        continue\n",
    "    if batch[k].type() == \"torch.DoubleTensor\":\n",
    "        batch[k] = batch[k].float()\n",
    "    batch[k] = batch[k].to(device)\n",
    "  return batch\n",
    "\n",
    "def sample_categorical_action(action_prob, candidate_ids, slate_size,\n",
    "                              with_replacement=True, batch_wise=False,\n",
    "                              return_idx=False):\n",
    "  '''\n",
    "  @input:\n",
    "  - action_prob: (B, L)\n",
    "  - candidate_ids: (B, L) or (1, L)\n",
    "  - slate_size: K\n",
    "  - with_replacement: sample with replacement\n",
    "  - batch_wise: do batch wise candidate selection\n",
    "  '''\n",
    "  if with_replacement:\n",
    "    # (K, B)\n",
    "    indices = Categorical(action_prob).sample(sample_shape = (slate_size,))\n",
    "    # (B, K)\n",
    "    indices = torch.transpose(indices, 0, 1)\n",
    "  else:\n",
    "    indices = torch.cat([torch.multinomial(prob, slate_size, replacement=False).view(1, -1) \\\n",
    "                         for prob in action_prob], dim = 0)\n",
    "  action = torch.gather(candidate_ids, 1, indices) if batch_wise else candidate_ids[indices]\n",
    "  if return_idx:\n",
    "    return action.detach(), indices.detach()\n",
    "  else:\n",
    "    return action.detach()\n",
    "\n",
    "\n",
    "##################\n",
    "#   Learning     #\n",
    "##################\n",
    "\n",
    "class LinearScheduler(object):\n",
    "  def __init__(self, schedule_timesteps, final_p, initial_p=1.0):\n",
    "    self.schedule_timesteps = schedule_timesteps\n",
    "    self.final_p = final_p\n",
    "    self.initial_p = initial_p\n",
    "\n",
    "  def value(self, t):\n",
    "    '''\n",
    "    see Schedule.value\n",
    "    '''\n",
    "    fraction = min(float(t) / self.schedule_timesteps, 1.0)\n",
    "    return self.initial_p + fraction * (self.final_p - self.initial_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c42156",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.520114Z",
     "iopub.status.busy": "2025-07-22T06:37:30.519857Z",
     "iopub.status.idle": "2025-07-22T06:37:30.529856Z",
     "shell.execute_reply": "2025-07-22T06:37:30.529352Z"
    },
    "id": "I_-339N7XCzA",
    "papermill": {
     "duration": 0.019979,
     "end_time": "2025-07-22T06:37:30.530908",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.510929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Plot Function\n",
    "\n",
    "def smooth(values, window = 3):\n",
    "  left = window // 2\n",
    "  new_values = [np.mean(values[max(0,idx-left):min(idx-left+window,len(values))]) for idx in range(len(values))]\n",
    "  return new_values\n",
    "\n",
    "\n",
    "def get_rl_training_info(log_path, training_losses = ['actor_loss', 'critic_loss']):\n",
    "  episode = []\n",
    "  average_total_reward, reward_variance, max_total_reward, min_total_reward, average_n_step, max_n_step, min_n_step \\\n",
    "          = [], [], [], [], [], [], []\n",
    "  training_loss_records = {k: [] for k in training_losses}\n",
    "  with open(log_path, 'r') as infile:\n",
    "    for line in tqdm(infile):\n",
    "      split = line.split('@')\n",
    "      # episode\n",
    "      episode.append(eval(split[0].split(':')[1]))\n",
    "      # episode report\n",
    "      episode_report = eval(split[1].strip()[len(\"episode report:\"):])\n",
    "      average_total_reward.append(episode_report['average_total_reward'])\n",
    "      reward_variance.append(episode_report['reward_variance'])\n",
    "      max_total_reward.append(episode_report['max_total_reward'])\n",
    "      min_total_reward.append(episode_report['min_total_reward'])\n",
    "      average_n_step.append(episode_report['average_n_step'])\n",
    "      max_n_step.append(episode_report['max_n_step'])\n",
    "      min_n_step.append(episode_report['min_n_step'])\n",
    "      # loss report\n",
    "      if training_losses:\n",
    "          loss_report = eval(split[2].strip()[len(\"step loss:\"):])\n",
    "          for k in training_losses:\n",
    "              training_loss_records[k].append(loss_report[k])\n",
    "  info = {\n",
    "      \"episode\": episode,\n",
    "      \"average_total_reward\": average_total_reward,\n",
    "      \"reward_variance\": reward_variance,\n",
    "      \"max_total_reward\": max_total_reward,\n",
    "      \"min_total_reward\": min_total_reward,\n",
    "      \"average_depth_per_episode\": average_n_step,\n",
    "      \"max_depth_per_episode\": max_n_step,\n",
    "      \"min_depth_per_episode\": min_n_step\n",
    "  }\n",
    "  if training_losses:\n",
    "      for k in training_losses:\n",
    "        info[k] = training_loss_records[k]\n",
    "  return info\n",
    "\n",
    "def plot_multiple_line(legend_names, list_of_stats, x_name, ncol = 2, row_height = 4, save_path=\"/kaggle/working/fig/rl.png\"):\n",
    "  '''\n",
    "  @input:\n",
    "  - legend_names: [legend]\n",
    "  - list_of_stats: [{field_name: [values]}]\n",
    "  - x_name: x-axis field_name\n",
    "  - ncol: number of subplots in each row\n",
    "  '''\n",
    "  plt.rcParams.update({'font.size': 14})\n",
    "  assert ncol > 0\n",
    "  features = list(list_of_stats[0].keys())\n",
    "  features.remove(x_name)\n",
    "  N = len(features)\n",
    "  fig_height = 12 // ncol if len(features) == 1 else row_height*((N-1)//ncol+1)\n",
    "  plt.figure(figsize = (16, fig_height))\n",
    "  for i,field in enumerate(features):\n",
    "      plt.subplot((N-1)//ncol+1,ncol,i+1)\n",
    "      minY,maxY = float('inf'),float('-inf')\n",
    "      for j,L in enumerate(legend_names):\n",
    "          X = list_of_stats[j][x_name]\n",
    "          value_list = list_of_stats[j][field]\n",
    "          minY,maxY = min(minY,min(value_list)),max(maxY,max(value_list))\n",
    "          plt.plot(X[:len(value_list)], value_list, label = L)\n",
    "      plt.ylabel(field)\n",
    "      plt.xlabel(x_name)\n",
    "      scale = 1e-4 + maxY - minY\n",
    "      plt.ylim(minY - scale * 0.05, maxY + scale * 0.05)\n",
    "      plt.legend()\n",
    "  plt.savefig(save_path)\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1bd2df",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.545839Z",
     "iopub.status.busy": "2025-07-22T06:37:30.545646Z",
     "iopub.status.idle": "2025-07-22T06:37:30.549220Z",
     "shell.execute_reply": "2025-07-22T06:37:30.548534Z"
    },
    "id": "HVUXZjicg3kg",
    "papermill": {
     "duration": 0.012463,
     "end_time": "2025-07-22T06:37:30.550404",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.537941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Socrer function\n",
    "def dot_scorer(action_emb, item_emb, item_dim):\n",
    "  '''\n",
    "  score = item_emb * weight\n",
    "\n",
    "  @input:\n",
    "  - action_emb: (B, i_dim)\n",
    "  - item_emb: (B, L, i_dim) or (1, L, i_dim)\n",
    "  @output:\n",
    "  - score: (B, L)\n",
    "  '''\n",
    "  output = torch.sum(action_emb.view(-1, 1, item_dim) * item_emb, dim=-1)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0dc6ce8",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.565182Z",
     "iopub.status.busy": "2025-07-22T06:37:30.564944Z",
     "iopub.status.idle": "2025-07-22T06:37:30.570076Z",
     "shell.execute_reply": "2025-07-22T06:37:30.569372Z"
    },
    "id": "t-f8lshQUlDz",
    "papermill": {
     "duration": 0.013872,
     "end_time": "2025-07-22T06:37:30.571269",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.557397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Dense Neural Network\n",
    "\n",
    "class DNN(nn.Module):\n",
    "  def __init__(self, in_dim, hidden_dims, out_dim=1, dropout_rate= 0.,\n",
    "               do_batch_norm=True):\n",
    "    super(DNN, self).__init__()\n",
    "    self.in_dim = in_dim\n",
    "    layers = []\n",
    "\n",
    "    for hidden_dim in hidden_dims:\n",
    "      linear_layer = nn.Linear(in_dim, hidden_dim)\n",
    "\n",
    "      layers.append(linear_layer)\n",
    "      in_dim = hidden_dim\n",
    "      layers.append(nn.ReLU())\n",
    "      if dropout_rate > 0:\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "      if do_batch_norm:\n",
    "        layers.append(nn.LayerNorm(hidden_dim))\n",
    "\n",
    "    # Prediction layer\n",
    "    last_layer = nn.Linear(in_dim, out_dim)\n",
    "    layers.append(last_layer)\n",
    "\n",
    "    self.layers = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, self.in_dim)\n",
    "    logit = self.layers(x)\n",
    "    return logit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec6ff041",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.585780Z",
     "iopub.status.busy": "2025-07-22T06:37:30.585609Z",
     "iopub.status.idle": "2025-07-22T06:37:30.589990Z",
     "shell.execute_reply": "2025-07-22T06:37:30.589498Z"
    },
    "id": "EcNXI4e7tyGR",
    "papermill": {
     "duration": 0.012776,
     "end_time": "2025-07-22T06:37:30.591006",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.578230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title # Data Reader class\n",
    "\n",
    "class BaseDataReader(Dataset):\n",
    "  def __init__(self, params):\n",
    "    self.phase = 'train'\n",
    "    self.n_worker = params['n_worker']\n",
    "    self._read_data(params)\n",
    "\n",
    "  def _read_data(self, params):\n",
    "    self.data = dict()\n",
    "    self.data['train'] = params['train']\n",
    "    self.data['val'] = params['val']\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    pass\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data[self.phase])\n",
    "\n",
    "  def get_statistics(self):\n",
    "    return {'length': len(self)}\n",
    "\n",
    "  def set_phase(self, phase):\n",
    "    assert phase in ['train', 'val', 'test']\n",
    "    self.phase = phase\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cea1aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.606427Z",
     "iopub.status.busy": "2025-07-22T06:37:30.606033Z",
     "iopub.status.idle": "2025-07-22T06:37:30.613344Z",
     "shell.execute_reply": "2025-07-22T06:37:30.612823Z"
    },
    "papermill": {
     "duration": 0.016258,
     "end_time": "2025-07-22T06:37:30.614386",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.598128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ML1M Data Reader\n",
    "\n",
    "class ML1MDataReader(BaseDataReader):\n",
    "        \n",
    "    def __init__(self, params):\n",
    "        '''\n",
    "        - from BaseReader:\n",
    "            - phase\n",
    "            - data: will add Position column\n",
    "        '''\n",
    "        super().__init__(params)\n",
    "        self.max_seq_len = params['max_seq_len']\n",
    "        \n",
    "    def _read_data(self, params):\n",
    "        # read data_file\n",
    "        super()._read_data(params)\n",
    "        print(\"Load item meta data\")\n",
    "        self.item_meta = params['item_meta']\n",
    "        self.user_meta = params['user_meta']\n",
    "        self.item_vec_size = len(self.item_meta[0])\n",
    "        self.user_vec_size = len(self.user_meta[0])\n",
    "        self.portrait_len = len(self.user_meta[0])\n",
    "    \n",
    "    ###########################\n",
    "    #        Iterator         #\n",
    "    ###########################\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        user_ID, slate_of_items, user_feedback, user_history, sequence_id = self.data[self.phase].iloc[idx]\n",
    "        user_profile = self.user_meta[user_ID]\n",
    "    \n",
    "        exposure = eval(slate_of_items)\n",
    "    \n",
    "        history = eval(user_history)\n",
    "    \n",
    "        hist_length = len(history)\n",
    "        history = padding_and_clip(history, self.max_seq_len)\n",
    "        # print(f\"history{}\")\n",
    "        feedback = eval(user_feedback)\n",
    "    \n",
    "        record = {\n",
    "            'timestamp': int(1), # timestamp is irrelevant, just a hack temporal\n",
    "            'exposure': np.array(exposure).astype(int),\n",
    "            'exposure_features': self.get_item_list_meta(exposure).astype(float),\n",
    "            'feedback': np.array(feedback).astype(float),\n",
    "            'history': np.array(history).astype(int),\n",
    "            'history_features': self.get_item_list_meta(history).astype(float),\n",
    "            'history_length': int(min(hist_length, self.max_seq_len)),\n",
    "            'user_profile': np.array(user_profile)\n",
    "            }\n",
    "        return record\n",
    "        \n",
    "    def get_item_list_meta(self, item_list):\n",
    "        return np.array([self.item_meta[item] for item in item_list])\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        '''\n",
    "        - n_user\n",
    "        - n_item\n",
    "        - s_parsity\n",
    "        - from BaseReader:\n",
    "            - length\n",
    "            - fields\n",
    "        '''\n",
    "        stats = super().get_statistics()\n",
    "        stats['length'] = len(self.data[self.phase])\n",
    "        stats['n_item'] = len(self.item_meta) - 1\n",
    "        stats['item_vec_size'] = self.item_vec_size\n",
    "        stats['user_portrait_len'] = self.user_vec_size\n",
    "        stats['max_seq_len'] = self.max_seq_len\n",
    "        return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76936a28",
   "metadata": {
    "id": "BZu5Gr-atrEE",
    "papermill": {
     "duration": 0.007042,
     "end_time": "2025-07-22T06:37:30.628381",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.621339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6be326dd",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.643778Z",
     "iopub.status.busy": "2025-07-22T06:37:30.643567Z",
     "iopub.status.idle": "2025-07-22T06:37:30.651523Z",
     "shell.execute_reply": "2025-07-22T06:37:30.651014Z"
    },
    "id": "aE05j2QDr6lh",
    "papermill": {
     "duration": 0.01718,
     "end_time": "2025-07-22T06:37:30.652571",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.635391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Base Model\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "  def __init__(self, reader, params):\n",
    "    super().__init__()\n",
    "    self.display_name = \"BaseModel\"\n",
    "    self.reader = reader\n",
    "    self.model_path = params['model_path']\n",
    "    self.loss_type = params['loss_type']\n",
    "    self.l2_coef = params['l2_coef']\n",
    "    self.device = params['device']\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self._define_params(reader, params)\n",
    "\n",
    "  def get_regularization(self, *modules):\n",
    "    return get_regularization(*modules)\n",
    "\n",
    "  def do_forward_and_loss(self, feed_dict: dict) -> dict:\n",
    "    '''\n",
    "    Used during training to compute predictions and the loss.\n",
    "    '''\n",
    "    out_dict = self.get_forward(feed_dict)\n",
    "    out_dict['loss'] = self.get_loss(feed_dict, out_dict)\n",
    "    return out_dict\n",
    "\n",
    "  def forward(self, feed_dict: dict, return_prob=True) -> dict:\n",
    "    '''\n",
    "      Used during evaluation/prediction to generate predictions and probabilities\n",
    "    '''\n",
    "    out_dict = self.get_forward(feed_dict)\n",
    "    if return_prob:\n",
    "      out_dict['probs'] = self.sigmoid(out_dict['preds'])\n",
    "    return out_dict\n",
    "\n",
    "  def wrap_batch (self, batch):\n",
    "    '''\n",
    "    Build feed_dict from batch data and move data to self.device\n",
    "    '''\n",
    "    for k, val in batch.items():\n",
    "      if type(val).__module__ == np.__name__:\n",
    "        batch[k] = torch.from_numpy(val)\n",
    "      elif torch.is_tensor(val):\n",
    "        batch[k] = val\n",
    "      elif type(val) is list:\n",
    "        batch[k] = torch.tensor(val)\n",
    "      else:\n",
    "        continue # No compatiable type\n",
    "      if batch[k].type() == 'torch.DoubleTensor':\n",
    "        batch[k] = batch[k].type(torch.FloatTensor)\n",
    "      batch[k] = batch[k].to(self.device)\n",
    "    return batch\n",
    "\n",
    "  def save_checkpoint(self):\n",
    "    torch.save({\n",
    "        \"model_state_dict\": self.state_dict(),\n",
    "        \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "    }, self.model_path + \".checkpoint\")\n",
    "\n",
    "  def load_checkpoint(self, model_path, with_optimizer=True):\n",
    "    checkpoint = torch.load(model_path + \".checkpoint\",\n",
    "                            map_location=self.device)\n",
    "    self.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    if with_optimizer:\n",
    "      self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    self.model_path = model_path\n",
    "\n",
    "  def _define_params(self, reader, params):\n",
    "    pass\n",
    "\n",
    "  def get_forward(self, feed_dict: dict) -> dict:\n",
    "    pass\n",
    "\n",
    "  def get_loss(self, feed_dict: dict, out_dict: dict) -> dict:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa64aade",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.667835Z",
     "iopub.status.busy": "2025-07-22T06:37:30.667641Z",
     "iopub.status.idle": "2025-07-22T06:37:30.676071Z",
     "shell.execute_reply": "2025-07-22T06:37:30.675591Z"
    },
    "id": "EM4gIUpwL6Bu",
    "papermill": {
     "duration": 0.017413,
     "end_time": "2025-07-22T06:37:30.677033",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.659620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ML1M Response Model\n",
    "\n",
    "class ML1MUserResponse(BaseModel):\n",
    "  def __init__(self, reader, params):\n",
    "    super().__init__(reader, params)\n",
    "    self.bce_loss = nn.BCEWithLogitsLoss(reduction= 'none')\n",
    "\n",
    "  def _define_params(self, reader, params):\n",
    "    stats = reader.get_statistics()\n",
    "    print(stats)\n",
    "    self.potrait_len = stats['user_portrait_len']\n",
    "    self.item_dim = stats['item_vec_size']\n",
    "    self.feature_dim = params['feature_dim']\n",
    "    self.hidden_dim = params['hidden_dims']\n",
    "    self.attn_n_head = params['attn_n_head']\n",
    "    self.dropout_rate = params['dropout_rate']\n",
    "    self.uEmb = nn.Embedding.from_pretrained(torch.FloatTensor(self.reader.user_meta), freeze=False)\n",
    "    self.iEmb = nn.Embedding.from_pretrained(torch.FloatTensor(self.reader.item_meta), freeze=False)\n",
    "\n",
    "    # fuse information\n",
    "    self.concat_layer = nn.Linear(self.feature_dim * 2, self.feature_dim)\n",
    "\n",
    "    # portrait embedding\n",
    "    self.portrait_encoding_layer = DNN(self.potrait_len, self.hidden_dim,\n",
    "                                        self.feature_dim, self.dropout_rate,\n",
    "                                        do_batch_norm= False)\n",
    "    # item embedding\n",
    "    self.item_emb_layer = nn.Linear(self.item_dim, self.feature_dim)\n",
    "\n",
    "    # user history encoder\n",
    "    self.seq_self_attn_layer = nn.MultiheadAttention(self.feature_dim, self.attn_n_head, batch_first= True)\n",
    "    self.seq_user_attn_layer = nn.MultiheadAttention(self.feature_dim, self.attn_n_head, batch_first= True)\n",
    "\n",
    "    self.loss = []\n",
    "\n",
    "  def get_forward(self, feed_dict: dict) -> dict:\n",
    "    user_emb = self.portrait_encoding_layer(feed_dict['user_profile']).view(-1, 1, self.feature_dim)\n",
    "    history_item_emb = self.item_emb_layer(feed_dict['history_features'])\n",
    "\n",
    "    seq_encoding, attn_weight = self.seq_self_attn_layer(history_item_emb, history_item_emb, history_item_emb)\n",
    "\n",
    "    user_interest, attn_weight = self.seq_user_attn_layer(user_emb, seq_encoding, seq_encoding)\n",
    "\n",
    "    user_interest = torch.concat([user_interest, user_emb], axis=-1)\n",
    "    user_interest = self.concat_layer(user_interest)\n",
    "\n",
    "    exposure_item_emb = self.item_emb_layer(feed_dict['exposure_features'])\n",
    "\n",
    "    score = torch.sum(exposure_item_emb * user_interest, dim=-1)\n",
    "\n",
    "    # regularization\n",
    "    reg = self.get_regularization(self.uEmb, self.iEmb, self.portrait_encoding_layer,\n",
    "                                  self.item_emb_layer, self.seq_user_attn_layer,\n",
    "                                  self.seq_self_attn_layer)\n",
    "    return {'preds': score, 'reg': reg}\n",
    "\n",
    "  def get_loss(self, feed_dict: dict, out_dict: dict):\n",
    "    preds, reg = out_dict[\"preds\"].view(-1), out_dict[\"reg\"]\n",
    "    target = feed_dict['feedback'].view(-1).to(torch.float)\n",
    "\n",
    "    # print(f\"preds: {self.sigmoid(preds)}\")\n",
    "    # print(f\"target: \", target)\n",
    "\n",
    "    loss = torch.mean(self.bce_loss(self.sigmoid(preds), target))\n",
    "    # print(f\"loss: {loss} l2: {reg} l2*coef: {self.l2_coef * reg}\")\n",
    "    self.loss.append(loss.item())\n",
    "    loss = loss + self.l2_coef * reg\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54353b2",
   "metadata": {
    "id": "EPzAu5L7uFO5",
    "papermill": {
     "duration": 0.007057,
     "end_time": "2025-07-22T06:37:30.691237",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.684180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36d2a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.706193Z",
     "iopub.status.busy": "2025-07-22T06:37:30.705980Z",
     "iopub.status.idle": "2025-07-22T06:37:30.716416Z",
     "shell.execute_reply": "2025-07-22T06:37:30.715953Z"
    },
    "papermill": {
     "duration": 0.01917,
     "end_time": "2025-07-22T06:37:30.717481",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.698311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['train'] = train\n",
    "params['val'] = test\n",
    "params['item_meta'] = item_info\n",
    "params['user_meta'] = user_info\n",
    "params['n_worker'] = 4\n",
    "params['max_seq_len'] = 50\n",
    "\n",
    "params['loss_type'] = 'bce'\n",
    "params['device'] = device\n",
    "params['l2_coef'] = 0.001\n",
    "params['lr'] = 0.0003\n",
    "params['feature_dim'] = 16\n",
    "params['hidden_dims'] = [256]\n",
    "params['attn_n_head'] = 2\n",
    "params['batch_size'] = 128\n",
    "params['seed'] = 26\n",
    "params['epoch'] = 2\n",
    "params['dropout_rate'] = 0.2\n",
    "params['model_path'] = os.path.join(path_to_output, \n",
    "                          f\"env/ml1m_user_env_lr{params['lr']}_reg{params['l2_coef']}.model\")\n",
    "set_random_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f5208f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:37:30.732468Z",
     "iopub.status.busy": "2025-07-22T06:37:30.732295Z",
     "iopub.status.idle": "2025-07-22T06:38:13.586543Z",
     "shell.execute_reply": "2025-07-22T06:38:13.585426Z"
    },
    "id": "pUiyHg58pQk3",
    "outputId": "de7d8a66-a100-4cfe-b476-963ac617cda0",
    "papermill": {
     "duration": 42.863144,
     "end_time": "2025-07-22T06:38:13.587663",
     "exception": false,
     "start_time": "2025-07-22T06:37:30.724519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load item meta data\n",
      "{'length': 77906, 'n_item': 3952, 'item_vec_size': 18, 'user_portrait_len': 30, 'max_seq_len': 50}\n",
      "epoch 0 is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77952it [00:16, 4813.44it/s]                           \n",
      "19584it [00:03, 5984.24it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 validating; auc: 0.5956\n",
      "epoch 1 is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77952it [00:14, 5308.25it/s]                           \n",
      "19584it [00:03, 5931.38it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 validating; auc: 0.5986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Train user response\n",
    "reader = ML1MDataReader(params)\n",
    "model = ML1MUserResponse(reader, params).to(device)\n",
    "\n",
    "\n",
    "# reader = RL4RSDataReader(params)\n",
    "# model = RL4RSUserResponse(reader, params).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "model.optimizer = optimizer\n",
    "\n",
    "\n",
    "epo = 0\n",
    "while epo < params['epoch']:\n",
    "  print(f\"epoch {epo} is training\")\n",
    "  epo += 1\n",
    "\n",
    "  model.train()\n",
    "  reader.set_phase(\"train\")\n",
    "  train_loader = DataLoader(reader, params['batch_size'], shuffle = True, pin_memory = True,\n",
    "                            num_workers= params['n_worker'])\n",
    "\n",
    "  t1 = time()\n",
    "  pbar = tqdm(total=len(train_loader.dataset))\n",
    "  step_loss = []\n",
    "  for i, batch_data in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    wrapped_batch = wrap_batch(batch_data, device)\n",
    "\n",
    "    out_dict = model.do_forward_and_loss(wrapped_batch)\n",
    "    loss = out_dict['loss']\n",
    "    loss.backward()\n",
    "    step_loss.append(loss.item())\n",
    "    optimizer.step()\n",
    "    pbar.update(params['batch_size'])\n",
    "    # print(model.loss)\n",
    "    # if (i + 1) % 10 == 0:\n",
    "      # print(f\"Iteration {i + 1}, loss {np.mean(step_loss[-100:])}\")\n",
    "  pbar.close()\n",
    "    # print(\"Epoch {}; time {:.4f}\".format(epo, time() - t1))\n",
    "\n",
    "  # validation\n",
    "  t2 = time()\n",
    "  reader.set_phase(\"val\")\n",
    "  val_loader = DataLoader(reader, params['batch_size'], shuffle = False, pin_memory = False,\n",
    "                          num_workers= params['n_worker'])\n",
    "  valid_probs, valid_true =  [], []\n",
    "  pbar = tqdm(total = len(val_loader.dataset))\n",
    "  with torch.no_grad():\n",
    "    for i, batch_data in enumerate(val_loader):\n",
    "      wrapped_batch = wrap_batch(batch_data, device)\n",
    "      out_dict = model.forward(wrapped_batch)\n",
    "      valid_probs.append(out_dict['probs'].cpu().numpy())\n",
    "      valid_true.append(batch_data['feedback'].cpu().numpy())\n",
    "      pbar.update(params['batch_size'])\n",
    "  pbar.close()\n",
    "  auc = roc_auc_score(np.concatenate(valid_true), np.concatenate(valid_probs))\n",
    "  print(f\"epoch {epo} validating\" + \"; auc: {:.4f}\".format(np.mean(auc)))\n",
    "  model.save_checkpoint()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0709ab31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:13.626565Z",
     "iopub.status.busy": "2025-07-22T06:38:13.625755Z",
     "iopub.status.idle": "2025-07-22T06:38:13.947358Z",
     "shell.execute_reply": "2025-07-22T06:38:13.946644Z"
    },
    "id": "eqgPbcAsID16",
    "outputId": "ca1dea56-cb24-4412-b8bb-133c693198cd",
    "papermill": {
     "duration": 0.342033,
     "end_time": "2025-07-22T06:38:13.948782",
     "exception": false,
     "start_time": "2025-07-22T06:38:13.606749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABmcAAAIjCAYAAAD2os/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADTCElEQVR4nOzdeVhU9eLH8c/MMICouLEjguK+oWIi7pVrVla2XS2XyrqKadKi3kqzRbt1M29lmqZmP7MsM7O0FDVtcV9yF8UF3MAFERWBgZnfH97mxkVNFDgDvF/Pw/M03/meM58zl2/dx4/fc0wOh8MhAAAAAAAAAAAAFAuz0QEAAAAAAAAAAADKEsoZAAAAAAAAAACAYkQ5AwAAAAAAAAAAUIwoZwAAAAAAAAAAAIoR5QwAAAAAAAAAAEAxopwBAAAAAAAAAAAoRpQzAAAAAAAAAAAAxYhyBgAAAAAAAAAAoBhRzgAAAAAAAAAAABQjyhkAAAAAMNgnn3wik8mkw4cPGx0FAAAAQDGgnAEAAABQ4vxRZmzatMnoKNf0yiuvyGQyOX+8vLzUsGFDvfTSS0pPTy+Uz5g7d64mTZpUKOcCAAAAUDzcjA4AAAAAAKXdlClTVKFCBV24cEHLli3TG2+8oZUrV+q3336TyWS6qXPPnTtXO3fu1DPPPFM4YQEAAAAUOcoZAAAAAChi999/v3x8fCRJf//739W7d28tWLBA69atU3R0tMHpAAAAABQ3bmsGAAAAoNTaunWrevToIW9vb1WoUEG333671q1bl2eOzWbTuHHjVKdOHXl6eqpatWpq166d4uLinHOSk5M1cOBAVa9eXR4eHgoMDFSvXr1u+Bkxt912myTp0KFD15z34YcfqlGjRvLw8FBQUJBiYmKUlpbmfL9Tp05avHixEhMTnbdOCwsLu6FMAAAAAIoPO2cAAAAAlEq7du1S+/bt5e3trRdeeEFWq1UfffSROnXqpNWrVysqKkrS5efCTJgwQU888YRatWql9PR0bdq0SVu2bFGXLl0kSb1799auXbv09NNPKywsTCdPnlRcXJySkpJuqAw5cOCAJKlatWpXnfPKK69o3Lhx6ty5swYPHqz4+HhNmTJFGzdu1G+//Sar1aoXX3xR586d09GjR/Xuu+9KkipUqFDgPAAAAACKF+UMAAAAgFLppZdeks1m06+//qpatWpJkvr166d69erphRde0OrVqyVJixcv1h133KFp06Zd8TxpaWlas2aN3n77bT333HPO8dGjR193ltTUVElyPnPmww8/lL+/v9q3b3/F+adOndKECRPUtWtX/fDDDzKbL9/0oH79+ho6dKjmzJmjgQMHqkuXLgoODtbZs2f1yCOPXHceAAAAAMbitmYAAAAASp3c3FwtW7ZM99xzj7OYkaTAwED16dNHv/76q9LT0yVJlStX1q5du7R///4rnqtcuXJyd3fXqlWrdPbs2RvKU69ePfn6+qpmzZp66qmnVLt2bS1evFheXl5XnL98+XJlZ2frmWeecRYzkjRo0CB5e3tr8eLFN5QDAAAAgGugnAEAAABQ6pw6dUoZGRmqV69evvcaNGggu92uI0eOSJJeffVVpaWlqW7dumrSpImef/55bd++3Tnfw8ND//znP/XDDz/I399fHTp00FtvvaXk5OTrzvP1118rLi5Oq1atUkJCgnbu3KnIyMirzk9MTJSkfPnd3d1Vq1Yt5/sAAAAASibKGQAAAABlWocOHXTgwAHNnDlTjRs31scff6wWLVro448/ds555plntG/fPk2YMEGenp56+eWX1aBBA23duvW6P6Nz587q2LGjwsPDi+pSAAAAAJQQlDMAAAAASh1fX195eXkpPj4+33t79+6V2WxWSEiIc6xq1aoaOHCgPv/8cx05ckRNmzbVK6+8kue48PBwPfvss1q2bJl27typ7OxsvfPOO0WSPzQ0VJLy5c/OztahQ4ec70uSyWQqkgwAAAAAig7lDAAAAIBSx2KxqGvXrvr22291+PBh53hKSormzp2rdu3aydvbW5J05syZPMdWqFBBtWvXVlZWliQpIyNDmZmZeeaEh4erYsWKzjmFrXPnznJ3d9d7770nh8PhHJ8xY4bOnTunnj17OsfKly+vc+fOFUkOAAAAAEXDzegAAAAAAHCjZs6cqR9//DHf+PDhw/X6668rLi5O7dq105AhQ+Tm5qaPPvpIWVlZeuutt5xzGzZsqE6dOikyMlJVq1bVpk2bNH/+fA0dOlSStG/fPt1+++168MEH1bBhQ7m5uembb75RSkqKHn744SK5Ll9fX40ePVrjxo1T9+7ddffddys+Pl4ffvihbrnlFj3yyCPOuZGRkZo3b55iY2N1yy23qEKFCrrrrruKJBcAAACAwkE5AwAAAKDEmjJlyhXHBwwYoEaNGumXX37R6NGjNWHCBNntdkVFRWnOnDmKiopyzh02bJgWLVqkZcuWKSsrS6GhoXr99df1/PPPS5JCQkL0t7/9TStWrND//d//yc3NTfXr19eXX36p3r17F9m1vfLKK/L19dUHH3ygESNGqGrVqnryySc1fvx4Wa1W57whQ4bo999/16xZs/Tuu+8qNDSUcgYAAABwcSbHn/fIAwAAAAAAAAAAoEjxzBkAAAAAAAAAAIBiRDkDAAAAAAAAAABQjChnAAAAAAAAAAAAihHlDAAAAAAAAAAAQDGinAEAAAAAAAAAAChGlDMAAAAAAAAAAADFyM3oACWV3W7X8ePHVbFiRZlMJqPjAAAAAAAAAAAAAzkcDp0/f15BQUEym6+9N4Zy5gYdP35cISEhRscAAAAAAAAAAAAu5MiRI6pevfo157hEOTN58mS9/fbbSk5OVkREhN5//321atXqqvPT0tL04osvasGCBUpNTVVoaKgmTZqkO+64Q5KUm5urV155RXPmzFFycrKCgoI0YMAAvfTSS85dLg6HQ2PHjtX06dOVlpamtm3basqUKapTp851Za5YsaKky1+yt7f3TX4DpYfNZtOyZcvUtWtXWa1Wo+MA+BPWJ+C6WJ+Aa2JtAq6L9Qm4JtYm4LpYn8UjPT1dISEhzv7gWgwvZ+bNm6fY2FhNnTpVUVFRmjRpkrp166b4+Hj5+fnlm5+dna0uXbrIz89P8+fPV3BwsBITE1W5cmXnnH/+85+aMmWKZs+erUaNGmnTpk0aOHCgKlWqpGHDhkmS3nrrLb333nuaPXu2atasqZdfflndunXT7t275enp+Ze5/yh5vL29KWf+xGazycvLS97e3ixywMWwPgHXxfoEXBNrE3BdrE/ANbE2AdfF+ixe1/MoFMPLmYkTJ2rQoEEaOHCgJGnq1KlavHixZs6cqVGjRuWbP3PmTKWmpmrNmjXOX6KwsLA8c9asWaNevXqpZ8+ezvc///xzbdiwQdLlXTOTJk3SSy+9pF69ekmSPv30U/n7+2vhwoV6+OGHi+pyAQAAAAAAAABAGWdoOZOdna3Nmzdr9OjRzjGz2azOnTtr7dq1Vzxm0aJFio6OVkxMjL799lv5+vqqT58+GjlypCwWiySpTZs2mjZtmvbt26e6detq27Zt+vXXXzVx4kRJ0qFDh5ScnKzOnTs7z1upUiVFRUVp7dq1VyxnsrKylJWV5Xydnp4u6XLjaLPZbv7LKCX++C74TgDXw/oEXBfrE3BNrE3AdbE+AdfE2gRcF+uzeBTk+zW0nDl9+rRyc3Pl7++fZ9zf31979+694jEHDx7UypUr1bdvXy1ZskQJCQkaMmSIbDabxo4dK0kaNWqU0tPTVb9+fVksFuXm5uqNN95Q3759JUnJycnOz/nfz/3jvf81YcIEjRs3Lt/4smXL5OXlVbALLwPi4uKMjgDgKlifgOtifQKuibUJuC7WJ+CaWJuA62J9Fq2MjIzrnmv4bc0Kym63y8/PT9OmTZPFYlFkZKSOHTumt99+21nOfPnll/rss880d+5cNWrUSL///rueeeYZBQUFqX///jf0uaNHj1ZsbKzz9R8P9unatSvPnPkTm82muLg4denShXsXAi6G9Qm4LtYn4JpYm4DrYn0Crom1idLG4XAoNzdXubm5cjgcRse5KTk5OVqzZo3atGkjN7cSVwu4BJPJJIvFIovFctVnyvxxx63rYej/Cj4+PrJYLEpJSckznpKSooCAgCseExgYKKvV6ryFmSQ1aNBAycnJys7Olru7u55//nmNGjXKeXuyJk2aKDExURMmTFD//v2d505JSVFgYGCez23WrNkVP9fDw0MeHh75xq1WK/+xuQK+F8B1sT4B18X6BFwTaxNwXaxPwDWxNlEaZGdn68SJEwXaCeHKHA6HAgICdOLEiet6WD2uzsvLS4GBgXJ3d8/3XkH+3WdoOePu7q7IyEitWLFC99xzj6TLO2NWrFihoUOHXvGYtm3bau7cubLb7TKbzZKkffv25fkyMjIynO/9wWKxyG63S5Jq1qypgIAArVixwlnGpKena/369Ro8eHARXCkAAAAAAAAAoCSw2+06dOiQLBaLgoKC5O7uXuILDbvdrgsXLqhChQr5/uwc18fhcCg7O1unTp3SoUOHVKdOnZv6Lg3fvxQbG6v+/furZcuWatWqlSZNmqSLFy9q4MCBkqR+/fopODhYEyZMkCQNHjxYH3zwgYYPH66nn35a+/fv1/jx4zVs2DDnOe+66y698cYbqlGjhho1aqStW7dq4sSJeuyxxyRd3n70zDPP6PXXX1edOnVUs2ZNvfzyywoKCnKWRAAAAAAAAACAsic7O1t2u10hISGl5nnjdrtd2dnZ8vT0pJy5CeXKlZPValViYqLz+7xRhpczDz30kE6dOqUxY8YoOTlZzZo1048//ih/f39JUlJSUp5flpCQEC1dulQjRoxQ06ZNFRwcrOHDh2vkyJHOOe+//75efvllDRkyRCdPnlRQUJCeeuopjRkzxjnnhRde0MWLF/Xkk08qLS1N7dq1048//nhTXyYAAAAAAAAAoHSgxMCVFNbvheHljCQNHTr0qrcxW7VqVb6x6OhorVu37qrnq1ixoiZNmqRJkyZddY7JZNKrr76qV199taBxAQAAAAAAAAAAbhjVHwAAAAAAAAAAQDGinAEAAAAAAAAAANdl1apVMplMSktLu+5jwsLCrnmnq7KIcgYAAAAAAAAAgFJgwIABMplM+vvf/57vveeee04Wi0UDBgwo/mCF4EZKIVdGOQMAAAAAAAAAQCkREhKiL774QpcuXXKOZWZmav78+apRo4aByfBnlDMAAAAAAAAAAFyDw+FQRnaOIT8Oh6NAWVu0aKGQkBAtWLDAObZgwQJVr15dzZo1yzM3KytLw4YNk5+fnzw9PdWuXTtt3Lgxz5wlS5aobt26KleunG699VYdPnw432f++uuvat++vcqVK6eQkBANGzZMFy9eLFDum3X27Fn169dPVapUkZeXl3r06KH9+/c7309MTNRdd92lKlWqqHz58mrUqJGWLFniPLZv377y9fVVuXLlVKdOHc2aNatI87oV6dkBAAAAAAAAACjhLtly1XDMUkM+e/er3eTlXrA/yn/sscc0a9Ys9e3bV5L0ySefqG/fvlq3bl2eeS+88IK+/vprzZ49W6GhoXrrrbfUrVs3JSQkqGrVqjpy5Ijuu+8+xcTE6Mknn9SmTZv07LPP5jnHgQMH1L17d73++uuaOXOmTp06paFDh2ro0KFFXnD82YABA7R//34tWrRI3t7eGjlypO644w7t3r1bVqtVMTExys7O1s8//6zy5ctr9+7dqlChgiTp5Zdf1u7du/XDDz/Ix8dHCQkJeXYeFQXKGQAAAAAAAAAASpFHHnlEo0ePVmJioiTpt99+00cffZSnnLl48aKmTJmiTz75RD169JAkTZ8+XXFxcZoxY4aef/55TZkyReHh4XrnnXckSfXq1dOOHTv0z3/+03meCRMmqG/fvnrmmWckSXXq1NF7772njh07asqUKfL09Czy6/2jlPntt9/Upk0bSdJnn32mkJAQLVy4UA888ICSkpLUu3dvNWnSRJJUq1Yt5/FJSUlq3ry5WrZsKUkKCwsr8syUMyhUGdk5WnHMpNYXs+Vf2Wp0HAAAAAAAAAC4aeWsFu1+tZthn11Qvr6+6tmzpz755BM5HA7dcccdqlatWp45Bw4ckM1mU9u2bZ1jVqtVrVq10p49eyRJe/bsUVRUVJ7joqOj87zetm2btm/frs8++8w55nA4ZLfbdejQITVo0OCaWX/55RdnOSRJH330kXPHz/Xas2eP3Nzc8mStVq2a6tWr57yWYcOGafDgwVq2bJk6d+6s3r17q2nTppKkwYMHq3fv3tqyZYu6du2qe+65x1nyFBXKGRSqp7/Ypp+TLPL95ZBevqux0XEAAAAAAAAA4KaZTKYC31rMaI899piGDh0qSXr//feL7HMuXLigp556SsOGDcv3Xo0aNf7y+JYtW+r33393vvb39y/MeE5PPPGEunXrpsWLF2vZsmWaMGGC3nnnHT399NPq0aOHEhMTtWTJEsXFxen2229XTEyM/vWvfxVJFkkyF9mZUSY92vryYpuz/ohS0jMNTgMAAAAAAAAAZVP37t2VnZ0tm82mbt3y7/oJDw+Xu7u7fvvtN+eYzWbTxo0b1bBhQ0lSgwYNtGHDhjzH/e9za1q0aKHdu3erdu3a+X7c3d3/Mme5cuXyHFOxYsUCX2uDBg2Uk5Oj9evXO8fOnDmj+Ph457VIUkhIiP7+979rwYIFevbZZzV9+nTne76+vurfv7/mzJmjSZMmadq0aQXOURAlq+qDy+tYx0c1Kzp06LxdH/6UoHG92D0DAAAAAAAAAMXNYrE4b+llseS/NVr58uU1ePBgPf/886patapq1Kiht956SxkZGXr88cclSX//+9/1zjvv6Pnnn9cTTzyhzZs365NPPslznpEjR6p169YaOnSonnjiCZUvX167d+9WXFycPvjgg0K/rh07duQpcEwmkyIiItSrVy8NGjRIH330kSpWrKhRo0YpODhYvXr1kiQ988wz6tGjh+rWrauzZ8/qp59+ct5ybcyYMYqMjFSjRo2UlZWl77///i9vx3az2DmDQmUymdQjxC5JmrfpiM5ezJZ0+Vk0B09dMDIaAAAAAAAAAJQp3t7e8vb2vur7b775pnr37q1HH31ULVq0UEJCgpYuXaoqVapIunxbsq+//loLFy5URESEpk6dqvHjx+c5R9OmTbV69Wrt27dP7du3V/PmzTVmzBgFBQUVyTV16NBBzZs3d/5ERkZKkmbNmqXIyEjdeeedio6OlsPh0JIlS2S1Xn42em5urmJiYtSgQQN1795ddevW1YcffihJcnd31+jRo9W0aVN16NBBFotFX3zxRZHk/4PJ4XA4ivQTSqn09HRVqlRJ586du+Yvd1ljs9m0ePESTUusot0nzuvZLnU19Lba+tv0dVp3MFUv39lQuXa7dh5L173Ng3VrfT+jIwNlhs1m05IlS3THHXc4/6MEwDWwPgHXxNoEXBfrE3BNrE2UFpmZmTp06JBq1qwpT09Po+MUCrvdrvT0dHl7e8tsZs/GzbjW70dBegNua4ZCZzJJj7UN03Pzd+j9lQnamHhW6w6mSpJe+363c97vR9IoZwAAAAAAAAAAZQ4VGYrEnU0C1L1RgLJz7fp53ylJUtXylx/+FFTpcpuYlJqh42mXDMsIAAAAAAAAAIARKGdQJCxmk97v01x/7xiuxsHe6lTPV6ue76SvB7fR6hduVUT1SpKk9YfOGJwUAAAAAAAAAIDixW3NUGSsFrNG9agvqb5zLDL08oOkompV07aj57TuQKrubV7doIQAAAAAAAAAABQ/ds7AEK1rVZUk/ZpwWtk5dmXl5BqcCAAAAAAAAAD+y+FwGB0BLqiwfi8oZ2CIqJrVVMXLqmNpl1T3pR8UMW6ZJv+UoFw7/8IDAAAAAAAAYByr1SpJysjIMDgJXNEfvxd//J7cKG5rBkOU93DTq70a6+nPt0qSMm12vb00XpIUc2ttI6MBAAAAAAAAKMMsFosqV66skydPSpK8vLxkMpkMTnVz7Ha7srOzlZmZKbOZPRs3wuFwKCMjQydPnlTlypVlsVhu6nyUMzDMnU0DlZSaoeRzmQqo5Km3l8br/ZX7dU/zYAVXLmd0PAAAAAAAAABlVEBAgCQ5C5qSzuFw6NKlSypXrlyJL5qMVrlyZefvx82gnIFhTCaTc5eMw+HQ6n2ntOFQqv61NF7vPtTM2HAAAAAAAAAAyiyTyaTAwED5+fnJZrMZHeem2Ww2/fzzz+rQocNN346rLLNarTe9Y+YPlDNwCSaTSS/3bKi7PvhV3/5+TENvq61w3wpGxwIAAAAAAABQhlkslkL7w3gjWSwW5eTkyNPTk3LGRXBzObiMJtUrqXMDf9kd0sRl+4yOAwAAAAAAAABAkaCcgUsZ0aWOzCZp8Y4TWr47xeg4AAAAAAAAAAAUOsoZuJRGQZU0qH0tSdLYRbuUnWM3OBEAAAAAAAAAAIWLcgYu55nOdeVb0UPH0i7pm61HjY4DAAAAAAAAAEChcjM6APC/yrlb9FSHWnp98R69vzJBFT2t2pJ4Vm4Ws46czdCjrUPVulY1o2MCAAAAAAAAAHBDKGfgkvpE1dDHvxzS0bOXNOSzLXne23YkTT8910lWCxu/AAAAAAAAAAAlD3+6DZfk5e6meU+1Vlg1L1nMJt3XIlgPRFaXJB09e0nfbD1mcEIAAAAAAAAAAG4MO2fgskKrldfSER10ITNH1Sp4SJLq+FfQ+CV7NfmnBN3XPFhu7J4BAAAAAAAAAJQw/Mk2XJqHm8VZzEhS36hQVS3vrsQzGVq07biByQAAAAAAAAAAuDGUMyhRynu46Yn2NSVJH6xMUK7dYXAiAAAAAAAAAAAKhnIGJU6/6DB5e7rp4OmLWrYr2eg4AAAAAAAAAAAUCOUMSpwKHm7q3yZMkjR19QE5HA5dyMrR+yv26+vNR3UpO9fYgAAAAAAAAAAAXIOb0QGAG9G/TZim/XxQ246e0+IdJ3Tw1EVNjNsnSfp8Q5K+fCpaZrPJ4JQAAAAAAAAAAOTHzhmUSD4VPPT3juGSpFcW7daSHSec721KPKv5m48aFQ0AAAAAAAAAgGuinEGJNeTWcNXyLa/TF7K0N/m8JOmR1jUkSf9aFq+cXLuR8QAAAAAAAAAAuCLKGZRYHm4WxXSq7XztW9FDY+5spCpeVp08n6V1B1MNTAcAAAAAAAAAwJVRzqBEuzMi0PnPQZU85e5mVvfGl8e+23ZckrQq/qQ6vf2Tftx54ornAAAAAAAAAACgOFHOoETzcLPozfuayMvdolE9GkiS7vpPYTNv0xGFjVqsAbM26vCZDP19zha9G7dPGw+n6khqhoZ8tlm3/muVDp++aOQlAAAAAAAAAADKGDejAwA36+FWNfRwqxrO11E1q6m2XwUlnLyQb+6/V+zX5J8SVM5q0fmsHEnS/M1H9Vy3etf8DIfDoWW7U1TR001twn0K9wIAAAAAAAAAAGUK5QxKHYvZpMXD2ulkepZ+3n9K6w+m6o4mgXr1u10ym006evaSs5iRpF8TTl+znMnKydX7KxL0wU8JkqQ7mgRowr1NVcnLWuTXAgAAAAAAAAAofShnUCp5uFkUUtVLfaNC1TcqVJLUvXGAcu0OTVmVoBy7Q/c2D1bHt1dp+9E0pWfa5O2Zv2z5cWeynv9qm7PMMZukJTuStTnxrO5rUV1Db62t8h4sIwAAAAAAAADA9eOZMyhTLGaTht5WR890rqvQauVVy6e87A5pTcJpSVKu3SFbrl2StGxXsobO3aLzWTny9/bQ6/c01rcx7RRazUsp6VmasuqAXpi/XReycrR0V/IVb6MGAAAAAAAAAMD/4q/8o0zrUNdXB09f1PPztys++YL+b12ifCq4a9jtdTT8i63KsTvUq1mQJj7YTBazSZL04/AOWrLjhEZ+vV2Ld5zQ4h0nJEle7hbN6H+LosOrGXlJAAAAAAAAAAAXx84ZlGnDbq+jyNAqOp+Zo3eX79PpC1nam3xeQz7bIluuQ3c2DdQ7D0Q4ixlJKuduUe/I6nqxZwPnWEUPN2Vk5+rx2Rt14twlIy4FAAAAAAAAAFBCsHMGZVrV8u76fFBrzVmXqM83JOnUhSylZdgkSe1q++jdh5rJzXLlDnNg25q6OyJIZpNJ5dwt+tv0ddqalKZ//rBXkx5uXpyXAQAAAAAAAAAoQdg5gzLP3c2sx9rVVFxsR219uYsGtAlTh7q+mtynhaxXKWb+UK2Ch6qUd5en1aLXejWWySQt/P24fvjPrc4AAAAAAAAAAPhflDPAn5hMJr1ydyN9+lgrVfKyFujYxsGV9HjbmpKkpz/fqk5v/6T1B88URUwAAAAAAAAAQAlGOQMUolE96qtzA3/l2B06fCZDby+NNzoSAAAAAAAAAMDFUM4AhcjNYtb0fpGaOyhKkrQp8ax2HD1ncCoAAAAAAAAAgCuhnAEKmclkUptwH/VqFiRJen/lfv17+X59/MtBORwOg9MBAAAAAAAAAIzmZnQAoLQa3Clc328/oWW7U7Rsd4ok6ejZSxp7V0OZTCaD0wEAAAAAAAAAjEI5AxSR+gHeerJDLU1ZdUB/dDGfrDmshb8fU8NAbzWvUVn9osPk7+1pbFAAAAAAAAAAQLGinAGK0PDb68jDzawmwZV0+kKWRn69Q2kZNq05cEZrDpzR3PVJ+qBPC7Wt7WN0VAAAAAAAAABAMaGcAYqQp9WiZzrXdb4u5+6m5btT1KJGZX21+ah2HU/X0LlbtPLZTqpS3t3ApAAAAAAAAACA4mI2OgBQltwdEaT3/tZcA9rW1IIhbVQ/oKLOZth06zur9Mlvh+RwOK7rPCnpmRr2+VZ9tj6xiBMDAAAAAAAAAAqbS5QzkydPVlhYmDw9PRUVFaUNGzZcc35aWppiYmIUGBgoDw8P1a1bV0uWLHG+HxYWJpPJlO8nJibGOSc5OVmPPvqoAgICVL58ebVo0UJff/11kV0j8L883Cx67Z7GkqS0DJte+W63PllzON+8rJxc5eTana+PpGbogalrtWjbcb34zU4t2XFCDodD2Tn2fMcCAAAAAAAAAFyP4bc1mzdvnmJjYzV16lRFRUVp0qRJ6tatm+Lj4+Xn55dvfnZ2trp06SI/Pz/Nnz9fwcHBSkxMVOXKlZ1zNm7cqNzcXOfrnTt3qkuXLnrggQecY/369VNaWpoWLVokHx8fzZ07Vw8++KA2bdqk5s2bF+k1A3+4Jayq5j3ZWj/sTNYnaw5r/JI9alvbR3X9KyojO0evfb9b32w9JqvFrPsjq6uc1aIFW44pOT1TnlazMm12Df9iq96p6qXkc5n69PFWigytavRlAQAAAAAAAACuwfCdMxMnTtSgQYM0cOBANWzYUFOnTpWXl5dmzpx5xfkzZ85UamqqFi5cqLZt2yosLEwdO3ZURESEc46vr68CAgKcP99//73Cw8PVsWNH55w1a9bo6aefVqtWrVSrVi299NJLqly5sjZv3lzk1wz8WVStahp7V0N1buAnW65D477bpbMXszVg5kZ9vuGIMm12nc/M0azfDuvDVQeUnJ6pOn4VtOLZTurZNFC2XIcOnLqoi9m5eu6r7UrPtCkrJ1fvr9iv57/apmk/H9Ch0xeNvkwAAAAAAAAAwH8YunMmOztbmzdv1ujRo51jZrNZnTt31tq1a694zKJFixQdHa2YmBh9++238vX1VZ8+fTRy5EhZLJYrfsacOXMUGxsrk8nkHG/Tpo3mzZunnj17qnLlyvryyy+VmZmpTp06XfFzs7KylJWV5Xydnp4uSbLZbLLZbDdy+aXSH98F30nBje5eVz/vP63fEs6o3VsrdTErVxU83PTew02VfilHm5PSJEmBlTz0QIvqquzlpnfvb6wOtasqPvmC5m48okOnLyp6wgoFensq4dR/C5kJP+zVHY0DFFzZU49E1VBgJU+DrhJGYn0Crov1Cbgm1ibgulifgGtibQKui/VZPAry/Zoc1/sE8iJw/PhxBQcHa82aNYqOjnaOv/DCC1q9erXWr1+f75j69evr8OHD6tu3r4YMGaKEhAQNGTJEw4YN09ixY/PN//LLL9WnTx8lJSUpKCjIOZ6WlqaHHnpIy5Ytk5ubm7y8vPTVV1+pa9euV8z6yiuvaNy4cfnG586dKy8vrxu5fCCfVSdM+ubw5ZLR19OhgXVzFVz++o49dF6am2DRyczLJaTV7FDHAIeOXJTiz/13k1ytig493ShXZtPVzgQAAAAAAAAAKKiMjAz16dNH586dk7e39zXnGv7MmYKy2+3y8/PTtGnTZLFYFBkZqWPHjuntt9++YjkzY8YM9ejRI08xI0kvv/yy0tLStHz5cvn4+GjhwoV68MEH9csvv6hJkyb5zjN69GjFxsY6X6enpyskJERdu3b9yy+5LLHZbIqLi1OXLl1ktVqNjlPi3CHpufNZOnjqoppW95aXe8GW6BCHQ78fOaeNiWfVNryaGgVd/t3ceiRNX285pnmbjungeZPO+zXR324JKYIrgCtjfQKui/UJuCbWJuC6WJ+Aa2JtAq6L9Vk8/rjj1vUwtJzx8fGRxWJRSkpKnvGUlBQFBARc8ZjAwEBZrdY8tzBr0KCBkpOTlZ2dLXd3d+d4YmKili9frgULFuQ5x4EDB/TBBx9o586datSokSQpIiJCv/zyiyZPnqypU6fm+1wPDw95eHjkG7darfwyXwHfy40LrmpVcNUKN3x8q3BftQr3zTtWy1etavmqtp+33liyR698t0eeVqsepKApk1ifgOtifQKuibUJuC7WJ+CaWJuA62J9Fq2CfLfmv55SdNzd3RUZGakVK1Y4x+x2u1asWJHnNmd/1rZtWyUkJMhutzvH9u3bp8DAwDzFjCTNmjVLfn5+6tmzZ57xjIwMSZefb/NnFoslz3mB0uaxdjX18C0hsjukF77ero9/OWh0JAAAAAAAAAAocwwtZyQpNjZW06dP1+zZs7Vnzx4NHjxYFy9e1MCBAyVJ/fr10+jRo53zBw8erNTUVA0fPlz79u3T4sWLNX78eMXExOQ5r91u16xZs9S/f3+5ueXdIFS/fn3Vrl1bTz31lDZs2KADBw7onXfeUVxcnO65554iv2bAKBazSRPua6KnOtaSJL2+eI9+2X/K4FQAAAAAAAAAULYY/syZhx56SKdOndKYMWOUnJysZs2a6ccff5S/v78kKSkpKc8Ol5CQEC1dulQjRoxQ06ZNFRwcrOHDh2vkyJF5zrt8+XIlJSXpsccey/eZVqtVS5Ys0ahRo3TXXXfpwoULql27tmbPnq077rijaC8YMJjJZNLoHg10MStHc9Yl6fmvtuv/Hm+lOv4VjY4GAAAAAAAAAGWC4eWMJA0dOlRDhw694nurVq3KNxYdHa1169Zd85xdu3aVw+G46vt16tTR119/XaCcQGnyjzsaaM2BMzp46qJ6vv+r7moapG6N/HVrfT9ZLYZvqgMAAAAAAACAUos/gQXKKC93N817Mlod6voqO8eur7cc1ZP/t1n9ZmxQpi3X6HgAAAAAAAAAUGq5xM4ZAMbwreih2QNv0Zaks/r29+P6evNRrT14Rre/s1rVKrjLy92iAW1qqnvjAKOjAgAAAAAAAECpQTkDlHEmk0mRoVUVGVpVdzYN0uOzN+pY2iUdS7skSVp3MFVzHo9Suzo+BicFAAAAAAAAgNKBcgaAU6uaVbV29O3adDhVWTl2zd98VHG7U7Rg61HKGQAAAAAAAAAoJJQzAPKo4OGmTvX8JElVvNwVtztFy3enKDvHLnc3HlMFAAAAAAAAADeLP2kFcFWRoVXkU8FD6Zk5Wrk3Rbl2hxZtO65Nh1MlSXa7Q8nnMg1OCQAAAAAAAAAlCztnAFyVxWzS3RFBmvnbIT331XaF+SRo57F0WS0mzf97G3386yF9t+243n0oQlaLWa1qVpVfRU+jYwMAAAAAAACAS6OcAXBNz3Wrq13Hz2n9oVTtPJYuSbLlOtRr8m/OOSPmbZMk1fQprx+Gt5en1WJIVgAAAAAAAAAoCShnAFyTl7ubPhnYSj/sPKGsHLua16isp+du1f6TFyRJZpNkd1yee+j0Rf1jwQ79o2cD+VTwMDA1AAAAAAAAALguyhkAf6mcu0X3tajufP39sHbanHhW2Tl2uVvMeunbnWoTXk1z1iVpwdZjWnPgjJbFdpC3p9XA1AAAAAAAAADgmihnABSYh5tFbcJ9nK9XPttJktSprp/GfLtTx89l6uOfD+ruZkHycndTYCVPmUwmg9ICAAAAAAAAgGuhnAFQaDo39NfF7BwN/+J3vbcyQe+tTJAk+VTw0Oge9XVnRKDMJpOsFrPBSQEAAAAAAADAOJQzAArVnU2DNGXVAe1NPq/y7hZl5dh1+kKWnv1qm579apv8vT3UrVGAzmfm6N7mwWpfx4ddNQAAAAAAAADKFMoZAIXKYjbpy79H69T5LNXyKa/sXLteWbRLn284IklKSc/Sp2sTJUnfbD2mYbfXUWyXukZGBgAAAAAAAIBiRTkDoNB5e1rl7WmVdPn5NK/1aqwmwZXlV9FD+06e15HUDJlMJs1dn6T3VuxXHb8KuisiyODUAAAAAAAAAFA8KGcAFDk3i1l9ompIuvxcmj94e1o1dfUBvb54t5qFVFZlL6sq/qfUAQAAAAAAAIDSinIGgGFGdKmj77cf19Gzl9T+rZ9UzmrR4E7hGnprbZnNeZ9Dk5Gdo2+2HtN3245rf8oFVa9STq/f00RNqlcyKD0AAAAAAAAA3BjKGQCG8XCz6IXu9TXs862SpEu2XE2M26fTF7I05s6GsuU6tGJviswmk177frdOnMt0HnvmYraGfr5FS5/pIE+rxahLAAAAAAAAAIACo5wBYKi7I4IUWMlTfhU99FvCGf3jmx36dG2iVu49qVy7I08hE1y5nAa0CVPLsCoaPGeLEs9k6OnPt2rCfU3kU8HDwKsAAAAAAAAAgOtHOQPAcLeEVZUkhVYrr/IeFo37breOnr0kSfKp4KGM7Bw1CvLWtEdbqkp5d0nShPua6PHZGxW3O0V7TqTrk4GtFFrNS1aL2bDrAAAAAAAAAIDrQTkDwKX0ahas2+r7acOhVNlyHWpXx0deVotMJslk+u9zaG6t76dvY9pp6OeXd9B0nrhavhU9NO3RSDWvUcXAKwAAAAAAAACAa6OcAeByKnpadXsD/7+c16R6Jc0d1FpPzN6kPSfSdep8lv42fZ1ub+Cv7By7nupQSy3/sysHAAAAAAAAAFwF5QyAEi24cjktGdZOF7JyNOSzLfpl/2kt3n5CkrQ1KU1Ln2mvajyPBgAAAAAAAIAL4eEMAEo8k8mkip5WzR7YSp8Paq2nb6sti9mk0xeyNHrBDjkcDqMjAgAAAAAAAIAT5QyAUsNsNik6vJqe7VpPi4a2ldVi0rLdKfpy0xGjowEAAAAAAACAE+UMgFKpUVAlxXapJ0l68ZudmrcxyeBEAAAAAAAAAHAZ5QyAUuvJDrV0d0SQcuwOjfx6h37ed8roSAAAAAAAAABAOQOg9LKYTfr3w8308C0hkqQR837XByv368yFLIOTAQAAAAAAACjLKGcAlGomk0lj72qk+gEVdeZitv61bJ/a/fMndtEAAAAAAAAAMAzlDIBSr5y7RV/9PVpv3tdETYIr6ZItV28s3iOHw2F0NAAAAAAAAABlEOUMgDKhoqdVD7eqoTlPRKm8u0XxKef18/7TRscCAAAAAAAAUAZRzgAoUyqVs+qhW2pIkobM2awZvx5iBw0AAAAAAACAYkU5A6DMibk1XBHVK+lidq5e+363xny7S9k5dqNjAQAAAAAAACgjKGcAlDnVKnjomyFt9VLPBpKk/1uXqPunrtGFrByDkwEAAAAAAAAoCyhnAJRJZrNJT7Svpen9Wqqyl1Xbj57T5J8SjI4FAAAAAAAAoAygnAFQpnVp6K+374+QJM345ZDidqfwDBoAAAAAAAAARcrN6AAAYLTODfzUqZ6vVsWf0qBPN6l/dKgOnr6o9nV89GSHcKPjAQAAAAAAAChl2DkDoMwzmUya3KeFnuxQS5I0e22iftl/WuOX7NW6g2cMTgcAAAAAAACgtKGcAQBJ5T3c9I87GujR1qF5xl9auJPbnAEAAAAAAAAoVJQzAPAnr9zdSJ8+1kq/vHCr3C1mJZy8oMNnMoyOBQAAAAAAAKAUoZwBgD+xmE3qUNdXIVW91CyksiRpwyFubQYAAAAAAACg8FDOAMBVtKpZVZK04dBZg5MAAAAAAAAAKE0oZwDgKpzlzGF2zgAAAAAAAAAoPJQzAHAVLUKryGySjqRe0tGzPHcGAAAAAAAAQOGgnAGAq6jg4abI0CqSpBV7ThqcBgAAAAAAAEBpQTkDANfQtWGAJClud4rBSQAAAAAAAACUFpQzAHANXRr6S5LWHTyjcxk2g9MAAAAAAAAAKA0oZwDgGsJ8yquufwXl2B1aujvZ6DgAAAAAAAAASgHKGQD4C72aBUuSvt581OAkAAAAAAAAAEoDyhkA+Av3Ng+WySStP5SqpDMZRscBAAAAAAAAUMJRzgDAXwiqXE7tavtIkgbM2qDPNyRpTcJpXcrONTgZAAAAAAAAgJKIcgYArsNLPRsqsJKnDp6+qNELdqjPx+vVbdLPOnsx2+hoAAAAAAAAAEoYyhkAuA71Aipq8bD2evq22mpfx0dVvKxKSs3Q0M+3UNAAAAAAAAAAKBDKGQC4TlXLu+vZrvX0f49Hae6g1vJwM+u3hDPq8u7POpLKs2gAAAAAAAAAXB/KGQC4AQ0CvTV3UGvV8imv0xey9Pri3UZHAgAAAAAAAFBCUM4AwA2KDK2iqY9GymI2aemuFK09cMboSAAAAAAAAABKAMoZALgJdf0rqneLYEnS0l3JBqcBAAAAAAAAUBJQzgDATepUz0+S2DkDAAAAAAAA4Lq4RDkzefJkhYWFydPTU1FRUdqwYcM156elpSkmJkaBgYHy8PBQ3bp1tWTJEuf7YWFhMplM+X5iYmLynGft2rW67bbbVL58eXl7e6tDhw66dOlSkVwjgNKrda1qkqT4lPM6dT7L4DQAAAAAAAAAXJ3h5cy8efMUGxursWPHasuWLYqIiFC3bt108uTJK87Pzs5Wly5ddPjwYc2fP1/x8fGaPn26goODnXM2btyoEydOOH/i4uIkSQ888IBzztq1a9W9e3d17dpVGzZs0MaNGzV06FCZzYZ/JQBKmKrl3dUg0FuStO4gu2cAAAAAAAAAXJub0QEmTpyoQYMGaeDAgZKkqVOnavHixZo5c6ZGjRqVb/7MmTOVmpqqNWvWyGq1Srq8U+bPfH1987x+8803FR4ero4dOzrHRowYoWHDhuX5jHr16hXWZQEoY9qEV9OeE+n6cVey7ooIMjoOAAAAAAAAABdmaDmTnZ2tzZs3a/To0c4xs9mszp07a+3atVc8ZtGiRYqOjlZMTIy+/fZb+fr6qk+fPho5cqQsFssVP2POnDmKjY2VyWSSJJ08eVLr169X37591aZNGx04cED169fXG2+8oXbt2l3xc7OyspSV9d/bFaWnp0uSbDabbDbbDX8Hpc0f3wXfCcqau5v6a8avh7R0Z7KOnDmvAG9PoyPlw/oEXBfrE3BNrE3AdbE+AdfE2gRcF+uzeBTk+zW0nDl9+rRyc3Pl7++fZ9zf31979+694jEHDx7UypUr1bdvXy1ZskQJCQkaMmSIbDabxo4dm2/+woULlZaWpgEDBuQ5hyS98sor+te//qVmzZrp008/1e23366dO3eqTp06+c4zYcIEjRs3Lt/4smXL5OXlVZDLLhP+uJUcUJaEV7TowHnp1bmrdGcNu9Fxror1Cbgu1ifgmlibgOtifQKuibUJuC7WZ9HKyMi47rmG39asoOx2u/z8/DRt2jRZLBZFRkbq2LFjevvtt69YzsyYMUM9evRQUFBQnnNI0lNPPeW8nVrz5s21YsUKzZw5UxMmTMh3ntGjRys2Ntb5Oj09XSEhIeratau8vb0L+zJLLJvNpri4OHXp0sV52zmgrDCHpujpL7ZpzWmrXn+0vaqWdzc6Uh6sT8B1sT4B18TaBFwX6xNwTaxNwHWxPovHH3fcuh6GljM+Pj6yWCxKSUnJM56SkqKAgIArHhMYGCir1ZrnFmYNGjRQcnKysrOz5e7+3z8MTUxM1PLly7VgwYJ855Ckhg0b5hlv0KCBkpKSrvi5Hh4e8vDwyDdutVr5Zb4CvheURT2bBmvqz4e063i6pv2aqJfvbPjXBxmA9Qm4LtYn4JpYm4DrYn0Crom1Cbgu1mfRKsh3ay7CHH/J3d1dkZGRWrFihXPMbrdrxYoVio6OvuIxbdu2VUJCgnP3iyTt27dPgYGBeYoZSZo1a5b8/PzUs2fPPONhYWEKCgpSfHx8nvF9+/YpNDT0Zi8LQBllNpv0fLd6kqR5G48oKyfX4EQAAAAAAAAAXJGh5YwkxcbGavr06Zo9e7b27NmjwYMH6+LFi87bjfXr10+jR492zh88eLBSU1M1fPhw7du3T4sXL9b48eMVExOT57x2u12zZs1S//795eaWd4OQyWTS888/r/fee0/z589XQkKCXn75Ze3du1ePP/540V80gFKrQx1f+Xt76EJWjtYknDE6DgAAAAAAAAAXZPgzZx566CGdOnVKY8aMUXJyspo1a6Yff/xR/v7+kqSkpCSZzf/tkEJCQrR06VKNGDFCTZs2VXBwsIYPH66RI0fmOe/y5cuVlJSkxx577Iqf+8wzzygzM1MjRoxQamqqIiIiFBcXp/Dw8KK7WAClntlsUrdGAfp0baJ+3JmsW+v7GR0JAAAAAAAAgIsxvJyRpKFDh2ro0KFXfG/VqlX5xqKjo7Vu3bprnrNr165yOBzXnDNq1CiNGjXqunMCwPXo/p9yZtnuZL2c1VAVPFziX7UAAAAAAAAAXIThtzUDgNKmVc2qql6lnM5m2PTG4t1GxwEAAAAAAADgYihnAKCQuVnMevv+CJlM0ucbjmjnsXNGRwIAAAAAAADgQihnAKAIRIdXU88mgZKkLzcdMTgNAAAAAAAAAFdCOQMAReThW2pIkhZuPaZMW67BaQAAAAAAAAC4CsoZACgibcKrKbhyOaVn5mjBlmNGxwEAAAAAAADgIihnAKCImM0mDWwbJkl6d/k+XczKMTYQAAAAAAAAAJdAOQMARejR6FCFVvPSqfNZmv7LQaPjAAAAAAAAAHABlDMAUIQ83Cx6rms9SdKk5fs1cNYGfbnxiMGpAAAAAAAAABiJcgYAitgdTQJV26+CJOmn+FP6xzc7dODUBYNTAQAAAAAAADAK5QwAFDGL2aRR3evLYjZJknLsDk1YssfgVAAAAAAAAACMQjkDAMWgc0N/bR3TRSue7Sg3s0nL95zUr/tPGx0LAAAAAAAAgAEoZwCgmHh7WhXuW0GPtA6VJL32/W5lZOcYnAoAAAAAAABAcaOcAYBi9kznOqrsZVV8ynn9bfp6XcyioAEAAAAAAADKEsoZAChmlb3cNaP/LarsZdW2I2n6fEOSbLl2paRn6kJWjl77frf+8c0OZefYjY4KAAAAAAAAoAi4GR0AAMqiyNAqer5bPb34zU69vniPJsbtU0Z2rixmk3LtDkmS2SS9fk8Tg5MCAAAAAAAAKGzsnAEAg/RqFuz854zsXElSrt2hCh5uMpmkOeuStO1ImkHpAAAAAAAAABQVyhkAMEgFDzcNal9TktQ3qoYS3uihxcPaaeWzHdW5gb8kae3BM0ZGBAAAAAAAAFAEuK0ZABjohe719dAtIQr3rSCTyaRGQZUkSVE1qypud4o2HU6VOoYbnBIAAAAAAABAYWLnDAAYyGoxq7ZfRZlMpjzjLcOqSpI2JZ6V/T/PoAEAAAAAAABQOlDOAIALahTkLU+rWWkZNh04dcHoOAAAAAAAAAAKEeUMALggq8Ws5iFVJEmLth03OA0AAAAAAACAwsQzZwDART3SOlRrD57RR6sPqkZVL32+IUlBlctp9B0NFFy5nNHxAAAAAAAAANwgds4AgIu6o0mAbq3nq+xcu56fv11bktL0/fYT6v3hGmXaco2OBwAAAAAAAOAGUc4AgIsymUya+GAzPdiyuspZLerROEC+FT2UnJ6pX/afNjoeAAAAAAAAgBtEOQMALqxKeXe9dX+Edr/aTVMeiVTPJoGSpKW7kg1OBgAAAAAAAOBGUc4AQAlgMpkkSd0bB0iSlu9JkS3XbmQkAAAAAAAAADeIcgYASpBbwqrKp4K70jJs+nrzUaPjAAAAAAAAALgBlDMAUIJYzCb9vWO4JOntpfE6l2EzOBEAAAAAAACAgqKcAYASpn+bMIX7lteZi9l6+outyuH2ZgAAAAAAAECJQjkDACWM1WLWvx9uLk+rWT/vO6URX25Tdg4FDQAAAAAAAFBSUM4AQAnUOLiS/v1wc7mZTfpu23E999U2ORwOo2MBAAAAAAAAuA6UMwBQQnVrFKCP+7eUxWzSom3H9eWmI0ZHAgAAAAAAAHAdKGcAoATrVM9Pz3atK0ma8MNeZWTnGJwIAAAAAAAAwF+hnAGAEu7J9rUUWs1LaRk2fb6B3TMAAAAAAACAq6OcAYASzs1i1lMdwiVJM345KLudZ88AAAAAAAAAroxyBgBKgd6RwfL2dNPxc5nanHTW6DgAAAAAAAAAroFyBgBKAQ83izo39JckLdlxwuA0AAAAAAAAAK6FcgYASok7GgdKkn7cmcytzQAAAAAAAAAXRjkDAKVEuzo+qujhphPnMvXbgdNGxwEAAAAAAABwFZQzAFBKeFot6h1ZXZI067fDxoYBAAAAAAAAcFWUMwBQivRvEyaTSVq596Q+35CknFy70ZEAAAAAAAAA/A/KGQAoRWr6lNddTYMkSaMX7NCt76zSJ78dUqYt1+BkAAAAAAAAAP5AOQMApcw7D0bopZ4NVMXLqiOpl/TKd7s1/IutRscCAAAAAAAA8B+UMwBQylgtZj3RvpbWjLpdr/VqJJNJWrorRYdOXzQ6GgAAAAAAAABRzgBAqVXO3aJHo8N0az0/SVLXf/+meQfNyrU7DE4GAAAAAAAAlG2UMwBQyj3aOtT5z2tSzFq+56SBaQAAAAAAAADcVDmTmZlZWDkAAEWkY11fPd+tnvP19F8Py+Fg9wwAAAAAAABglAKXM3a7Xa+99pqCg4NVoUIFHTx4UJL08ssva8aMGYUeEABwc8xmk2Jura21IzvKzeTQtqPnNOGHvbJzezMAAAAAAADAEAUuZ15//XV98skneuutt+Tu7u4cb9y4sT7++ONCDQcAKDw+FTzUs4ZdkjTt54Oat+mIwYkAAAAAAACAsqnA5cynn36qadOmqW/fvrJYLM7xiIgI7d27t1DDAQAK121BDj1ze21J0qdrE7m9GQAAAAAAAGCAApczx44dU+3atfON2+122Wy2QgkFACg6fVuFyN3NrD0n0vX7kTSj4wAAAAAAAABlToHLmYYNG+qXX37JNz5//nw1b968UEIBAIpOZS+r7mwaKEn6bH2Sft53SgknLxicCgAAAAAAACg73Ap6wJgxY9S/f38dO3ZMdrtdCxYsUHx8vD799FN9//33RZERAFDI+kbV0IItxzR/81HN33xUwZXL6ZcXbpXZbDI6GgAAAAAAAFDqFXjnTK9evfTdd99p+fLlKl++vMaMGaM9e/bou+++U5cuXYoiIwCgkLWoUUVh1bycr4+lXdLGw6kGJgIAAAAAAADKjgLvnJGk9u3bKy4urrCzAACKiclk0uPta+nlhTudY4t3nFBUrWoGpgIAAAAAAADKhgLvnAEAlA59W9XQOw9EaPy9TSRJS3YkKyfXbnAqAAAAAAAAoPQrcDljNptlsViu+gMAKBnMZpN6R1bX/ZHVVcXLqtMXsvTL/tNGxwIAAAAAAABKvQLf1uybb77J89pms2nr1q2aPXu2xo0bV2jBAADFw93NrHuaB2vWb4f11eYjurW+n9GRAAAAAAAAgFKtwDtnevXqlefn/vvv1xtvvKG33npLixYtuqEQkydPVlhYmDw9PRUVFaUNGzZcc35aWppiYmIUGBgoDw8P1a1bV0uWLHG+HxYWJpPJlO8nJiYm37kcDod69Oghk8mkhQsX3lB+ACjpHogMkSTF7U5R6sVsg9MAAAAAAAAApVuhPXOmdevWWrFiRYGPmzdvnmJjYzV27Fht2bJFERER6tatm06ePHnF+dnZ2erSpYsOHz6s+fPnKz4+XtOnT1dwcLBzzsaNG3XixAnnT1xcnCTpgQceyHe+SZMmyWQyFTg3AJQmDYO81SS4kmy5Dn37+zGj4wAAAAAAAAClWoFva3Ylly5d0nvvvZenILleEydO1KBBgzRw4EBJ0tSpU7V48WLNnDlTo0aNyjd/5syZSk1N1Zo1a2S1WiVd3inzZ76+vnlev/nmmwoPD1fHjh3zjP/+++965513tGnTJgUGBhY4OwCUJg+0rK4dx85p3sYjGtAmjOIaAAAAAAAAKCIFLmeqVKmS5w/sHA6Hzp8/Ly8vL82ZM6dA58rOztbmzZs1evRo55jZbFbnzp21du3aKx6zaNEiRUdHKyYmRt9++618fX3Vp08fjRw5UhaL5YqfMWfOHMXGxubJnZGRoT59+mjy5MkKCAj4y6xZWVnKyspyvk5PT5d0+Zk7Npvtuq+5tPvju+A7AVzPX63PHg399PriPdqbfF5bE8+oSXCl4owHlGn89xNwTaxNwHWxPgHXxNoEXBfrs3gU5PstcDnz7rvv5ik5zGazfH19FRUVpSpVqhToXKdPn1Zubq78/f3zjPv7+2vv3r1XPObgwYNauXKl+vbtqyVLlighIUFDhgyRzWbT2LFj881fuHCh0tLSNGDAgDzjI0aMUJs2bdSrV6/ryjphwgSNGzcu3/iyZcvk5eV1XecoS/64lRwA13Ot9dm0slmbTpv18ry1erK+vRhTAZD47yfgqlibgOtifQKuibUJuC7WZ9HKyMi47rkFLmf+t+Qobna7XX5+fpo2bZosFosiIyN17Ngxvf3221csZ2bMmKEePXooKCjIObZo0SKtXLlSW7duve7PHT16tGJjY52v09PTFRISoq5du8rb2/vmLqoUsdlsiouLU5cuXZy3nQPgGq5nfTY8c1Hd31ujXWfN+jy5mkZ1r6dGQfw7Dihq/PcTcE2sTcB1sT4B18TaBFwX67N4/HHHretxXeXM9u3br/uETZs2ve65Pj4+slgsSklJyTOekpJy1VuNBQYGymq15rmFWYMGDZScnKzs7Gy5u7s7xxMTE7V8+XItWLAgzzlWrlypAwcOqHLlynnGe/furfbt22vVqlX5PtfDw0MeHh75xq1WK7/MV8D3Ariua63POgGV9fAtIfpsfZLWHTqr15fEa/7gNsWcECi7+O8n4JpYm4DrYn0Crom1Cbgu1mfRKsh3e13lTLNmzWQymeRwOK45z2QyKTc397o/3N3dXZGRkVqxYoXuueceSZd3xqxYsUJDhw694jFt27bV3LlzZbfbZTabJUn79u1TYGBgnmJGkmbNmiU/Pz/17Nkzz/ioUaP0xBNP5Blr0qSJ3n33Xd11113XnR8ASqOX72youv4VNXbRLm1KPKvjaZcUVLmc0bEAAAAAAACAUuO6yplDhw4VWYDY2Fj1799fLVu2VKtWrTRp0iRdvHhRAwcOlCT169dPwcHBmjBhgiRp8ODB+uCDDzR8+HA9/fTT2r9/v8aPH69hw4blOa/dbtesWbPUv39/ubnlvcyAgIAr7sypUaOGatasWURXCgAlg6fVov5twrR4+wltOJyqJTtO6In2tYyOBQAAAAAAAJQa11XOhIaGFlmAhx56SKdOndKYMWOUnJysZs2a6ccff5S/v78kKSkpyblDRpJCQkK0dOlSjRgxQk2bNlVwcLCGDx+ukSNH5jnv8uXLlZSUpMcee6zIsgNAaXZnRKA2HE7Vv5fvV0VPNz10Sw2jIwEAAAAAAAClwnWVM1eye/duJSUlKTs7O8/43XffXeBzDR069Kq3MbvS81+io6O1bt26a56za9euf3kbtj8ryFwAKAvubR6s+ZuPavvRcxq1YIcaBlZSk+qVjI4FAAAAAAAAlHgFLmcOHjyoe++9Vzt27MjzHBqTySRJBXrmDADAdVX0tOqbIW01/Iut+n77CY1dtFNfD27j/Pc9AAAAAAAAgBtj/uspeQ0fPlw1a9bUyZMn5eXlpV27dunnn39Wy5Ytr7jLBQBQclnMJr3Us6G83C3akpSmH3cmGx0JAAAAAAAAKPEKXM6sXbtWr776qnx8fGQ2m2U2m9WuXTtNmDBBw4YNK4qMAAADBVTy1BPta0mS/rUsXjm5dud7WTm5ev373Ro5f7tSL2Zf7RQAAAAAAAAA/qTA5Uxubq4qVqwoSfLx8dHx48clSaGhoYqPjy/cdAAAl/BE+5qq7GXVgVMXtXRXiiTpSGqGHvl4vT7+9ZDmbTqiO/79i46lXTI4KQAAAAAAAOD6ClzONG7cWNu2bZMkRUVF6a233tJvv/2mV199VbVq1Sr0gAAA43l7WvVo61BJ0vsr9+v5r7ap88TV2nj4rCp6uCmsmpeS0zP1zBdb8+ysAQAAAAAAAJBfgcuZl156SXb75T94e/XVV3Xo0CG1b99eS5Ys0XvvvVfoAQEAruHBliGSpL3J5/XV5qPKyrGrVc2qWvR0O336WJQqeLhp4+Gz+m77cYOTAgAAAAAAAK7N7XontmzZUk888YT69Okjb29vSVLt2rW1d+9epaamqkqVKjKZTEUWFABgrJCqXmpX20e/JpxWFS+rpvdrqcjQ//67/9HoUE1ZdUBrEs7o3ubVDU4LAAAAAAAAuK7r3jkTERGhF154QYGBgerXr59WrVrlfK9q1aoUMwBQBrzaq5GGdArXD8M7qGVY3n/3twqrKknalHjWqHgAAAAAAABAiXDd5cyMGTOUnJysyZMnKykpSbfffrtq166t8ePH69ixY0WZEQDgImr5VtAL3esroJJnvvda1KgiSTp0+qJOX8gq7mgAAAAAAABAiVGgZ854eXlpwIABWrVqlfbt26eHH35YH330kcLCwtSzZ08tWLCgqHICAFxcJS+r6vlXlCRtOszuGQAAAAAAAOBqClTO/Fl4eLhef/11HT58WJ9//rnWrVunBx54oDCzAQBKmJZhl3fPfLY+Ubl2h8FpAAAAAAAAANd0w+WMJK1atUoDBgzQgAEDlJubq0GDBhVWLgBACfRodKg83Mz6Zf9phf9jicZ+u9PoSAAAAAAAAIDLKXA5c/ToUb3++uuqXbu2brvtNh0+fFgffvihTpw4oalTpxZFRgBACVE/wFtv3d9UbmaTJGn22kTtPHbO4FQAAAAAAACAa7nucubLL79U9+7dVbNmTU2ZMkUPPvig9u3bp9WrV6tfv34qV65cUeYEAJQQvZoFa8OLndUqrKok6YOVCQYnAgAAAAAAAFzLdZczjzzyiMqVK6dvvvlGR44c0fjx41W7du2izAYAKKGqlnfXG/c2lskk/bgrWTN/PaS3ftyrTFuu0dEAAAAAAAAAw7ld78SjR4/Kz8+vKLMAAEqROv4VdW/zYC3Yckyvfr9b0uXS5on2tQxOBgAAAAAAABjrunfOUMwAAArq+W715Gn9739qFv5+zMA0AAAAAAAAgGu47nIGAICCCqxUTrMHttKIznUlSTuPpSvh5Pl8806mZypudwq3PQMAAAAAAECZQDkDAChSUbWqaXjnOrqt/uUdmIPnbNHBUxec70/+KUFt3lypQZ9u0l3v/6pDpy8aFRUAAAAAAAAoFpQzAIBi8VzXevKt6KH9Jy/omXm/y+Fw6Kf4k3p7abxy7A6Vs1q0/+QFvf6f59MAAAAAAAAApVWBy5kjR47o6NGjztcbNmzQM888o2nTphVqMABA6dIwyFvfDW2nclaLth89p8k/JSh23u+SpAFtwvTt0LaSpNX7Tin1YraBSQEAAAAAAICiVeBypk+fPvrpp58kScnJyerSpYs2bNigF198Ua+++mqhBwQAlB4BlTzVv02YJOlfy/bpbIZNEdUraVSP+qrrX1GNgryVY3fo++3HjQ0KAAAAAAAAFKEClzM7d+5Uq1atJElffvmlGjdurDVr1uizzz7TJ598Utj5AAClzOBO4bqtvp/czCaF+5bXjAG3yNNqkSTd0yxYkvTKol3q9cGvGr9kj9IzbUbGBQAAAAAAAAqdW0EPsNls8vDwkCQtX75cd999tySpfv36OnHiROGmAwCUOpXKWTVzwC3KtOXKYjbJavnv3xPoE1VD6w6e0Yq9J7Xt6DltO3pO3287roUxbeXn7WlgagAAAAAAAKDwFHjnTKNGjTR16lT98ssviouLU/fu3SVJx48fV7Vq1Qo9IACgdPK0WvIUM5JU3sNNMwbcol9euFX/friZQqqW0/FzmZq0Yr9BKQEAAAAAAIDCV+By5p///Kc++ugjderUSX/7298UEREhSVq0aJHzdmcAANyMkKpe6tUsWBMfbCZJmrfxiA6dvmhsKAAAAAAAAKCQFPi2Zp06ddLp06eVnp6uKlWqOMeffPJJeXl5FWo4AEDZdktYVXWq56tV8ac0e81hvXJ3I6MjAQAAAAAAADetwDtnLl26pKysLGcxk5iYqEmTJik+Pl5+fn6FHhAAULYNbFtTkjR3fZJ+2HFCZy9mG5wIAAAAAAAAuDkFLmd69eqlTz/9VJKUlpamqKgovfPOO7rnnns0ZcqUQg8IACjb2tf2UfUq5ZSda9fgz7bo2a+2GR0JAAAAAAAAuCkFLme2bNmi9u3bS5Lmz58vf39/JSYm6tNPP9V7771X6AEBAGWb2WzSoPa1nK9/ij+pMxeyDEwEAAAAAAAA3JwClzMZGRmqWLGiJGnZsmW67777ZDab1bp1ayUmJhZ6QAAA+kWH6ufnb1XDQG85HNIPO5O1Kv6kZv12SLl2h9HxAAAAAAAAgAJxK+gBtWvX1sKFC3Xvvfdq6dKlGjFihCTp5MmT8vb2LvSAAACYTCbVqOalXs2CtPtEul5auNP5Xq7doSf+tLMGAAAAAAAAcHUF3jkzZswYPffccwoLC1OrVq0UHR0t6fIumubNmxd6QAAA/nBP82BV9rLmGfvXsnjFJ583KBEAAAAAAABQcAXeOXP//ferXbt2OnHihCIiIpzjt99+u+69995CDQcAwJ/5e3vqh+HtNWXVAXm5u2n70TStOXBGf5u+Tv2iQ3V/ZHVVr+JldEwAAAAAAADgmgpczkhSQECAAgICdPToUUlS9erV1apVq0INBgDAlQRWKqdXezWWJKVlZKvfzA3afvScJi3fr49WH9Qb9zbWfS2qG5wSAAAAAAAAuLoC39bMbrfr1VdfVaVKlRQaGqrQ0FBVrlxZr732mux2e1FkBADgiip7ueuLJ1vrjXsb65awKrpky9WoBTt08NQFo6MBAAAAAAAAV1XgcubFF1/UBx98oDfffFNbt27V1q1bNX78eL3//vt6+eWXiyIjAABX5eXupr5RofryqWh1qOur7By7Xvxmp+x2h9HRAAAAAAAAgCsqcDkze/Zsffzxxxo8eLCaNm2qpk2basiQIZo+fbo++eSTIogIAMBfM5lMer1XY3lazVp78IymrD5gdCQAAAAAAADgigpczqSmpqp+/fr5xuvXr6/U1NRCCQUAwI2oUc1L4+5uJEl6e2m8nv9qm7Jycg1OBQAAAAAAAORV4HImIiJCH3zwQb7xDz74QBEREYUSCgCAG/VgyxA91aGWJOmrzUc1ddVBgxMBAAAAAAAAebkV9IC33npLPXv21PLlyxUdHS1JWrt2rY4cOaIlS5YUekAAAArCZDJp9B0NVC+gomK/3KYPVyXovhbBCqnqZXQ0AAAAAAAAQNIN7Jzp2LGj9u3bp3vvvVdpaWlKS0vTfffdp/j4eLVv374oMgIAUGD3Ng9WVM2qysqxa+jcLcq0cXszAAAAAAAAuIYC75yRpKCgIL3xxht5xo4ePaonn3xS06ZNK5RgAADcDJPJpLfvj9Ddk3/VtqPn9O8V+zWye/5npgEAAAAAAADFrcA7Z67mzJkzmjFjRmGdDgCAm1ajmpfeuKeJJOmrTUdky7UbnAgAAAAAAAAoxHIGAABX1LWRv6qVd9fpC9n6ed8po+MAAAAAAAAAlDMAgNLNajHrnubBkqSpqw/w7BkAAAAAAAAYjnIGAFDq9Y2qoXJWizYePqvYL383Og4AAAAAAADKOLfrnXjfffdd8/20tLSbzQIAQJGo5VtBMwfcon4z12vJjmStO3hGrWtVMzoWAAAAAAAAyqjr3jlTqVKla/6EhoaqX79+RZkVAIAbFh1eTQ/dEiJJGvvtLi3efkIOh8PgVAAAAAAAACiLrnvnzKxZs4oyBwAARW7orXU0f/NRxaecV8zcLXrtnsZ6tHWo0bEAAAAAAABQxvDMGQBAmRFQyVMLY9rqvhbBkqTxi/foSGqGwakAAAAAAABQ1lDOAADKlPoB3vrX/RFqFVZVl2y5mrM+0ehIAAAAAAAAKGMoZwAAZY7ZbNKAtmGSxLNnAAAAAAAAUOwoZwAAZdKt9fzk5W7R0bOX9PuRNKPjAAAAAAAAoAyhnAEAlEnl3C3q3MBfkvT99hMGpwEAAAAAAEBZQjkDACiz7mwaKOnyrc3sdm5tBgAAAAAAgOJBOQMAKLM61vNVRQ83JadnanPSWaPjAAAAAAAAoIygnAEAlFkebhZ1aXT51mYPTF2r+ZuPGpwIAAAAAAAAZYFLlDOTJ09WWFiYPD09FRUVpQ0bNlxzflpammJiYhQYGCgPDw/VrVtXS5Yscb4fFhYmk8mU7ycmJkaSlJqaqqefflr16tVTuXLlVKNGDQ0bNkznzp0r0usEALieh1qGyGy6/M/PfbVNy3enGBsIAAAAAAAApZ7h5cy8efMUGxursWPHasuWLYqIiFC3bt108uTJK87Pzs5Wly5ddPjwYc2fP1/x8fGaPn26goODnXM2btyoEydOOH/i4uIkSQ888IAk6fjx4zp+/Lj+9a9/aefOnfrkk0/0448/6vHHHy/6CwYAuJSoWtX068jb9FDLEElS7Je/6+zFbINTAQAAAAAAoDRzMzrAxIkTNWjQIA0cOFCSNHXqVC1evFgzZ87UqFGj8s2fOXOmUlNTtWbNGlmtVkmXd8r8ma+vb57Xb775psLDw9WxY0dJUuPGjfX111873w8PD9cbb7yhRx55RDk5OXJzM/xrAQAUo6DK5fTaPY217Wia9iaf10c/H9SoHvWNjgUAAAAAAIBSytAWIjs7W5s3b9bo0aOdY2azWZ07d9batWuveMyiRYsUHR2tmJgYffvtt/L19VWfPn00cuRIWSyWK37GnDlzFBsbK5PJdNUs586dk7e391WLmaysLGVlZTlfp6enS5JsNptsNtt1XW9Z8Md3wXcCuB7W57WZJI3oXFtPzdmqT9Yc0qNR1eVX0cPoWCgjWJ+Aa2JtAq6L9Qm4JtYm4LpYn8WjIN+voeXM6dOnlZubK39//zzj/v7+2rt37xWPOXjwoFauXKm+fftqyZIlSkhI0JAhQ2Sz2TR27Nh88xcuXKi0tDQNGDDgmjlee+01Pfnkk1edM2HCBI0bNy7f+LJly+Tl5XXV48qqP24lB8D1sD6vzuGQwipYdPiCXaM+/Uk9Q+yKP2dS3UoOebGpEsWA9Qm4JtYm4LpYn4BrYm0Crov1WbQyMjKue67J4XA4ijDLNR0/flzBwcFas2aNoqOjneMvvPCCVq9erfXr1+c7pm7dusrMzNShQ4ecO2UmTpyot99+WydOnMg3v1u3bnJ3d9d33313xQzp6enq0qWLqlatqkWLFjlvlfa/rrRzJiQkRKdPn5a3t3eBrrs0s9lsiouLU5cuXa76XQIwBuvz+qw7mKpHZ22SJJlNkt0hRdeqqtkDIq+5AxO4GaxPwDWxNgHXxfoEXBNrE3BdrM/ikZ6eLh8fH+eduq7F0L8H7OPjI4vFopSUlDzjKSkpCggIuOIxgYGBslqteW5h1qBBAyUnJys7O1vu7u7O8cTERC1fvlwLFiy44rnOnz+v7t27q2LFivrmm2+u+Uvp4eEhD4/8t7exWq38Ml8B3wvgulif19a+nr861vXV6n2nZP/PX19YezBV4xbH66kO4apRjd2SKDqsT8A1sTYB18X6BFwTaxNwXazPolWQ79ZchDn+kru7uyIjI7VixQrnmN1u14oVK/LspPmztm3bKiEhQXa73Tm2b98+BQYG5ilmJGnWrFny8/NTz549850nPT1dXbt2lbu7uxYtWiRPT89CuioAQEn3Yd8WmjsoSouHtdOTHWpJkj5bn6Rek3/V+UzuzQoAAAAAAICbY2g5I0mxsbGaPn26Zs+erT179mjw4MG6ePGiBg4cKEnq16+fRo8e7Zw/ePBgpaamavjw4dq3b58WL16s8ePHKyYmJs957Xa7Zs2apf79+8vNLe8GoT+KmYsXL2rGjBlKT09XcnKykpOTlZubW/QXDQBwaeU93NQm3EeNgipp6G211aPx5d2cZzNs+mLDEYPTAQAAAAAAoKQz/PHGDz30kE6dOqUxY8YoOTlZzZo1048//ih/f39JUlJSkszm/3ZIISEhWrp0qUaMGKGmTZsqODhYw4cP18iRI/Ocd/ny5UpKStJjjz2W7zO3bNnifJ5N7dq187x36NAhhYWFFfJVAgBKKm9Pq6Y8Eql5G5M08usd+ujnA6pWwV33Ng/mGTQAAAAAAAC4IYaXM5I0dOhQDR069IrvrVq1Kt9YdHS01q1bd81zdu3aVQ6H44rvderU6arvAQBwJfc0D9YHPyXoSOolxX65TQ6H1DuyutGxAAAAAAAAUAIZflszAABKAg83ixYMbquHbwmRJP17xX7Zcu1/cRQAAAAAAACQH+UMAADXybeih8bc1VDVyrsrKTVDQz7bojMXsoyOBQAAAAAAgBKGcgYAgALwcnfTiz0byGI2KW53il7+dudNn9PhcCjXzu02AQAAAAAAygrKGQAACui+FtU178nWkqQfdybr6NmMGz7XkdQM3fHer+rw1k9Kz7QVVkQAAAAAAAC4MMoZAABuQMuwqmpX20d2hzR7zeEbOsd3246r1+TftOdEuo6lXdLy3SmFGxIAAAAAAAAuiXIGAIAb9Hi7mpKk/1uXqJT0zKvOSz6Xme/9NQdO6+nPtyr1YrZzbMmO5KIJCgAAAAAAAJdCOQMAwA3qVM9XkaFVlGmzK2r8Cr2yaJdycu155vyWcFqd/vWTOrz1k8Z+u1Mj52/XsbRLmrr6oCTp7oggff90O0nSz/tP6Ty3NgMAAAAAACj1KGcAALhBJpNJo3vUd77+ZM1hvbFkjy5m5Ui6/DyZx2dvVKbNrqwcu2avTdS8TUfU9s2V+nnfKZlN0nNd66lRkLdq+ZZXdo5dP+zMu3vG4XDIbncU63UBAAAAAACgaFHOAABwE1qGVdXcQVF6+JYQSdKs3w6r5evLtXj7CX2+IUmZNrta1Kis57vV051NA9Ug0Nt5bM+mQapRzUsmk0n3R1aXJM1dnyRJupCVoydmb1SDMT8q/MUl6jxxtc5cyCr+CwQAAAAAAEChczM6AAAAJV2bcB+1CfdRwyBvTV11QMfPZSpm7hbn+4Pa11KPJoGSpExbrtYeOKNcu0PR4dWccx6IDNG7cfv0+5E0/bzvlBZvP6Hle0463084eUHf/n5cj/3nOTcAAAAAAAAoudg5AwBAIekXHaZfRt6me5sHO8d8Knioc0N/52tPq0W31vdT54b+Ku/x378j4VvRQ3f8p8DpN3OD5m06Ikma+kikhnQKlyQt3nFCdrtDq+JP6vMNSVqxJ0U7jp5jRw0AAAAAAEAJw84ZAAAKkcVs0jsPRCg6vJrmbz6qR1qHymq5vr8L8erdjeVmNmvB1qMySRp6a211bxygZiGV9eGqA9qceFYPT1unDYdT8xznbjHrhe71FFipnLo09Je7W8H+7kXyuUx9t+247m0RLJ8KHgU6FgAAAAAAAAVHOQMAQCEzm016sGWIHmwZUqDjKnlZ9c6DEXr9nsZys5icpU5AJU/dElZFGw+f1YbDqXIzm9Shrq+Op13SyfNZSr2YrdcX75EkDbuttmK71ruuzzuSmqHvt5/Q7DWHlZyeqbjdKfriydYym00Fu2AAAAAAAAAUCOUMAAAuppy7Jd/YuLsba+rqA0pKzdDTt9XW7Q0u3yrNlmtX7Jfb9N2245Kkr7cc0zOd6/5lwXI87ZLu+uBXpWXYnGMbDqfq841J6hsVmmdupi1XcbtT1Di4kmr6lL/ZywMAAAAAACjzKGcAACgBGgZ5672/Nc83brWY9d7DzTT+3saKnrBSx9Iuafbaw+raKEBBlTxlMuUtaRwOhz7fcETTfj6gtAybwn3L666IIEnSpOX79eaSvbq9vr/8vT3kcEjH0i7p73M2a9fxdEnSiM51NbxznaK/YAAAAAAAgFKMcgYAgBLOZDKpoqdV3RoF6OstRzXuu90a991uNQmupCfa11TimQzdWs9PmxJTtXxPin5LOCNJqlreXbMGtFKNal7KtTu0Kv6Ufj+Spufnb1NWjl17T6TLw2rRqfNZ8nK3KCM7V1NXH9BTHWvJ05p/dw8AAAAAAACuD+UMAAClxOPtamr9oTOy5dqVejFbO46d0/AvfpckTYzbl2fusNvraECbMFUt7y5JsphNerN3E939wW/6Zf/p/07MzFEdvwr69PFWuu/DNTpxLlNrD5zRrfX9iuuyAAAAAAAASh2z0QEAAEDhaBjkrV9H3qb1/+isFbGdFFrNSx5uZtXzryhJalGjshoHe2tUj/qK7VLXWcz8oX6At2YNuEVe7hZV9HDTqB71NaBNmD5/srUCK5XTbf8pZJbvSZEkzduYpO6TftbaA2eK90IBAAAAAABKOHbOAABQCtWo5qVlIzooJ9chL3eLzlzMlk8Fj788rm1tH/068jaZJFX5n/KmcwN/fbY+SUt3JatxcCW9+M0O2R1SzNwtmt4vUi1qVMn3jBsAAAAAAADkx84ZAABKKQ83i8p7uMlkMl1XMfOHquXd8xUzktSmdjWFVvPS6QvZGr3gcjHj4WZW6sVs9Z6yVi8t3FmY8QEAAAAAAEotyhkAAHBdPNwsmvN4lIIrl5PVYtLj7Wpq2YgO6tkkUJI0d0OSEk6eNzglAAAAAACA6+O2ZgAA4LqFVPXS8tiOys6xq5KXVZI0uW8L2T7dpGW7U/TgR+v0Vu+m6tzQ3+CkAAAAAAAAroudMwAAoEDKuVucxcwfYm6tLUlKvZitJz7dpPUHz+R5PyM7Rw6Ho9gyAgAAAAAAuDLKGQAAcNMiQiprzuNRurWeryTp1e93a3NiquauT9KahNNqPX6Fbp+4WtuOpBkbFAAAAAAAwAVwWzMAAFAo2tXxUf3Airr17VXadTxdvaeszfN+emaOek3+TbeEVdHH/W9RpXLWq5wJAAAAAACgdGPnDAAAKDQ+FTw0vX9LtQytoooebqpW3l2SZDZJbcKryWoxaePhs5q0fJ/BSQEAAAAAAIzDzhkAAFCoWteqpvmD20iSTl/I0ie/HVb3xgFqHFxJv+4/rUdmrNenaxN18nyW/nFHAwVXLmdwYgAAAAAAgOLFzhkAAFBkfCp46Llu9dQ4uJKky7c+uz+yunLtDi3efkLvLd9vcEIAAAAAAIDiRzkDAACK1dv3N9XEByMkSUt2nlCmLdfgRAAAAAAAAMWLcgYAABQrk8mke5oFK7CSp85n5uidZfHKybUbHQsAAAAAAKDYUM4AAIBiZzabdHezIEnS9F8O6an/2yyHw2FwKgAAAAAAgOJBOQMAAAzxRLta6tUsSO4Ws1bsPam1B84YHQkAAAAAAKBYUM4AAABD+Fb00L8fbq6/tQqRJL27fB+7ZwAAAAAAQJlAOQMAAAw1uFNtebiZtfHwWc1Zl2h0HAAAAAAAgCJHOQMAAAwVUMlTo3rUlyS9sWSPzl7MNjgRAAAAAABA0aKcAQAAhusfHaa6/hWUabPr5/2njI4DAAAAAABQpChnAACA4cxmk26r7y9JWh3/33LGbucZNAAAAAAAoPRxMzoAAACAJHWq56upqw9owdZjyszJ1d7k8zp8+qLq+lfUAy1DdG/zYFUt766tSWe1bHeK7mkWrHoBFY2ODQAAAAAAUGCUMwAAwCW0qFFFHm5mZeXYtWRHsnN8b/J5vfb9bk1avk8tQ6vop//srPn4l4N6+/4IRdWqqp3H0lW1vFWRoVWNig8AAAAAAHDdKGcAAIBLcHcza1D7Wvpy0xHd2zxYbWv7KLSal37ed0pz1iUpPuW8foo/JYvZpPoBFbXreLpe+363snPtOp+ZI0n698PN1KtZsMFXAgAAAAAAcG2UMwAAwGU8162enutWL8/Yo9Hl9dAtNfTu8n3adTxdL3Srp3oBFdX+nz8pOT0zz9wX5m9XvYCKqh/gXZyxAQAAAAAACsRsdAAAAIC/4u5m1sju9fXpY63UOLiSrBazHo0Odb7/xZOt1amer7Jy7Hrk4w1atO24zmXYDEwMAAAAAABwdZQzAACgRHokKlQtQ6voiXY11bpWNb15X1NV8HDT6QtZGvb5Vo1asN3oiAAAAAAAAFdEOQMAAEqkSl5WzR/cRi/d2VCSFFDJU+PubuR8f9nuFKX8z23PAAAAAAAAXAHlDAAAKDV6R1bX4Td7qmVoFeXaHfpo9UFl2nKNjgUAAAAAAJCHm9EBAAAACtvfWtXQpsSzmvnbIX256YiahVRWjWpeer5rPVUp7250PAAAAAAAUMZRzgAAgFLnnubBSkrN0LyNR5ScnqlfE05LCdKeE+n67Ikoebnzf4EAAAAAAIBxuK0ZAAAodSxmk0Z0qas1o27TgiFt9OZ9TVSpnFVbk9L04jc75XA4ZLc7jI4JAAAAAADKKP7aKAAAKLXMZpNa1KiiFjWqqKZPefX5eL2+2XpMS3clKyM7V7fX99PH/VvKZDIZHRUAAAAAAJQh7JwBAABlQlStanqhWz1JUkZ2riRpxd6TWrXvlJGxAAAAAABAGcTOGQAAUGY81TFc3RsHSJJm/XZYn6w5rLd+jFdgJU+FVSsvT6vF4IQAAAAAAKAsYOcMAAAoU0KrlVdotfIaelttlXe3aM+JdHWf9ItavBanRduOGx0PAAAAAACUAZQzAACgTPKp4KF5T0Xr1nq+8nAzKyM7V898sVUtXovTjF8PGR0PAAAAAACUYpQzAACgzGocXEmzBrbSnle766GWIbI7pNSL2XpnWbzOXsw2Oh4AAAAAACilKGcAAECZZzab9M/7m2rVc53kU8FDGdm5mrXmsNGxAAAAAABAKUU5AwAA8B9hPuX1aq9GkqRZvx5SKrtnAAAAAABAEaCcAQAA+JPujQLUMNBb57Ny9MHKBKPjAAAAAACAUohyBgAA4E/MZpNG31FfkjRnXSLPngEAAAAAAIXOJcqZyZMnKywsTJ6enoqKitKGDRuuOT8tLU0xMTEKDAyUh4eH6tatqyVLljjfDwsLk8lkyvcTExPjnJOZmamYmBhVq1ZNFSpUUO/evZWSklJk1wgAAEqO9nV81SjIW9m5dn2//bjRcQAAAAAAQCljeDkzb948xcbGauzYsdqyZYsiIiLUrVs3nTx58orzs7Oz1aVLFx0+fFjz589XfHy8pk+fruDgYOecjRs36sSJE86fuLg4SdIDDzzgnDNixAh99913+uqrr7R69WodP35c9913X9FeLAAAKDHubX75/1ss2HrM4CQAAAAAAKC0MbycmThxogYNGqSBAweqYcOGmjp1qry8vDRz5swrzp85c6ZSU1O1cOFCtW3bVmFhYerYsaMiIiKcc3x9fRUQEOD8+f777xUeHq6OHTtKks6dO6cZM2Zo4sSJuu222xQZGalZs2ZpzZo1WrduXbFcNwAAcG13NwuS2SRtTUrTlFUH5HA4jI4EAAAAAABKCTcjPzw7O1ubN2/W6NGjnWNms1mdO3fW2rVrr3jMokWLFB0drZiYGH377bfy9fVVnz59NHLkSFkslit+xpw5cxQbGyuTySRJ2rx5s2w2mzp37uycV79+fdWoUUNr165V69at850nKytLWVlZztfp6emSJJvNJpvNdmNfQCn0x3fBdwK4HtYnUDBVPC0a2CZUM35L1D9/3KssW45iOtUqks9ifQKuibUJuC7WJ+CaWJuA62J9Fo+CfL+GljOnT59Wbm6u/P3984z7+/tr7969Vzzm4MGDWrlypfr27aslS5YoISFBQ4YMkc1m09ixY/PNX7hwodLS0jRgwADnWHJystzd3VW5cuV8n5ucnHzFz50wYYLGjRuXb3zZsmXy8vL6iyste/64lRwA18P6BK5fE4d0T6hJCxMtmrQiQcmH4hXtX3Q7aFifgGtibQKui/UJuCbWJuC6WJ9FKyMj47rnGlrO3Ai73S4/Pz9NmzZNFotFkZGROnbsmN5+++0rljMzZsxQjx49FBQUdFOfO3r0aMXGxjpfp6enKyQkRF27dpW3t/dNnbs0sdlsiouLU5cuXWS1Wo2OA+BPWJ/AjekpqfKSvfpkbZK+OGiRm2+I7mgcoHDf8qpa3r1QPoP1Cbgm1ibgulifgGtibQKui/VZPP6449b1MLSc8fHxkcViUUpKSp7xlJQUBQQEXPGYwMBAWa3WPLcwa9CggZKTk5WdnS139//+IUliYqKWL1+uBQsW5DlHQECAsrOzlZaWlmf3zLU+18PDQx4eHvnGrVYrv8xXwPcCuC7WJ1BwY+9uLC8Pqz5cdUBz1h/RnPVHFODtqeXPdlQFj8L7v1OsT8A1sTYB18X6BFwTaxNwXazPolWQ79ZchDn+kru7uyIjI7VixQrnmN1u14oVKxQdHX3FY9q2bauEhATZ7Xbn2L59+xQYGJinmJGkWbNmyc/PTz179swzHhkZKavVmudz4+PjlZSUdNXPBQAAZZfJZNIL3evrsyei1CqsqiQpOT1TU1cdMDgZAAAAAAAoiQwtZyQpNjZW06dP1+zZs7Vnzx4NHjxYFy9e1MCBAyVJ/fr10+jRo53zBw8erNTUVA0fPlz79u3T4sWLNX78eMXExOQ5r91u16xZs9S/f3+5ueX9G62VKlXS448/rtjYWP3000/avHmzBg4cqOjoaLVu3broLxoAAJRIbWv76Mu/R2vqI5GSpOm/HNTpC1kGpwIAAAAAACWN4c+ceeihh3Tq1CmNGTNGycnJatasmX788Uf5+/tLkpKSkmQ2/7dDCgkJ0dKlSzVixAg1bdpUwcHBGj58uEaOHJnnvMuXL1dSUpIee+yxK37uu+++K7PZrN69eysrK0vdunXThx9+WHQXCgAASo1ujfwVUb2Sth09p682HdXgTuFGRwIAAAAAACWI4eWMJA0dOlRDhw694nurVq3KNxYdHa1169Zd85xdu3aVw+G46vuenp6aPHmyJk+eXKCsAAAAJpNJfaNCte3odn2+IUlPdagls9lkdCwAAAAAAFBCGH5bMwAAgJLozohAVfRwU1JqhsZ9t0s5ufa/PggAAAAAAECUMwAAADfEy91Nz3evJ0mavTZRL3+785q7dgEAAAAAAP5AOQMAAHCD+kWH6YM+zWU2SZ9vOKIvNh656tz45PPKzmF3DQAAAAAAoJwBAAC4KXc2DdJz3S7voJn8U4Jy7fl3z7yzLF7dJv2sBz5aq0xbbnFHBAAAAAAALsbN6AAAAAAl3WNta2razwd19Owlrdx7UgHenlq+J0XubmZdzMrRh6sOSJK2HUnT2G936Z/3N813jpRLUmJqhsL9vGUymYr7EgAAAAAAQDGinAEAALhJnlaLHrolRB+tPqgJP+zRkdQM2XLz7qC5OyJIi7Yd14KtR/XinQ1U0cNNmTa7yrlbtO3oOU343aLxv/+q5jUqa3q/lvKp4GHQ1QAAAAAAgKJGOQMAAFAIHmtbU19uPKKDpy5KklrUqKzyHm7afTxdo+9ooPsjq2vn8XM6eOqi4nal6IedyVq5N0V3Ng3ShUybHLq8W2ZrUpoenrZO3z/dTp5Wi5GXBAAAAAAAigjlDAAAQCHw9/bUB31aaMCsDfKp4KGP+9+iquXd88zp0tBfH60+qGe/2uYcW7TtuPOfX7u7od776YASTl7Qgi3H1CeqRrHlBwAAAAAAxcdsdAAAAIDSom1tH/38wq1aNqJDvmJGkro29Hf+czmrRePvbeJ8bTY59GBksJ7qUEuS9I9vdqjj2z/p532nij44AAAAAAAoVpQzAAAAhSjw/9u76+gorv+N4+/dTbJxdyXBJbhLgWJtqVOnLaXfOm2pU3f3X406FepCCxT34q4xIJCEuBD37Pz+CGxJoRQoTQJ9XufknOzMndk7m70JzLP3frxc8HB2POK+bhE+DGsXyIBWfsy8cyBX9Ynk6xv6EOHjwmXRNsxmE5f3isDdWj+5OSW/nFunbiAhq7gxL0FERERERERE/mVa1kxERESkkZjNJj65rleDbf1b+bPonkHMmjULAA9nR56/OJbftmawKCGHsuo6Xp6TyKiOQUT4uNK/lX9TdF1ERERERERETiKFMyIiIiLNzPldQjm/Syi7ckoZ/vpSFiXksCghB4Cdz52No6V+8nNWUSW7c0vpEuFtn21TW2fjm7WpzI/P4Y4zW9GrhW+TXYfIP1VUUcPDP2/D0WJiTI9wIn1difJza+puiYiIiIiI/GMKZ0RERESaqVaB7nQI8SQu849lzbakFdKzhS/fr0vjgZ+2AtAu2IPvbupHeU0tt321kU2phQCsSc7nk3G92JpeSHFFLed2DqFTmFdTXIrIcSutqmXsx6vZnl7//v9lcwYANwyMZlz/FkT4ujZl90RERERERP4R1ZwRERERacbG9o1s8HjFrnzqbAZvL95p35aQVcKQVxcz+JUlbEotxNPZgR5RPlTV2vjf5+t4eU4i7y/dzYXvriCtoLyxL0HkuNhsBqn55bwwK57t6cX4uztxbucQYvzrZ8x8vHwPZ7yymO/WpTZxT0VERERERE6cZs6IiIiINGOX94ygorqOlPxyvlydwhsLkpi7I4u0ggq8XR35bHxvbvlyA1nFlQB0j/Tmjcu7EuTpzFlvLmNv/h9hTK3N4JdN6dwxrHVTXY7I33p70S7eWJBkf/zWFd3stZbm7sjinUW72JZexKvzkrioWzibUvdTZzNUj0lERERERE4pmjkjIiIi0ow5WMzcMCiGGwfF2LcdXOZsbJ9IukZ48/ukoXx/cz9m3jGQn27tT5SfG86OFp67KBaL2UTXCG9evDgWgGmb0jEMo0muReTvlFXV8vHyZPvjK3tHNAhdRnUM5ufb+hPkaSW3pIrX5ydx+YeruebTtaQXVjRFl0VERERERE6IZs6IiIiInAIi/Vy5pm8U8ZnFdArzwsXJwm1DWgHgaDHTO9r3sGMGtPJn2QND8XF1xGbAkzN2kJxXxherUhjQyp8YfzfMZlNjX4rIEdlsBh8uS6akspYoP1c+H9/7iHVlHC1mru4TxWvzk3h/6W4A6mwGM7ZkcMvglif8/DV1Nhwt+uyaiIiIiIg0DoUzIiIiIqeIZy7sdNzHhHm72L8f178FHyxN5onpOwCYMLQl949qd9L6J3KiqmrrGD9lHSt35wNww6AYWhyoMXMk4wdG8/uuPNbuKbBvm775j3DGMAwWxOfg5+5E90ifI56jps7GE9N3kFdSRbiPK9+tS+X5i2NpE+RBfmk1/h5ORHlbT+JVioiIiIiI/EHhjIiIiMh/xINntcPF0cKbC3YC8O7i3aTvr6BfSz8u7xXZxL2T0923a1Mpr65j/IAWmEwmKqrrcHGyUFlTx8M/b2Pl7nxcnSzcfEZLxvY++vvR3erANzf2Zda2TLxcHLn+s3XEZRazYlceA1r588vmdO7+bgsAo2NDeHFMLB7OjvbjDcPg/h+28MvmjAbnnfjt5gaP2wd7MF5DQ0RERERE/gUKZ0RERET+I0wmE3cNb8PEYa254N0VbN1XxC+bM/h1SwbdIn1oE+TR1F2U09TG1P08+PM2AJwdLVjMMOmnbbQJcqeooobs4irMJnhvbHeGtA08pnNazCbO6xIKwCU9wvl2XRoTvt7I/13RjWdnxtvb/bYtk+S8Mqbd1h9nRwtQX3vpl80ZOJhNODtaKK2qJcCjvo6Nk8VMtL8bKQVlxGeVsMjBxEUn+fWQf19NnY3UgnLCvF3sP/djVVRew6rkPEZ0CMZymiz9WFZVywdLd2N1tHBht7AGsypFREREpGkonBERERH5jzGZTNw7si3jp6zFZoBhwCtzE/no2p5N3TU5DRmGwQuz/ghLHp62zf59UnYpAIEeVp65sNMxBzN/9uT5HYnLLGbrviLGfboWgNaB7jx/cSw3frGe+MxiliblMqpjMIXl1Tz7W31/7h7RhrM6BbMjo5gz2wUyZ3sWfWN8Cfdx5betmUz4eiNz9lno8dwiRnQIxtPFgd4tfCmurMHf3cqw9kEn+rLIv+yZmXF8sSoFq4OZt67sxqiOwcd87P0/bmFeXDa3DmnJpLNOj6Uf/2/hTj5clgzAlBV7mXf3Gfi6Of3tcYZhkJxXRllVLe1DPFWXSUREROQkUjgjIiIi8h80uE0AS+8fSlFFDee/s5z5cdl8tSaFsX2imrprcprZll7Eur37sTqY6Rbpzerk+joxbk4WnrmwE4EezvSI8sHF6fhmNxzK2dHCF9f35o5vNvH7zjy6hHvx5hXdiPZ348KuYXy2ci+L4nMY1TGYKSv2UlBWTZsgd246IwZHi5mWAe5A/Qycg86JDaZPtA9r9uynuLKWnzbuA+pvbB/06Oj2XN4rosGSadL0DMNg3o5sAKpqbUxesvuYw5nduaXMi6s/dvKS3WzYu59bh7RkaLsTCw6bg5ySSr5Ytdf+OK+0ipu/XM8Ng2KO+roUV9Yw6cetzN6eBdQHnh9e25NofzeSc0uZfSDM7BHl+29fgoiIiMhpSR97EREREfmPivB1pVOYF3cPbwPA47/uYGd2SRP3Sk43y5JyARjSNoCPx/UiNswLgCfO78jF3cMZ2Nr/HwUzB3m7OvH5+N7Mu/sMfr5tANH+bgCceeCm+uLEHMqqau03qe8c1vqoswBMJhOfjevB491q+XJ8T24Z3JJr+0UR6uVsb/Psb/EMfGkx29OL/nH/5fjM2Z7F0zPiqKypO2xfemEFWcWV9seb0wpZnZxPWVXtUc8Zl1HMI4fM7AJYu7eAm7/cwPq9BSen442spLKGO77eRGWNjW6R3vw6YQAWs4l1e/dz85cb+GnDviMeV1Nn48bP1zN7exYOZhNuThZ25pRy/jvLWZyYw53fbuKVuYmMmbyKl+ckNPJViYiIiJweNHNGRERE5D/u9jNbsSF1P0sSc/lqTSpPnt+xqbskp5FlO/MAGNQ6AHerA9/f3I+4zGK6R3qf9Ocym02H1U7qE+OLq5OFnJIquj09n+o6G5G+rpx1DDMpHCxm/Jyhb4wvg9rWL2H29AWdMAyD95bs5otVe8kuruLZ3+L45sa+mEynR32S5u7XzelM/HYzAAEeVq7uG8mevDIKy2toH+LJhpT9AHQJ9yLI05l5cdlc8eFqAPq39OPL//XBYjaxfGcebyxIIim7hBZ+bsRnFlNrM7CYTbx/dQ82pu7n103pZBRVcutXG1lwz2C8XJrfLCmbzSC/rJoAD6t925ztmezbX8G0TensyCjG3erAk+d1pEtEfUDzyfI9TNuUzqO/bKdnCx+i/NzsxxqGwRPTd7BmTwHuVge++F9vwr1duPWrjWxI2c/4KesaPP97S3bTOsidi7qFIyIiIiLHTuGMiIiIyH+cyWTiuv4tWJKYy7RN6Tx4drvjLqAtciQllTVsPHCjfHCbAABcnCz0iPJptD5YHSyc2zmE79fvo7rOhrerI89e2AmHf1A7w2QyMWFoKy7sFsbQV5awOrmAm77cwJ1ntiY23Osk9l7+LKOwggd+3Gp//NKcBF46ZOZGhK8L/WL8AOgR5cuojkEsTMihzmYAsHJ3PtO3pJNZVMnLcxLtx207MPtpRIcg7jizFZ3Dve3fn/vWcpLzyhj++lLCfVzYnVPK2Z1CePDsdvgcQ92WZ2bGkVtSxWuXdfnL2Vrb04uYuTWTMd3D2JZexPb0Yoa0DeCMA+PmUJU1dTz401ZCvF24olcEd3+3mY2phVzbL4p7R7QlbX85t0zdaG/v5+bE59f3ptOBWWudwrx49dIuZBRWsGZPAZ+t3MsT5/0Ryj/7Wzxfr0kF4PXLutA9sn68fnNjX277aiML4uuXfRvTPRx/Dyc+WJrMvd9vISGrhIu7hdM2uGFAKiIiIiJHpnBGRERERBjUOoAwbxfSCyv4eWM6V/WJ/Mu2e/LKcLSYCPN2OeJMgaLyGjycHTCbNYvgr+zOLcXJYibc58iv4eniu3Vp1NoMWvi5EuHr2mT9eOHizlzeK5Ls4koGtvbH8yTViAnzduGWwTG8tWgX8+OyWbkrj8+v703PFqrB8W95fX4SVbU2ekT5kF9axd78cgD83a3klVaRVlBBWkH9Ul09W/jQJ8aPrU+MxNFi5p3Fu3hr4U7u/m6L/XxX943kil6RrNiVR7CXM+d3CW0wJl2dHHjuoliu/Gg1uSVV5JZUAfDd+jQyiir44vreRx3Dm9MK+WT5HgDO6xLKiA5B9n2rdufz7G9x5JdW25dhe3/pbvv+nzftY+3Dw3FyaBjoPP7rdn7ZnAHA12tSKaqoAeCLVSl8sSqlQdtukd68dmkXYg7UVTrIYjZx65CWrNlTwI8b9nH/qLa4OjmQml9u7+/Ll3Rm5CEzzJwczLx2aRfOeet3MosqGD+gBe1DPCksq+G79Wl8sDSZKSv28uuEAbQP8fzL10RERERE6imcEREREREsZhPjB7Tg2d/ieW1eIqNjQ/Byrb+BXVJZQ0FZNZG+rny1JpVHf9kOwKiOQbw3tgeWQ0KY79el8fC0bXQI9eSavlHklFQR5OnMRd3CGrQ7HRWWV5OcV0a3CO+j3qz9ccM+7vuh/ubwsHaBfDyu52kX0GxJK+TzVXuZfuAG8vUDo5u0Pxaz6V+brXP3iDYMbhvAq3OTWJWcz8RvN7Pk/iFHrWcjJyY+s5ifNtYHL4+d2wGLycTU1Slc0jOcXi18+XZtKg/+XF8zJtLX1T7rxM1a/9/em8+I4es1qeSV1gcsdw9vw8ThrQHss0qOpF9LP964vAtb9xUR5u1CTIAbt07dyO878/h+fRqX92oYZqcXVvDcb3EUlFWzOvmPWjU/bdjHgFZ+xGUUM3NrJp+t3HvE5wv3cWHf/goKy2tYkpjTICCZtyOL79f/USemqKKGFn6uTBjaiveX7mZ3bhkAjhYTC+8ZQqTfX4eiZ7QOINLXldSCcr5dm8aQtgH2YOaMNgFc1jPisGO8XB2ZfvsA8kqr7TNkXrg4ll7Rvny5OoUtaYXc+c0mpt8+sEEtqYrqOpLzSqmutRHt74a369/POBIRERE53SmcEREREREAxvVvwbfr0tiVU8qTM3ZwftdQiitqeHF2AplFlUT5uZJ9SJHtuTuyafnwLPzdrdwwKBo3qwOP/7odw4Ct+4q4/5ClhxbGZ3PvyLa0CnQ/0lOf8nbnljL2ozVkFVcyskMQD57d7rBPqgPs21/Ok9N32B8vTMhhVXI+/Vv627elFZRz6furGNUxiKcu6HRMz28YBiaTiTqbwe7cUoK9nO2zQ0qraqmzGY1SK+ObtanM3p7Fil159mWkzu0cwjV9o/71524qJpOJHlG+fHJdT854eQnphRX8simdS49wY1tOTFVtHVYHCy/NScAwYHTnELpGeAPw0iWd7e0u6RHOgvgcyqpqeePyrrhbG/53183qwI+39GPLvkKi/d3oHO59zH24qFt4g5oq94xowwuzE3hr4S7GdA+3L5NnGAYP/rSV3w/UWjrU3LgsOj2RxYGhAcCVvSPZmV3C3vxypt7QGwezmWh/N16ak8CHy5L5fn0aw9oHYTGbqKyp49nf4gG4pm8U8+KyKCyv4Z2rutMpzItLe0aQml/O12tTiQ3zOmowA/U1mm4cFM1jv+7g6ZlxPD3zj31X9f7r96+fuxU/9z/q25jNJi7pEc6QtgGc/X+/szOnlGd/i+PZCzuRXVzFtvQi7v9xC4Xl9TN8XJ0sPHROexbFZ7M5rZA2QR7cM6INfQ4sRyciIiLyX6FwRkREREQAcLSYeeHiWC7/YBXTNqUzbVN6g/0pB5YPGtjKnzE9wuxLA+WVVvHi7D9qPlzeM4LCimr2l9UQ5uPCzK0ZzN6exeztWTxxXgfGD2jaWRQnW0FZtT2YAZgXl828uGxuG9KS+0e1paiihuo6G4Eezry7eBelVbX0jPKhbbAHX61J5ZW5iTxzgSMJWSWc3yWUr9akklVcyZerU7h5cEtCvV2O+LyfLt9DUUUNJZW1fL8+jXNig1kYn0N+WTXtQzy5dUhL3lu8i4SsEgCeubDTvxqSxGcW8/C0bRgHbjyPjg1hTI8wBrcJPO1mBh2Jq5MDNw6K5oXZCby3ZDcXdQv7R3VtpN5nK/bw5Iw4OoV5sj29GAeziftHtj1iWweLmY/H9Tzq+Vr4u9HC3+0f92tc/xZ8uCyZ9MIKZm/P4rwuoQBMXZNqD2buHNaazWmFtA/2YM2eAjanFWIAQZ5WYsO8GNs3iqFtAwGorbM1eL9c2DWMD5clsyA+hxGvL2Xi8Nb8sH4fqQXlBHlaefDsdkwc3pqqWhthh/yOiPRz5cGz2x3zdYztE8WcHVms2JX/xzl8XRnWPugoRx2Zv7uV1y/rwjWfrOWrNfVBbUFZtX2/t6sjDmYzeaVVPHZgBibAmj0FXP/ZOn6fdCa+x1DDR0REROR0oXBGREREROx6tfDlnhFteHVeEh7ODgR6WAn1duGFi2PZnl5EQlYJ1/SNws/dioujA7U2G5U1Nt5ckMS+/RVc178FT5zXocHN+Mt7RfDmgiRWJxfw4uwEzmwXSJTfsd8cTSuo/yT45T0jTspN1X8qp6SSF2cnsGJXHu5WB+psBlnFlcQEuPHMBZ2YsmIPC+JzeG/JbrbsK2RjSiGOFhPTJgxgxpZMAO4b1ZYWfm78tHEfm1ILOfft5UD9zJMNKfsBsBn1j+89wo3ojan7eXpmXINthy51FJ9ZzJ3fbGqw/6npO2gV4E6/ln//6fQpK/awanc+z1zYiSBP579tX1pVy3O/xWMY0CrQnZfGdP7XlhFrzsb2jeKDZcnsySvj+/X7jlq7Sf5eVW0dby/aBcD29GJMpgNjpxn8HnB2tHBNvyjeXLCTF2cnsCghhw0p+0ktqA+xD10yDSC/tIq4zGLaBHkccUz9OcjrEOrJI+e05+1FO0nOK2Pit5sBcHG08NKYzrhZHezLtf0TZrOJt67oxifL9zC0XSAB7la8XBxPeFm+Qa0DeOjsdrw2L4mCsmosZhNuThbO7RLK4+d2AODi91YSl1lM72hfJp3Vlkd/2UF8ZjEfLNvNQ2e3/8fXJCIiInKqUDgjIiIiIg1MGNqKfi39iPF3x+eQTzGH+7hyVqcQ++OzOv1RB+H8LqHs219+xKW8+sb48c2NfRn78RpW7s5nzOSV3DeyLZf3ivjbGRUbUgq46YsN5JdVk5pfzrtju5+EKzw+NpvB0zPjKKqo4dp+Ubw2L4nlu+o/GZ9Nfe0KJwcz71zZnQ6hngxo5c/369J4aNo2+6fRK2pg2GtLAYjyc6VPtC8mk4lPxvXili83UFJVi5PFbA9mDvpiVQoXdA07bDm4dw/csD6oQ4gn7s4OnN8ltMHSRxd2DeWJ8zry6K/b+W1rJtd+uoZHzmnP2L5RmE2mw+oA1dkMckuqeGpGffCzPb2IXyYMIPAoAU1KfhljJq8kr7QaB7OJj67tSXQzuHneFNytDtxxZiuemhHHGwuSuLBbKK5Oze+/XCWVNXy2Yi/9W/nTNtgDB7MJZ0fL3x/YyOZszyL/wMyL6wdEc05sMD1b+DZxr/4wrl8Lftywj337KxrMNLzzzFbcfmarBm393K0Mah1wXOe/8YwYrugdwctzElmVnE+7YA8mDmtN6yCPk9L/Q/v2wFnHPtvm79w8uCVX9IokPquYjqGeeDg3XFLxm5v6sjo5n8FtAnB2tHDfyDb87/P1TFm+lyhfN67sHUF2cRWTl+wi1NuFS3qEN1hGTUREROR00fz+pyAiIiIiTepgDY3j4eRgPmIwc+g5X7y4M9d+uoa9+eU8+PM2libl8s5V3Q8LCADW7y1g1rYspq5JobrWBsCynbmHLf1zMlTV1vHCrAQCPKzcfEbMYef/am2qvXD3wRuwjpb6EMLRYiatoJx2IZ50CPW0H3NZrwi6RXozecluiitrWBCfY993Sfdweyg1oJU/8+8ZTG5JFS5OFp6ZGcfSpFzuPLMVS5Ny2bKviHPe+p0OIZ58eG0PAj2c2ZNXxsKEHMwm+Gx8b8wmEwNa+dnPWV1rY/muPCwmEy+O6Yyzo4VXLumMYRjM2pbFkzPieG5WPH5uVmbeORD/Azc9U/LLuOLD1WQW/VFXKKOokjcWJPHCxX/U9fizN+YnkVdaTYSvCw+f3f4/G8wcdFWfSD5dsYe0ggo+WraHcf2jDit+/uzMOFbuzuez8b2OGnz9W56dGc9369N4bX4SAM6OZs7vEsozF3bC6tA8QpoNKft5+kBIeO+INtwxrPXfHNH4fNycmH77wPpaW8CVvSJpGehGiNeRlyI8ER7Ojjxz4bHVnmpOvFwd6fsXNWS8XBwZ1fGPcP/MdoGMjg3ht22ZPDxtGwvis9mRUUR2cX34/e26NObcNeikvzcziyqwmE0EejT+GBQREREBhTMiIiIi0kgi/VyZf89gpqzYw6tzk5i9PYtPlidz0xktG7T7YOluXjxQ+BtgZIcg1u0tYH95DaPfWs7V/aKOu3ZKnc3g6Rk7WLOngEBPZ96+shteLvWf5n51bqI9fFm3t8AeugDkllTx8iH1dA66vFcEQw7UivgrrYM8eP3yrkB9gDE/Lpve0b5cN6BFg3bBXs4Ee9XfHPz8+t6UVtXi5mThugHRXPPJGnZkFLM5rZCnZ8RxVe9INqUVAvXBzhltDv8kvpODmc/G926wzdXJgXev6s6UFXt5flY8NXX1S7G9ODuBVy/tQkllDRO+3tggmLllcEveX7qbH9bv47YhrQj3qb/hfDAEstkMZmzN4NctGQBMHtuDTmFeR31N/gusDhbuG9mWid9u5o0FSbyxIImPr+3J4LYBOJhN5JZU8emKPdgMeG1eUoOC9scqMauE79enEeXnSkllLaM6BtEq8NhmU+zKKeGHDWkNtlXW2Ph+/T7Kq+v4vyu6HTEw/SeqautIzCohNszrL2fLGYbB7txSVicX4G514LFft1NSWUvHUE+u7d/ipPbnZPJ1c+Kdqxp/Rt/pxGQy8faV3egU5sWr8xJZlFAfZrcMcKOoopY9eWW8t7i+jlNNne2kzByKyyhmzOSVODuamXPXGce0fKOIiIjIyaZwRkREREQajaPFzE1ntMTT2ZEHf97Gq3OTOKNNAMUVtTw5fQdxmcX2tqNjQxjZMYjzOody9/eb+XVzBonZJTz2y3bOjQ1psOTa35m1LZPPV6UAkJBVwi1fbmDK+F5sSNnPR7/vsbdbkpjLS7MTePRAbYR3F++ipKqW2DAvfpkwgJ827GN1cj73jDhyQfK/cveINtw9os0xtXU/UEfC98Cn8n/blsmd32xi5tZMZm7NtLcb1u7o4dCfmUwmrh8YzfldQ1mWlMs932/hxw37yC6uJCGrhNySKvt5I3xdeWBUW3ZkFPH7zjyu/2wdBWXV9IjyYfLVPTAB9/6wxT6T6OxOwQpmDnFe51CmrNjL5gNB2g1frMfF0cKYHmFE+bphOxA8fr8hjfEDW9Au2JOCsmocLabDloD6s4Kyaq6bsrZBkPbThn3Mv2cwFrOJ8upatqQV0TvaF4vZRGVNHU/8ugMDgyt7R/LAj1uxGfWh59MXdMLBYmJzaiG3frWBmVszqbMZXNYrgkGt/P/xLLWq2jrqbAaTftrGjC0Z3HlmK+75Uw2lndklfLUmlUUJOfZ6LQd1jfDm6xv7NMul4eTkMptN3DqkJX1ifJm3I5swb2cu7BbGnO1Z3P/jVv5v4U7+b+FOAD64pkeDmTfHKrOogpdmJ7A9o5hdOaUAVNTU8fDP2/h4XM+/XWZTRERE5GTTv3JFREREpNFd3iuCBfHZLIjP4aw3f8fVyUJ5dZ19/wNnteW2IX/UbBjWPohfN2fYH782P5EeUT6Mjg0lt7SKUC/nw26sGYbB3B1ZLNuZx9drUgGICXAjo7CCVcn5nPf2cnYeuEF3VZ9IBrcJ4OYvN/Dx8j10jfQGsB836ax2WMwmLusVwWW9Iv6V1+RILGYT53cJZUliDj9vTG+wb1j7oBM6p7+7lYu7h7Mrp5T3luzm95319XNa+Lny+uVd6R7pY2/7xHkduOyD1fbXaV5cNk/N2EFpZS3TNqXjYDZx25CW3Dy45RGf67/KbDbxxf96s25PAf/7fD1QfxN46upUDr5NfVwd2V9ewwuzEpgwtBVXf7KG2job7lYHwnxc+ebGPocth2azGdz13WZ7MNMjyocNKftJzitj9vZMRseGcN2n61i7t4DRsSH0jfHlt22ZrE4uAOD79fsACPZ05rFzO9hnbA3vEMT/XdGNid9uYvb2LGZvz2JYu0A+vLbnCc2iMQyDdxfv4sNlyRRX1tq3v7VoF53CvBh+4L37/rLdvDo30R5WOVnMxIZ7sSl1P+5WB96+spuCmf+Y7pE+DX4HjekeTlxmMb9sSmd/eQ0AT8+IY1BrfxyP8tZMzCoh3McFtwNht2EY3PXtZtbsKbC3CfVyJq+0moUJOaxP2U+HEE97exEREZHGoH95iIiIiEijM5lMvHBxZza+uYyCsmp7MNMjyodh7QMbBDMA58aGUFpZy8bU/fy4YR9TV6cydXUqj07bTll1HdcPiMbLxZEuEV725cbeWLCTtw580hrA09mBabcNICGzmJu+3GAPHKL93Xh0dHtcnRy4YWA0Hy/fw+1fb7IfN6CVHwNaHbl2QmN5eUxnrh8QzafL9/DzpnTCfVyI8HX9R+d84Kx2nNs5lJW784j0deWMA8W5D9Uq0INvbuzL87PiyS2pIi6zmC8OzEACeHFMZy7pEf6P+nG68nR2ZFj7IPrF+LEqOd++3TDqZ0d9Nr43YyavZGlSLkuTcu37iytrKc4s5t3Fu3hkdAf7dpvN4LX5iSxLysXZ0cwvEwbQLtiTN+Yn8X8Ld/Lq3ETSCipYu7f+5vNv2zL5bVv9TCtnRzNtgjxIyi6hW4QPL1wce9j755zYEHzdnPh0+R6WJuWyMCGHl+cmcP/ItszYmkFheQ3X9W9x1NkF8ZnFfLM2FVcnB95furvBvgAPK7klVdz05QYAwrxdSC+sAOpn8VzSI5wBrfxxszqQXliBo9nUJPV4pHkxm008cV5HHj+3AxU1dYx4fRnphRUMf20pb15+5CUB3164k9fmJzGiQxAfXdsTgIXxOazZU4DVwcy7V3XHycFMx1BPXpydwA8b9nHp+6uwmE1MHNaaOw/UN1qUkM2+/RVc0CUML9ejz2gTEREROREKZ0RERESkSQR4WPlkXE9mbs0k3MeFy3pG/OWnls1mU/3slrYB/Lih/tP/FrOJsgOhzqcr6pcmszqYWfbAULxcHPn8QB2ZS3uE42AxMbJDMF4ujvSJ8WPG7QP5fn0ahRXVXNe/hf3T+ZPObsemtEI2pOzH393Klb0juGFQTJMvd+NgMdMpzIvnLoolys+NwW0PrzVzIjqEetIh1POobdoGe/D59fU1bL5dm8ovm9NxtJi548zW9I72PSn9OJ09fUFHnp4Zx5ntAnlhVgJWRzMfX9uTLhHejOvfgk+W1793WwW689G1PVkYn82zv8Xz+coUrhsQTZi3C+XVtVz7yVrWp+wH4JkLOtEuuP7nNn5AC75bl8be/HJemlNfH6lnlA8OFhPuVgei/d24oGsYncK8MAzjqO/lvjF+9I3x49fN6Uz8djMfLE3mg6XJ9v2h3i725aTySqtwtzpQWVPHF6tSDhRxL6bu4DQY4H8Do/F3t7Izu4RHRrfn4WnbmLsjG8AezJzRJoAPD9xAPyjM2+UfveZy+jGZTLg6OfD6ZV2445tNZBRV8sxvCdwQCVU1dSTmlOPt6siWtCJem58EwPy4bPbtLyfcx5UPltWHheMHRDO8wx+zDi/vFcEPB/6m1NkMXp+fxK+b02nh58bCA7Vv3lywk18nDCDC15WyqlqenhFHp3Cv4659dqJsNgOTiSb/OyQiIiInn8IZEREREWky3SJ96HbIEjZ/J8zbhRcujqWgrJqLu4exKbWQpYm5fLe+vsB5Va2NV+Ym0iXci6KKGsJ9XHhxTOfDlmaK9HPlvlGH141xtJiZ+r8+bN1XSLdIH5wc/lnNjZPNxcnCxOGtm+z5r+gdyRW9I5vs+U9FrYM8+PJ/fQAY3CYAb1cnfA/US3rw7HYMaOVHbkkVQ9sGEujpzP8GRrMgPpvVyQXc891mSipr7bWYPKwO3DeqLZf2/GNpPW9XJ765qS9Xf7yG3NIqLugSyjMXdjpsFhQc+83dC7qGsTO7lHcW72qw/flZ8czdkYW/u5WPf0+mc7g3ZVW19lloUL9UVEZRJf7uTtw9oo29hhLA21d25+eN+4jPLLbXgLrjzIaz5ESOpk+MH7MnDqLfC4vYll7MRlcTL7y5nKziKixmU4NwEOCH9fu4snck6/bWB5vj+jcMVHpE+RAT4EZybhktA9xIzitjd27910EFZdVMXZPC/SPbcsvUDfy+M4/v1qdxYdfQv60RdaKqautYkpjLjxv2sSA+m/bBnjx6bnv6t/T/V55PREREmobCGRERERE5pVx5SDgQEuvCyA5BDG0XSHWdjTu/2cSPG/bZZ9dc1SfyuGtmuDhZ6BPTtMuYyekpJsC9wWNHi5kz2zWsHWQymbhxUAyrkwsa1McwmeoLofdvdfjN2Wh/NxbeOxjgiKHMibhnRBsCPKxYHcy0DvJgzOSVpOSXk5Jfbm+zOa0QAF83Jx46ux29WvgS4u3M9+v30buFb4NgBsDJwWwP91oFeVBXZ6NXC82+kuPj527lrE7BTN+Swec7LUAVgD2YsZhNPHFeBx7/dQdfrfmjzlPPKB9CvBrOyjKZTLx9ZTdW7c7n6r5R5JdVszghh2dmxhHq7cKEoa2474ctfLA0mU2phaw9ZEwuSczlvC6h7C+rZmlSLiM7Bp2UGklztmfy9Iw4Mg7UlgKIyyzmuinrmPq/PpqxKCIichpROCMiIiIipzQHi5mzOtUvtZRfWsVbC3dSUlnLeV1CGd8/uol7J3L8DtZNOig2zIuLu4cdMZg56GSFMgeZzSbG9W9hf9whxNM+gyfQw0pBWTW1B26GTxzWusFsnmNZ7qmxloSS09O4/i2YuTUDmwHtgz14d2x3znxtKQCjY0O4vFcEn63YS3JeGW8uqK89dk5syBHP1THUi46hXkD97Myr+0ZxYbcwLCYTDhYTL86OJ6+0mrV7CnB1shDm7cLOnFJmb88kJsCNW6ZuIK2ggmHtAvl4XE9MJhPLknIpqazlnNjgBjPWErNK+H1nLoGezpwbG4L5Tx8eWLkrjwlfb6LOZhDgYeX8LqGc1yWUdxbtYkF8Njd9uZ5F9w6xz74TERGRU5vCGRERERE5bYwfEM3VfaOorTNwcTq5N6tFGovFbOL/rujKMzPjefmS2MNm1zSF5y+OZeaWDG4Z0hJ/dytlVbVc9N4KnB0tDWaziTSGHlE+zLtrIIsXL+Gai/ribHXi6xv7MHV1Cg+d0w6rg4XnLorlyo9WA/XL7V3QNfSYz3/orK8JQ1vxytxEBrX25/5RbSmprOWi91Yya1sWs7dnYRxYSW1hQg4/bNjH8p15TN+SAcArl3QmxMuFPjG+zNiSwX0/bOHgymtTV6XQLdKbm86Iwc/dSmp+Obd9vZE6m8H5XUJ5+ZLO9tD1nau6ceG7K0jIKuHlOQm8OKbzSXgVRUREpKkpnBERERGR04qjxcxJnkQg0ugu6BrGBV3Dmrobdl0jvOka4W1/7GZ1YN7dg5uuQ/KfF+XrSqAL9qUr+7f0b1CTpV9LP96+shsFZdWM6RF+2DJ7x2r8gGjGD/hjFqbNZjCglR8rduVjGPUzdUK9nfno9z08Om071XU2e9v7f9wK1C89uDe/DMOAXi182LKviLV7C1i7t4BlO/MY0NKPOTuyKCyvoUu4V4NgBupnxj1zYScufX8V365LI8TLhTuHtcJkMlFda2t29dFERETk2CicEREREREREZHTznldjn22zLEym018dUNfMgorsBkG4T6uVNfamLUti/TCCgBuGdySWdsySS2or9G0J68MgOsHRPPo6Pbszi1lUUIOHy5LJj6zmPhDlgz84JqeR1ymsFcLX+44sxVvL9rFGwuSiPB1wcnBzKQft9KvpT+Tr+6Oo0UhjYiIyKlE4YyIiIiIiIiIyHEI9Xaxf+/kYGbi8NY88ONWvFwcuW1oS67pF8XaPfm0CfJg6upURnUMsteTah3kQesgDwa1DuDNBUmEeDnTMdSLYe0D8XO3/uVz3juyLSaTibcW7uSe77fYty+Iz+bxX3fwwsWx/94Fi4iIyEmncEZERERERERE5B+4pHs4VTV1dAj1xNPZEU9nRy7qFg7wl6FJh1BPPry253E9z21DWvLThn32WTrD2weyID6H79alcv+otvi6Of2zCxEREZFGozmvIiIiIiIiIiL/gNls4pp+LegR5fuvPo+zo4U3Lu/KkLYBfHBNDz4e14v2IZ7YDFickPOvPreIiIicXJo5IyIiIiIiIiJyiugd7Uvv6N72xyPaBxKfWczChGzG9Ahvwp6JiIjI8dDMGRERERERERGRU9Sw9kEALE3Mpaq2rol7IyIiIsdK4YyIiIiIiIiIyCkqNsyLYE9nyqrrWBCnpc1EREROFQpnREREREREREROUWaziTE9wgB4aU4C36xNZUFcdoNZNHmlVSRmlTRVF0VEROQIFM6IiIiIiIiIiJzCLusZAUBqQTkP/byNG75Yz/O/xQNQZzO44sPVnPPW72zbV9SU3RQREZFDKJwRERERERERETmFRfm5cXanYEwmiPF3A+DrtamkFZSzKCGHXTml1NkMPl2xp4l7KiIiIgc5NHUHRERERERERETkn3nrym5U1NTh6ezI1R+vYfmuPO77YQuVNX8sbzZtUzomoFe0L8PbB2EYBlZHC14ujgCUV9fy6+YMhrcPIsDDCkBlTR3l1XX4ujkdc1+WJuXi4mihd7TvSb3G/6JNqfuZsz2LO4a1xt2q23giIqcT/VYXERERERERETnFOVrMOFrqF0iZdFY71r2/kjV7Cg7sMxHl58aunFJ+3pTOz5vSecy8nVqbQYiXM3MmnoGLk4Wbv9zA7zvzmNYine9u7su369J4bV4iJZW1fHdzP7pGeANQWlXLo9O24Wgx89KYzpjNJns/liXlMu7TtThaTCy6dwgRvq6N/locK5vN4PNVe4kN86Jni+YXJFXV1nH715tIL6zAZhg8MrpDU3dJRE4R7yzayS+bM3j3qu60CXJnxa58Yvycm7pb8icKZ0RERERERERETiOx4V7MuGMgT07fgZvVgRsHxRDi5cz0LRkUVdSwOjmfrQfqz2QWVfLy3AQqquv4fWceAGv3FtDusTlU1drs53x+Vjx3ntmazWn7+WVzBrtySgG4oGsYA1v7A5BeWMEDP24FoKbO4P8W7uTVS7v8a9e5fGcet0zdwH0j23DdgOjjPv6bdak8NSMOgN3Pn4PlkJCpOfhuXRrphRUAfLEqhRsHxRDoqZurInJ01bU2Xp2XBMDF763glsEteW1+Eu2DPbipRdP2TRpSOCMiIiIiIiIicpppE+TB1zf2bbBtwtBW9u+Tc0vZll7ExG8389WaVAAsZhND2wawID6HqlobFrOJq/tE8uXqFNbuKeDqT9Yc9jxTV6cQ7GXljQU7WbU7n4KyaoI8rWQXV/HTxn208HNlwtBWmEwnN/iw2Qye/S2O0qpanp+VQJiPK10ivAj0OHJ4YRgGgL0fhmHwye9/1OBZsyef/i39T2ofj1dlTR1TV6fQI8qHrKJKXpiVAICbk4Wy6jpenJPA65d1PebzGYZBUUUN3q7HviSdiJz6Vifn278vq67jtfn1QU18VglbPEyc21Qdk8MonBERERERERER+Y+JCXAnJsCdlPxyJi/ZTWVtHS9cFMsF3UJ5b/FuTCYY1i6I2HAvfN2svLEgiQhfFzqHe9M32peWge5c9dEa5uzIYs6OLPt52wZ58On4Xny0LJnPVu7l1XlJRPq5cX6X0JPa/9+2ZZKQVQJAdZ2NG79YT6iXM4vuG4Kzo6VB2+paGxe8uwKbzWDGHQNxcjCzNCmX5Lwye5urPlrDyA5B9Ijy4aJuYcc0QyWvtIqc4irS9pezKbWQjan72VdQztB2gUwc1vqYzmEYBrU2A0eLmf9buJPJS+pf+wNZEoPbBHDbkJZc+dFqft6YTv+W/lzSI5yaOht1NoMliTm8tXAX7UI8uGdEG8J96peRq62zMfHbzczenslDZ7fnxjNiGjxvQVk1W9IKGdwmoMGydCJy6psXV/87uXcLX3JKKtmbX46Lo4WKmjpmppmZWFWLj6PjCZ/fZjNYvSefbfuKaB/iyRltAk5W1/9zFM6IiIiIiIiIiPxH3TmsNf8bGM3+8mr7jf27R7Rp0Gbi8NbcOqQlTg7mBttHdQxi7o5sAKL8XHn83A4MaOWPs6OFJ8/viLOjhfeX7ubDZbs5r3PISZs9Mz8um/t/3ALAWR2DWZqUS0VNHRlFlUxZsZcz2wXSNtjD3n7ujiziM4sBWJWcz+A2AfbZQq0D3dl5YIm2eXHZzIvL5tV5ibx6aRcu6BrW4HnrbAZ78kopqqhlQXw2Hy1LptZmHNa/r9aksio5n59v7U9CVgmllbUM7xB0WLtFCdk8MzOe/NIq3r6qO58sr5/JYxhgNsENg2J4YFRbHCxmbjwjhg+WJnPfD1tYv7eAzWmF9nAKIC6zmMSsEqbfPhCAh37exm/bMgF4blY87s4ODGsfyO9JeVTU1PHOol1kFVdyy+CWPHh2uxP7QYhIs2OzGSyIywHg1qEt6RHlw8L4bHpH+3HxuyvILqni4Wk7eO/qHif0O9lmM7jj2038trX+98ulPcIVzvwDTR7OvPvuu7zyyitkZWXRpUsX3n77bXr37v2X7QsLC3nkkUf4+eefKSgoICoqijfffJNzzjnH3iY9PZ1JkyYxe/ZsysvLadWqFVOmTKFnz54AlJaW8uCDD/LLL7+Qn59PdHQ0d955J7fccsu/fr0iIiIiIiIiIs2Jm9UBN+vRbxH9OZgBePvK7ryxIImVu/N58eJY2od4Nth/0xkxfLZyD9vTi1mzp4C+MX4n3EebzWBHRjGvz09kcWIuAEPbBvB/V3bFMOCLVXt5flYCL82p/xrdOYRXL+mCi5OFqatT7Of5YOlu1u0pYH5cfaj0zlXd+b+FSZRU1tK/pT/z4rLYlFrI/T9uJdLXlW6RPvZjH/t1O18fCHUO8nd3wt/dSrdIb7pF+ODn7sRjv2wnObeMfi8soqKmDoCnL+jI1X2i+GnjPn7YsI8oX1embUq3hzs3fL6OmjqDAa38uOmMlgR5WmkX/Mfred/Itpgw8eGy3Xy7Lu1PfbBSUV3LjoxirvpoNWaTiVXJ+ZhNcGa7QBbE5/DQz9uO+Lq+v3Q3A1r5Mai1bq6KnA62pReRVVyJm5OF/i39sDpYuKhbOABvX9GFKz9ew+wd2XyyfA83DIr5y/NU1daxfu9+ekT5NJiN+PaiXfy2NRNHi4kRHYLoFe37r1/T6axJw5nvvvuOe+65h/fff58+ffrw5ptvMmrUKBITEwkMDDysfXV1NSNGjCAwMJAff/yRsLAwUlJS8Pb2trfZv38/AwYMYOjQocyePZuAgAB27tyJj88ff0zvueceFi1axNSpU2nRogXz5s3jtttuIzQ0lPPPP78xLl1ERERERERE5JTm5GBm0ll/PevC182JMd3D+WpNKh//vueYwpnv16dRWVPH2D5RWMwmqmrrKCir5qqP1rDnwDJkjhYT1/VvwX2j2mJ1qL9peFWfKD5Ymkx+WTUAv23NpEOIJ/1a+rFmT4H9/Ct357Nyd309ht4tfGkb7MF7Y3vY9998Rgy3TN3AvLhsHvt1O9/f3I+3F+1iQVy2fYaNj6sjncO9uaJXBGfHhhx2DWE+Llz36Tqyiivt256aEceSxFwWJdR/on3tgT55WB0oqaqlps7AbILHzu3QIJQ5yNFi5sGz29E+xIO7vtuMo8XMZT3DMWHi3pFt+GH9Pp6bFW+/Vgezif+7ohvnxAbzyC9/hEqxYV4UlFVTXl1Lzxa+zI/L5pFp25l39xmHLQcnIqeeg0uaDWkbaP/9eFC3SG8uamHjxz0WXpidwMDW/ni5OPLAj1s5r0sol/WMAOqXgrz+s3Ws2JVPtL8beaVVnNs5hMFtAnhjQX39mucujOWyXhGNe3GnoSYNZ15//XVuvPFGxo8fD8D777/Pb7/9xqeffsqDDz54WPtPP/2UgoICVq5cieOBdfFatGjRoM1LL71EREQEU6ZMsW+Ljo5u0GblypWMGzeOIUOGAHDTTTfxwQcfsHbtWoUzIiIiIiIiIiInyfUDo/lqTSoLE7JJzi0lJsD9L9suiMvmgR+3ArAsKY+WAW5MWbGX6jobAC6OFoa2C+D+Ue2I9ndrcKy71YHpdwykqLyGDSkFPPbrDmZsyWD65gwALuwayuLEXIoqagj2dMbqaD5s+TYAs9nEi2M6s2LXIranF9Ph8bkN9l/aI5xXLu1y1GtuF+zJ8klD2ZVbiq+rEy/NSeSnjfvswYyPqyP7y2twdjQz+65B3P71JjanFXJF78gjBjOHuqBrGG2DPXB2sNDikNdg/IAWmM0m0grKCfCwMrJDEK2D6pd2e/aCTgxrF0iUnxutAt0xDIM6m0FlrY3hry0ltaCc/1u4k+Htg3CzWv62DyLSfB2cFTjiCEspAgwMMihyDmR+fA7vLt6No8XE7zvz+H1nHt+tS6NfjB/JeaWs2FUfYh8Mxb9Zm8bMA0uZXT8gWsHMSdJk4Ux1dTUbNmzgoYcesm8zm80MHz6cVatWHfGY6dOn069fPyZMmMCvv/5KQEAAV111FZMmTcJisdjbjBo1iksvvZSlS5cSFhbGbbfdxo033mg/T//+/Zk+fTrXX389oaGhLFmyhKSkJN54442/7G9VVRVVVVX2x8XF9WuV1tTUUFNT849ei9PJwddCr4lI86PxKdJ8aXyKNE8amyLNl8bnqSPS28qZbQNYlJjLZyv28NjoI8+0yS6u5OFpfyy9tSA+mwXxDdt8Mb4HXSO8gSP/7APdHAh0c8DXNYAnpmOvyeLr5sjDZ7fhgi4h7Mgo5rr+UVgPLNN2pPN4OJkY1y+K95Ym15/Xw0qfaB+KK2q5d0SrY37ftfRzAeCp89qRkl/K+pRCxvaO4Mnz2rN8Vz7+7k4EuTvyypiOzNqWzbX9Io/p3AfP++e21/YJb/D40P1ntPI9bJvVDI+e05bbv93C5CW7mbxkN1YHM7Pu6E+kr+sxXeOfaWyKNJ2U/HKSsktxMJsY2NLnsHFYU1ODyQS3DopifnwOM7ZkNNi/IWU/G1L2A/Wz754+vwN788v48Pe9AJRU1hLj78r9I1pqjB/F8bw2JsMwDq9c1ggyMjIICwtj5cqV9OvXz779gQceYOnSpaxZs+awY9q1a8fevXsZO3Yst912G7t27eK2227jzjvv5IknngDA2dkZqF+67NJLL2XdunVMnDiR999/n3HjxgH1QctNN93EF198gYODA2azmY8++ohrr732L/v75JNP8tRTTx22/euvv8bV9cT+YImIiIiIiIiInO62FZj4ONGCr9Xg8W51/LkG9f4qeD/eQlaFiSAXg8ti6vhmt4W8ShMtPQx2l5jo5mfjuja2Y37Ol7dYSC+vf6Ib2tYR63t8t7+q6mBGihkfq8GAIAPnf/jx5lobpJRCtAeYj78G97/qx2Qzv2f/UVOok4+NG9sd+2stIs3DogwTv6ZYaONlY0KHo4/hTxLNbC2oH/dtvWzE+hpU1MKWAjPF1TCudR2tvOrbLs8y8cOe+okRV8TU0S+oSeKEU0Z5eTlXXXUVRUVFeHoefSZiky5rdrxsNhuBgYF8+OGHWCwWevToQXp6Oq+88oo9nLHZbPTs2ZPnn38egG7durF9+/YG4czbb7/N6tWrmT59OlFRUSxbtowJEyYQGhrK8OHDj/jcDz30EPfcc4/9cXFxMREREYwcOfJvX+T/kpqaGubPn8+IESPsS8+JSPOg8SnSfGl8ijRPGpsizZfG56llSHUtnz+/mIIqaNd7MFG+LiTnlWExmymvruXxzzdQVFFLkKeVb27oRYSPKzfX2sguriTS15WErBKi/VyxHkdNFCMii7u+38rtQ2KYOKzVCfX7ohM66tQzvNbGl2tSMQGvzNvJ9v1m0tzbcvMZ0X977J9pbIo0nS8/XgsUcsXADpzTN/Kw/YeOz2EjzEzbnMmevDLG9Ysk1NvF3s4wDEyHpOj9y2tY9NYKPJwdePSa/vaZh3JkB1fcOhZNFs74+/tjsVjIzs5usD07O5vg4OAjHhMSEoKjo6N9CTOA9u3bk5WVRXV1NU5OToSEhNChQ4cGx7Vv356ffvoJgIqKCh5++GGmTZvG6NGjAejcuTObN2/m1Vdf/ctwxmq1YrVaD9vu6OioPzZHoNdFpPnS+BRpvjQ+RZonjU2R5kvj89Tg5ehI3xg/ft+Zx6wdOcyPyyY+sxiTCUK9XCiqqCU2zIt3r+pOpF/96iSOjuDuUn8fJjbC97if88LuEYzoGIKb9ZT6XHKTcHSEW4a0BsBisfDsb/G8On8n3aJ86Rvjx08b9tEqyJ3ukT7HcU6NTZHGlFtSxYbUQgBGxYYedfwdHJ/X9D+2ADbAy5FF9w3BYjbhrt+pf+t4fvc1Wczl5OREjx49WLhwoX2bzWZj4cKFDZY5O9SAAQPYtWsXNtsf07KSkpIICQnBycnJ3iYxMbHBcUlJSURFRQF/1IgxmxteusViaXBeERERERERERE5OYa0DQTgrYU7ic+s/1SxYUB6YQVWBzOfjOtpD2ZOFgUzx++GQTFc1af+E/evzkvk85V7eeCnrVz83kpenJ1AE1VH+EdOxT6LHEluSRU1dTbeX7qbdxfvavDefm/JLgwDuoR7EXbILJiTxcvFUcHMv6BJX9F77rmHcePG0bNnT3r37s2bb75JWVkZ48ePB+Daa68lLCyMF154AYBbb72Vd955h4kTJ3LHHXewc+dOnn/+ee688077Oe+++2769+/P888/z2WXXcbatWv58MMP+fDDDwHw9PRk8ODB3H///bi4uBAVFcXSpUv54osveP311xv/RRAREREREREROc1d1C2Mr1ankJxXhqPFxBfX9+Ghn7eyN7+cq/pEEujp3NRdlAPuGt6anzfuY1NqIZsOfBIf4P2lu3l/6W46hHjywTU9iPBtfjWY0wrKuf3rjThazPRv5c+WtELW7y2ge5QPL43p3GDppiMxDIP5cdn4uTvRI+r4Z2yJ/BM2m8Hnq/by6Yo9hHq5cEHXMOpsNq7uG8WynXmMn7KWvjF+rNydD0CnMC8Gtwlg5a48vliVAsB9o9o25SXIcWrScObyyy8nNzeXxx9/nKysLLp27cqcOXMICgoCIDU1tcEMl4iICObOncvdd99N586dCQsLY+LEiUyaNMneplevXkybNo2HHnqIp59+mujoaN58803Gjh1rb/Ptt9/y0EMPMXbsWAoKCoiKiuK5557jlltuabyLFxERERERERH5j/B1c2L2XYOYtS2TMG9Xekf78ul1vZi5NZP/DTz+2iby7wn0cOamQTG8tWgXADH+blzaM4KX5iQAEJdZzMRvN/Hdzf1wtDSf2hM1dTbu+GYTW/YVAbA+Zb993+8787huylo6hHhSWWOjb4wvV/SOxPlAHaOSyhq+WJXCyt15rNiVj9XBzOqHhuHj5tQk1yL/LTabwZ78MuZsz+KVufUrQqUVVLBmTwEAvm5WJi/dhc3AHswAvDg7gbySKu77cQuGAaM6BjGodUCTXIOcmCafi3T77bdz++23H3HfkiVLDtvWr18/Vq9efdRznnvuuZx77rl/uT84OJgpU6YcVz9FREREREREROTEWR0sXNQt3P44JsCdO4e1bsIeyV+5e0QbOoV5MWd7FuMHRNMpzJM6m431KftZkpjLxtRCLv9gFe9f3eMfz3pKKyinqraOVoEeJ3wOwzB4ekYcm9MKgfrZP6t252MA1w+I5papG0jKLiUpuxSAOTuymLJyL+9e1Z30wgo+WpbcIMypqrUxfUsG4/q3+AdXJv8lc7ZnMn1LBk+e1/G4x8SDP2/l+/X77I/vPLMV6/buZ1VyfRAz4euNRzwuPrOY+w8EMxd1C+PZCzud+AVIk2jycEZERERERERERESaD5PJxMiOwYzsGGzfdvuZ9UHa4oQc7vxmExtTC3ltXhIvXdK5wbHVdbAtvYgOYT72mSl/ZfqWDO7/YQs1dTbObBdEbmkVL4/pTNvgYw9qaupsvDArgS9Xp2AywftX92BUx2DuGv5Hm+sHRPPpij10DPXkvC6hfL5yLyn55Zz79nJ7G09nB24cFENGUQXfrE3jp437FM7I3/p1czrzdmTz27ZMACJ8XGkZ4E6Ah5X+rfywOhx9DMzaltkgmDm7UzB3j2iDyWRiT14ZQ19dYt8X7uPCvv0VmE3w0NnteW5WPDYD2gV78MolnXFoRjPZ5NgonBEREREREREREZFjMrRdIO+O7c61n65lYUI2NpuB2WwCYPb2LJ7aaKF07Ro8nB14/bKujOgQZD+2qLyGjKIK2gV7sDe/nLu+3YTtQE3zBfHZADzw01am3drffs6/EpdRTK3NxpsLdrIoIQeAx8/twKhDAqWDHh3dnpEdg+gS7o2Lk4XzuoRy6eSVZBRV0jbIgwhfV+4a3ppOYV4UlFXz44Z9bN1XxI6MIjqGep2Ml01OQ1v3FXLXd5sxjD+2fbAs2f59Cz9X3h3b/S/fQzO2ZHDP95uB+gDx7NhgukZ4YzLVv/ej/d3o3cKXtXsL6BzuxcfjenLLlxvoHunDjWfEkLa/nB837OO5i2IVzJyiFM6IiIiIiIiIiIjIMesb44eH1YG80mpWJefj724lKbuEe3/cRk2dCScHMyWVtTw5fQeh3s7M3pbF77vy2LavEJsBr1zSmdSCcmwG9G/px4Xdwpi7PYuFCTlsSSvky9UpDWatrN1TwMKEbOrqDG4aHENVjY0L31tBda0NAGdHM29e3pWzOoUcsb9ms4m+MX72x2HeLsy+6wzySqtoGeDeoK2vmxNndQphxpYMpqzYy6uXdjnsfIZhUF1n+9tZEXL6sdkMkvNKifZ354npOzAMaB3ozr0j23DL1IbLj+3NL+fS91fxzY196RLhjWEY9uClsqaOST9tpabOYHRsCA+e3Q4nh8MDlhfHxDJ7exbX9IvC09mRn28bYN/39AWdeOr8jvZzyqlH4YyIiIiIiIiIiIgcMycHM2e0CeC3bZmM/XhNg32dfW18cduZDHn9d9ILKxj91vLDjp+2KZ2U/HIAruwdyXldQrmsZwSfLt/D0zPjeHpmHNH+bgxs5c99P2zh503p9mPLa+rwc3OyBzMmE0cNZv6Kl4sjXi6OR9x3/YAWzNiSwY8b9uFoMXPfyDZ4ODviaDExfUsGr8xNpLC8hg+v6UH/Vv7H9bxy6korKOf2bzaxJa2Q1oHu7Mwpxc3JwtQb+hDk6UybIHd7XaP1jw7njq83sSo5n/GfrePibmF8uTqFszoFc1XvSIoqaiivriPUy5m3r+z2lzPFYgLcmTC01V/2ScHMqU3hjIiIiIiIiIiIiByXUZ2C7XU2vF0d8Xe3EhvmSV/HVNysDlzaI5yPft8DQL8YPy7uHkaErytXfLialbvrC517WB0aLHs2fkALtqcX8fOmdG74Yj39W/qxJDEXB7OJAA8rmUWVzNySYZ9hcP+otgxpG3DSlx7rFulDzygf1qfs55u1qaxJzieruJJeLXz5fWeufSm2G75Yzy2DW3LDoGhcnXSb9XT31Iw4tqQVArAzpz6EuWNYa4I8nQF44eJYHv55O4+Mbo+/u5WPxvXkqo9Ws3VfER8vrx8Lv27O4NfNGfZzDu8Q9LdL+MnpS781RERERERERERE5Lic1zkEq4OZMG8XOoXVhyM1NTXMmpUKwLX9WvDjhn10jfDm/Wt62JcAC/K0kl1cBcBVfSJxdvxjaTCTycSLYzqTUVTB6uQCliTmAvXLN13WM5zezy+koKwaqF9+7IZB0f/a0mIfXtuTBfHZPDMzjuS8MgCWJtX3p1+MH3WGwdo9Bbw+P4l1ewuYcl0v1f34C6VVtUxesovRsaF0CPU8Ypvy6locLWYcD7yGVbV1/J6UR1xmMcm5pVzUPZw2Qe6s3VOAp7MjQ9sFnlBf6mwGxRU1+Lg5/W3bzKIKfN2csDpYKCqvYWlSfW2j87qEMmNLBjH+blw/INrevkeUL3PvPsP+2N3qwJTrenHp+6tIzitjUGt//NycmLsjm4qaOoAG4aT89yicERERERERERERkeNiMpkY1TH4L/dH+Lqy/tERmE0Nl166oGsYHy5LxmSCu4a3Oew4JwczH1zdkwd+2kJ5dR0jOwZzZe8ITCYTI9oH8d36NAAeP7fDv1rzxdfNict6RhDgYeWxX7azb3+Ffd+j57anbZAHM7Zm8PDP2/l9Zx6vzE3koXPaH/FcB4OGEG/nfzzLZ0liDm/MT+L2M1s3yo19wzAwjPq6PdnFlVjMJvzdrQCk5pfzwux41qfs5/mLYv+yP5+v3Mu7i3fz7uLdzL3rDNoGe5BWUM7UNSlsTNmPi5MDy3fm4uRgZkBLf86ODeGLVXvZuq/Ifo7Z27MwmaCypn45u18mDKBrhLd9f0p+GU4OZkK8XP7yOr5fn8Y7i3exb38FL14cy+W9Iv/yun/ZlM49328m0teVqTf0YeXufGrqDNoGefDWFV25oEt90HSkOjGH8nO38uvtA0jKLqV7pDcmk4mVu/K49tO1+Lg50Sfa76jHy+lN4YyIiIiIiIiIiIicdJYjLNd025CW2GwGV/SOwMXpyOGKl6sjH1zT87DtNwyKZn1KAVf1ieLCbmEnvb9HMrRtIMsnnUl1rY2nZuwg0tfVHrBc1C0cR4uZ27/exAfLkukY5sX5XULtx+7JK+OpGTtYv3c/pVW1uDlZWPnQsL+sdfN38kqruOf7LRSUVTPhq418Nr7Xv1rz5us1qby7eBdFFTWMjg2xB2ND2gbw+mVduebTNfbaQbd9tYHPxvdmwIH+5BRXkldaTYdQT+bFZdvPeeG7K+gd7cvK3XnU1BkNnq+yxsbChBwWJtTPUPFycWRYu0D2FVawdk9Bg7YztmTYw5ldOaWMfut3nCxmfri1H+2C/5idU1NnY+6OLD5ZvodNqYX27ZN+2saUFXu5YVAMl/QIb3DuxYk53PfDFmwG7M0v54oPV+PtWv8zO7dzCCaTieHHEYx5ODvSI8rH/rh/K3/m3zMYJwfz34Y7cnpTOCMiIiIiIiIiIiKNwtvViUfP7XBCx7YO8mDhvUNOboeOkZODmecuij1s+7mdQ9mWXsQHS5N5ZNo2Brbyx9fNidT8cq78cDVZxZX2tmXVdczcmsHYPlF/+Tw5JZV8/Pse1u0t4M5hrTEMg0+X72V7RhGF5TUAOJhNVNfZuG7KOq7sHUGHUE+Gtg0k8EDtk5NhZ3YJj/yyDeNAfnIwmAFYkpjL0FeXUFRRg7+7Ez2ifJi7I5tHf9nOvLvPoLbO4KL3VpJeWMGT53Vg675CACJ9XUktKLcvDzeglR/ndQ6luLKG/i39cbCY+HVzBuv2FODiZOHJ8zvSMsCdsqpanp8VT5SfK5G+rtwydSOzt2UyqmMw//tsHSVVtQBU1dq47tN1fHJdTzqGepGYVcL4KWvJKKr/GTg7mrl7eBtWJ+ezODGXhKwS7vthC2YTXNy9PqDZlLqfW6duoNZmcE5sMNvTi0ktKGff/grcrQ6M+VOQc6Ki/d1Oynnk1KZwRkREREREREREROQEPTCqHcuS8ojPLKb7M/M5s10gS5NyqbMZtAp0583Lu/L7zjxempPAI9O24+fmxKiOwZhMJnbllBLu44Kzo4Xiyhqu+mgNuw4Um7/h8/XU2RrOLgn2dObdsd15bV4iK3fn8/mqFAA8rA78fFt/Wgd5nJRr+r+FOzEMGNjKn5LKGrbsK2Jsn0iu7B3J/z5fZ68bdMvgllzeK4L1e5ewJ6+M1o/MbnCeJ2fEAdAu2IPZEwexMD6HrOJKOoZ60i3S57DnbXfW4TVp3KwO9mCssqYOd6sDGUWVXPbBKnsbq4OZMB8XknPLuPi9lVzRK4J5cdlkFlXi727lqt4RXNUnimAvZ64b0IJF8Tn8viuPr9ekcv+PW3F1stAlwpubv9xAZY2NIW0D+L8rurErp5SL31tJRU0dL1/SmVDvIy+bJnIiFM6IiIiIiIiIiIiInCCL2cQj57Tn6k/WALDowLJc0f5ufH1DHwI9nQn0tPLqvETqbAa3TN3IE+d1oLiiljcWJBHl58pjozvw7pJd7Mopxd/dSkV1LWXVdZhNcP2AaC7uHk6IlzNeLo6YzSY+vLYnby/aSW5xFVv2FbI7t4y7vtvM5LE9iPRzPayP29OLmLM9i7M6BdMprGHdm6raOnbllBLk6Yy/u5XFCTnM3JoJwCOj29Mq0J2EzBI6hXliMpn4dcJA7v1hMzV1BmP7ROHiZOGuEW147Jfth70uB8OlszoFH/dyYEfi7Gjh/K6hfL0m1b7t3M4hXNQtjJ5Rvkz8bhNLEnPtoVXLADd+urU/3q5O9vZWBwtnx4YwqmMwlTV1/LwxnVumbsRkAsOA1oHuvHtVdxwtZtqHeDJr4iAKyqroEeX7j/ou8mcKZ0RERERERERERET+gYGt/XnivA6kFpTj4mghq6iS+89qa19qLNDDmWcu6MS7i3eRXljBUwdmlACk5JdzwxfrAXC3OvDpdT2JCXDni1V76RPte8RQwN3qwENntwcgu7iSkW8sY0dGMYNfXcx9I9tyVqdgonxdMZtMfLU2lWdmxFFdZ+OdxbsY2jaA24a2omeUDyaTiUk/buWXzRmYTHBpj3Dm7qivEXNN3yjah9TPZIkN/yPQCfZy5qsb+jboz9V9Ion0dcXdauHXzRm4Wx24f1Rb4jKL2ZNXxoh/GMoc6uFz2rNqdz578soY0z2c1y7rYt835bpezIvLZmF8NmHeroztG9kgmDmU2WzipTGdcXG08OOGfVTV2ugU5snbV3bHzfrHbfNofzctQyb/CoUzIiIiIiIiIiIiIv/Q+AHRR91/VZ9IrugVwdWfrGHl7nycHMzcfEYMv2xOp7iilv4t/Xj4nPZE+NbPfLltSKtjet4gT2c+G9+L1+YlsXxXHq/MTeSVuYm0DHDDw9mRzWmFQP3SYjtzSlmcmMvixFzaBnlw/cAWzDgwS8Yw4Pv1+wDoFunNo+e2P+ZrN5lMDG4TANAgTOoY6kXHUK+/OuyEuFsd+ObGvvy0cR9j+0Qe1o9RHYMZ1TH4mM7laKmvJfTQOe0pq6ol6CTW7RH5OwpnRERERERERERERBqB2Wzig2t6sCQxlwGt/PF1c+LekW0xDAOTyXTC5+0W6cPUG/rw0bJkXpgdD8Du3DKgPsy4Z0QbruvfgpSCct5bvItZ2zJJzC5h0k/bAOgZ5cMVvSN57rc4hrcP4snzO2J1sPzzC/6XBHs5M2HosYVXx8Ld6oC7VbfKpXHpHSciIiIiIiIiIiLSSDycHTmvS2iDbf8kmDnUjWfEcHXfKIora3hk2na8XR25f1Rb+4yQaH83Xrm0C4+O7sCLcxL4Zm197ZYre0cypkc4Y7qHnbS+iMjRKZwREREREREREREROU24OFlwcbLw8bief9nGy9WR5y/qRAs/V3bnlnJulxDg5IVEIvL3FM6IiIiIiIiIiIiI/MeYTCZuHtyyqbsh8p9lbuoOiIiIiIiIiIiIiIiI/JconBEREREREREREREREWlECmdEREREREREREREREQakcIZERERERERERERERGRRqRwRkREREREREREREREpBEpnBEREREREREREREREWlECmdEREREREREREREREQakcIZERERERERERERERGRRqRwRkREREREREREREREpBEpnBEREREREREREREREWlECmdEREREREREREREREQakcIZERERERERERERERGRRqRwRkREREREREREREREpBEpnBEREREREREREREREWlECmdEREREREREREREREQakcIZERERERERERERERGRRqRwRkREREREREREREREpBEpnBEREREREREREREREWlEDk3dgVOVYRgAFBcXN3FPmpeamhrKy8spLi7G0dGxqbsjIofQ+BRpvjQ+RZonjU2R5kvjU6R50tgUab40PhvHwbzgYH5wNApnTlBJSQkAERERTdwTERERERERERERERFpLkpKSvDy8jpqG5NxLBGOHMZms5GRkYGHhwcmk6mpu9NsFBcXExERQVpaGp6enk3dHRE5hManSPOl8SnSPGlsijRfGp8izZPGpkjzpfHZOAzDoKSkhNDQUMzmo1eV0cyZE2Q2mwkPD2/qbjRbnp6eGuQizZTGp0jzpfEp0jxpbIo0XxqfIs2TxqZI86Xx+e/7uxkzBx09uhEREREREREREREREZGTSuGMiIiIiIiIiIiIiIhII1I4IyeV1WrliSeewGq1NnVXRORPND5Fmi+NT5HmSWNTpPnS+BRpnjQ2RZovjc/mx2QYhtHUnRAREREREREREREREfmv0MwZERERERERERERERGRRqRwRkREREREREREREREpBEpnBEREREREREREREREWlECmdEREREREREREREREQakcIZOaneffddWrRogbOzM3369GHt2rVN3SWR09oLL7xAr1698PDwIDAwkAsvvJDExMQGbSorK5kwYQJ+fn64u7szZswYsrOzG7RJTU1l9OjRuLq6EhgYyP33309tbW1jXorIae3FF1/EZDJx11132bdpbIo0nfT0dK6++mr8/PxwcXEhNjaW9evX2/cbhsHjjz9OSEgILi4uDB8+nJ07dzY4R0FBAWPHjsXT0xNvb2/+97//UVpa2tiXInJaqaur47HHHiM6OhoXFxdatmzJM888g2EY9jYanyL/vmXLlnHeeecRGhqKyWTil19+abD/ZI3DrVu3MmjQIJydnYmIiODll1/+ty9N5JR3tPFZU1PDpEmTiI2Nxc3NjdDQUK699loyMjIanEPjs/lQOCMnzXfffcc999zDE088wcaNG+nSpQujRo0iJyenqbsmctpaunQpEyZMYPXq1cyfP5+amhpGjhxJWVmZvc3dd9/NjBkz+OGHH1i6dCkZGRlcfPHF9v11dXWMHj2a6upqVq5cyeeff85nn33G448/3hSXJHLaWbduHR988AGdO3dusF1jU6Rp7N+/nwEDBuDo6Mjs2bOJi4vjtddew8fHx97m5Zdf5q233uL9999nzZo1uLm5MWrUKCorK+1txo4dy44dO5g/fz4zZ85k2bJl3HTTTU1xSSKnjZdeeonJkyfzzjvvEB8fz0svvcTLL7/M22+/bW+j8Sny7ysrK6NLly68++67R9x/MsZhcXExI0eOJCoqig0bNvDKK6/w5JNP8uGHH/7r1ydyKjva+CwvL2fjxo089thjbNy4kZ9//pnExETOP//8Bu00PpsRQ+Qk6d27tzFhwgT747q6OiM0NNR44YUXmrBXIv8tOTk5BmAsXbrUMAzDKCwsNBwdHY0ffvjB3iY+Pt4AjFWrVhmGYRizZs0yzGazkZWVZW8zefJkw9PT06iqqmrcCxA5zZSUlBitW7c25s+fbwwePNiYOHGiYRgamyJNadKkScbAgQP/cr/NZjOCg4ONV155xb6tsLDQsFqtxjfffGMYhmHExcUZgLFu3Tp7m9mzZxsmk8lIT0//9zovcpobPXq0cf311zfYdvHFFxtjx441DEPjU6QpAMa0adPsj0/WOHzvvfcMHx+fBv+unTRpktG2bdt/+YpETh9/Hp9HsnbtWgMwUlJSDMPQ+GxuNHNGTorq6mo2bNjA8OHD7dvMZjPDhw9n1apVTdgzkf+WoqIiAHx9fQHYsGEDNTU1DcZmu3btiIyMtI/NVatWERsbS1BQkL3NqFGjKC4uZseOHY3Ye5HTz4QJExg9enSDMQgamyJNafr06fTs2ZNLL72UwMBAunXrxkcffWTfv2fPHrKyshqMTy8vL/r06dNgfHp7e9OzZ097m+HDh2M2m1mzZk3jXYzIaaZ///4sXLiQpKQkALZs2cLy5cs5++yzAY1PkebgZI3DVatWccYZZ+Dk5GRvM2rUKBITE9m/f38jXY3I6a+oqAiTyYS3tzeg8dncODR1B+T0kJeXR11dXYMbSABBQUEkJCQ0Ua9E/ltsNht33XUXAwYMoFOnTgBkZWXh5ORk/yN8UFBQEFlZWfY2Rxq7B/eJyIn59ttv2bhxI+vWrTtsn8amSNNJTk5m8uTJ3HPPPTz88MOsW7eOO++8EycnJ8aNG2cfX0caf4eOz8DAwAb7HRwc8PX11fgU+QcefPBBiouLadeuHRaLhbq6Op577jnGjh0LoPEp0gycrHGYlZVFdHT0Yec4uO/Q5UZF5MRUVlYyadIkrrzySjw9PQGNz+ZG4YyIyGliwoQJbN++neXLlzd1V0T+89LS0pg4cSLz58/H2dm5qbsjIoew2Wz07NmT559/HoBu3bqxfft23n//fcaNG9fEvRP5b/v+++/56quv+Prrr+nYsSObN2/mrrvuIjQ0VONTRETkONTU1HDZZZdhGAaTJ09u6u7IX9CyZnJS+Pv7Y7FYyM7ObrA9Ozub4ODgJuqVyH/H7bffzsyZM1m8eDHh4eH27cHBwVRXV1NYWNig/aFjMzg4+Ihj9+A+ETl+GzZsICcnh+7du+Pg4ICDgwNLly7lrbfewsHBgaCgII1NkSYSEhJChw4dGmxr3749qampwB/j62j/rg0ODiYnJ6fB/traWgoKCjQ+Rf6B+++/nwcffJArrriC2NhYrrnmGu6++25eeOEFQONTpDk4WeNQ/9YV+fccDGZSUlKYP3++fdYMaHw2Nwpn5KRwcnKiR48eLFy40L7NZrOxcOFC+vXr14Q9Ezm9GYbB7bffzrRp01i0aNFh00579OiBo6Njg7GZmJhIamqqfWz269ePbdu2NfjjfPCP959vXonIsRk2bBjbtm1j8+bN9q+ePXsyduxY+/camyJNY8CAASQmJjbYlpSURFRUFADR0dEEBwc3GJ/FxcWsWbOmwfgsLCxkw4YN9jaLFi3CZrPRp0+fRrgKkdNTeXk5ZnPD2xQWiwWbzQZofIo0BydrHPbr149ly5ZRU1NjbzN//nzatm2rJZNE/oGDwczOnTtZsGABfn5+DfZrfDYzhshJ8u233xpWq9X47LPPjLi4OOOmm24yvL29jaysrKbumshp69ZbbzW8vLyMJUuWGJmZmfav8vJye5tbbrnFiIyMNBYtWmSsX7/e6Nevn9GvXz/7/traWqNTp07GyJEjjc2bNxtz5swxAgICjIceeqgpLknktDV48GBj4sSJ9scamyJNY+3atYaDg4Px3HPPGTt37jS++uorw9XV1Zg6daq9zYsvvmh4e3sbv/76q7F161bjggsuMKKjo42Kigp7m7POOsvo1q2bsWbNGmP58uVG69atjSuvvLIpLknktDFu3DgjLCzMmDlzprFnzx7j559/Nvz9/Y0HHnjA3kbjU+TfV1JSYmzatMnYtGmTARivv/66sWnTJiMlJcUwjJMzDgsLC42goCDjmmuuMbZv3258++23hqurq/HBBx80+vWKnEqONj6rq6uN888/3wgPDzc2b97c4D5RVVWV/Rwan82Hwhk5qd5++20jMjLScHJyMnr37m2sXr26qbskcloDjvg1ZcoUe5uKigrjtttuM3x8fAxXV1fjoosuMjIzMxucZ+/evcbZZ59tuLi4GP7+/sa9995r1NTUNPLViJze/hzOaGyKNJ0ZM2YYnTp1MqxWq9GuXTvjww8/bLDfZrMZjz32mBEUFGRYrVZj2LBhRmJiYoM2+fn5xpVXXmm4u7sbnp6exvjx442SkpLGvAyR005xcbExceJEIzIy0nB2djZiYmKMRx55pMENJY1PkX/f4sWLj/j/zHHjxhmGcfLG4ZYtW4yBAwcaVqvVCAsLM1588cXGukSRU9bRxueePXv+8j7R4sWL7efQ+Gw+TIZhGI03T0dEREREREREREREROS/TTVnREREREREREREREREGpHCGRERERERERERERERkUakcEZERERERERERERERKQRKZwRERERERERERERERFpRApnREREREREREREREREGpHCGRERERERERERERERkUakcEZERERERERERERERKQRKZwRERERERERERERERFpRApnREREREREmoDJZOKXX35p6m6IiIiIiEgTUDgjIiIiIiL/Oddddx0mk+mwr7POOqupuyYiIiIiIv8BDk3dARERERERkaZw1llnMWXKlAbbrFZrE/VGRERERET+SzRzRkRERERE/pOsVivBwcENvnx8fID6JccmT57M2WefjYuLCzExMfz4448Njt+2bRtnnnkmLi4u+Pn5cdNNN1FaWtqgzaeffkrHjh2xWq2EhIRw++23N9ifl5fHRRddhKurK61bt2b69On/7kWLiIiIiEizoHBGRERERETkCB577DHGjBnDli1bGDt2LFdccQXx8fEAlJWVMWrUKHx8fFi3bh0//PADCxYsaBC+TJ48mQkTJnDTTTexbds2pk+fTqtWrRo8x1NPPcVll13G1q1bOeeccxg7diwFBQWNep0iIiIiItL4TIZhGE3dCRERERERkcZ03XXXMXXqVJydnRtsf/jhh3n44YcxmUzccsstTJ482b6vb9++dO/enffee4+PPvqISZMmkZaWhpubGwCzZs3ivPPOIyMjg6CgIMLCwhg/fjzPPvvsEftgMpl49NFHeeaZZ4D6wMfd3Z3Zs2er9o2IiIiIyGlONWdEREREROQ/aejQoQ3CFwBfX1/79/369Wuwr1+/fmzevBmA+Ph4unTpYg9mAAYMGIDNZiMxMRGTyURGRgbDhg07ah86d+5s/97NzQ1PT09ycnJO9JJEREREROQUoXBGRERERET+k9zc3A5bZuxkcXFxOaZ2jo6ODR6bTCZsNtu/0SUREREREWlGVHNGRERERETkCFavXn3Y4/bt2wPQvn17tmzZQllZmX3/ihUrMJvNtG3bFg8PD1q0aMHChQsbtc8iIiIiInJq0MwZERERERH5T6qqqiIrK6vBNgcHB/z9/QH44Ycf6NmzJwMHDuSrr75i7dq1fPLJJwCMHTuWJ554gnHjxvHkk0+Sm5vLHXfcwTXXXENQUBAATz75JLfccguBgYGcffbZlJSUsGLFCu64447GvVAREREREWl2FM6IiIiIiMh/0pw5cwgJCWmwrW3btiQkJADw1FNP8e2333LbbbcREhLCN998Q4cOHQBwdXVl7ty5TJw4kV69euHq6sqYMWN4/fXX7ecaN24clZWVvPHGG9x33334+/tzySWXNN4FioiIiIhIs2UyDMNo6k6IiIiIiIg0JyaTiWnTpnHhhRc2dVdEREREROQ0pJozIiIiIiIiIiIiIiIijUjhjIiIiIiIiIiIiIiISCNSzRkREREREZE/0erPIiIiIiLyb9LMGRERERERERERERERkUakcEZERERERERERERERKQRKZwRERERERERERERERFpRApnREREREREREREREREGpHCGRERERERERERERERkUakcEZERERERERERERERKQRKZwRERERERERERERERFpRApnREREREREREREREREGtH/A53skDFnoRPwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Plot loss\n",
    "\n",
    "def plot_line(labels, data_dicts, x_name='X-Axis', y_name='Y-Axis'):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for label, data_dict in zip(labels, data_dicts):\n",
    "        for key, values in data_dict.items():\n",
    "            plt.plot(values, label=f\"{label} - {key}\")\n",
    "    plt.xlabel(x_name)\n",
    "    plt.ylabel(y_name)\n",
    "    plt.title('Loss Plot')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "loss_values = model.loss\n",
    "smoothed_loss = smooth(np.array(loss_values), window=300)  # Adjust smoothness if needed\n",
    "\n",
    "info = {'Loss': smoothed_loss}\n",
    "plot_line(['Model'], [info], x_name='Epoch', y_name='Loss Value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74ec43",
   "metadata": {
    "papermill": {
     "duration": 0.062137,
     "end_time": "2025-07-22T06:38:14.031205",
     "exception": false,
     "start_time": "2025-07-22T06:38:13.969068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train HAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a2c8523",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.071425Z",
     "iopub.status.busy": "2025-07-22T06:38:14.070848Z",
     "iopub.status.idle": "2025-07-22T06:38:14.075851Z",
     "shell.execute_reply": "2025-07-22T06:38:14.075182Z"
    },
    "id": "Q7IfdzX4LFTk",
    "papermill": {
     "duration": 0.026379,
     "end_time": "2025-07-22T06:38:14.076970",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.050591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Cost function\n",
    "def mean_with_cost(feedback, zero_reward_cost=0.1):\n",
    "  B, L = feedback.shape\n",
    "  cost = torch.zeros_like(feedback)\n",
    "  cost[feedback == 0] = -zero_reward_cost\n",
    "  reward = torch.mean(feedback + cost, dim=-1)\n",
    "  return reward\n",
    "\n",
    "def nsw(avg_r, min_r, lambda_nsw=1e-4, epsilon=1e-8):\n",
    "    r_vec = torch.stack([avg_r, min_r + lambda_nsw], dim=-1)\n",
    "    r_vec = torch.clamp(r_vec, min=epsilon)\n",
    "    return torch.sum(torch.log(r_vec), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de0d10f6",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.119001Z",
     "iopub.status.busy": "2025-07-22T06:38:14.118374Z",
     "iopub.status.idle": "2025-07-22T06:38:14.122522Z",
     "shell.execute_reply": "2025-07-22T06:38:14.121851Z"
    },
    "id": "KP_0zmoEFwta",
    "papermill": {
     "duration": 0.026967,
     "end_time": "2025-07-22T06:38:14.123555",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.096588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title BaseRL Environment\n",
    "class BaseEnv():\n",
    "  def __init__(self, params):\n",
    "    super().__init__()\n",
    "    self.reward_func = params['reward_function']\n",
    "    self.max_step_per_episode = params['max_step']\n",
    "    self.initial_temper = params[\"initial_temper\"]\n",
    "\n",
    "  def reset(self, paras):\n",
    "    pass\n",
    "  def step(self, action):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290bf5cc",
   "metadata": {
    "papermill": {
     "duration": 0.02218,
     "end_time": "2025-07-22T06:38:14.165832",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.143652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1. Environment define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f34e983",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.206695Z",
     "iopub.status.busy": "2025-07-22T06:38:14.206499Z",
     "iopub.status.idle": "2025-07-22T06:38:14.227444Z",
     "shell.execute_reply": "2025-07-22T06:38:14.226706Z"
    },
    "id": "zBhnDCBm0ESQ",
    "papermill": {
     "duration": 0.042943,
     "end_time": "2025-07-22T06:38:14.228639",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.185696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ML1M Environment\n",
    "\n",
    "\n",
    "class ML1MEnvironment(BaseEnv):\n",
    "  def __init__(self, params):\n",
    "    super().__init__(params)\n",
    "    self.reader = ML1MDataReader(params)\n",
    "    self.user_response_model = ML1MUserResponse(self.reader, params)\n",
    "    checkpoint = torch.load(params['model_path'] + \".checkpoint\", map_location=device)\n",
    "    self.user_response_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    self.user_response_model.to(device)\n",
    "    self.n_worker = params['n_worker']\n",
    "\n",
    "    # spaces\n",
    "    stats = self.reader.get_statistics()\n",
    "    self.action_space = {'item_id': ('nomial', stats['n_item']),\n",
    "                         'item_feature': ('continuous', stats['item_vec_size'], 'normal')}\n",
    "    self.observation_space = {'user_profile': ('continuous', stats['user_portrait_len'], 'positive'),\n",
    "                              'history': ('sequence', stats['max_seq_len'], ('continuous', stats['item_vec_size']))}\n",
    "\n",
    "  def reset(self, params = {'batch_size': 1, 'empty_history': True}):\n",
    "      self.empty_history_flag = params['empty_history'] if 'empty_history' in params else True\n",
    "      BS = params['batch_size']\n",
    "      observation = {'batch_size': BS}\n",
    "      if 'sample' in params:\n",
    "          sample_info = params['sample']\n",
    "      else:\n",
    "          self.batch_iter = iter(DataLoader(self.reader, batch_size = BS, shuffle = True,\n",
    "                                            pin_memory = True, num_workers = self.n_worker))\n",
    "          sample_info = next(self.batch_iter)\n",
    "          sample_info = wrap_batch(sample_info, device = self.user_response_model.device)\n",
    "      self.current_observation = {\n",
    "          'user_profile': sample_info['user_profile'],  # (B, user_dim)\n",
    "          'history': sample_info['history'],  # (B, H)\n",
    "          'history_features': sample_info['history_features'], # (B, H, item_dim)\n",
    "          'cummulative_reward': torch.zeros(BS).to(self.user_response_model.device),\n",
    "          'min_reward': torch.zeros(BS).to(self.user_response_model.device),\n",
    "          'temper': torch.ones(BS).to(self.user_response_model.device) * self.initial_temper,\n",
    "          'step': torch.zeros(BS).to(self.user_response_model.device),\n",
    "      }\n",
    "      self.reward_history = [0.]\n",
    "      self.step_history = [0.]\n",
    "      return copy.deepcopy(self.current_observation)\n",
    "\n",
    "\n",
    "  def sample_user(self, n_user, empty_history = False):\n",
    "    '''\n",
    "    Sample random users and their history\n",
    "    '''\n",
    "    random_rows = np.random.randint(0, len(self.reader.data['train']), n_user)\n",
    "    return self.pick_user(random_rows, empty_history)\n",
    "\n",
    "  def pick_user(self, rows, empty_history = False):\n",
    "    '''\n",
    "    Pick users and their history\n",
    "    '''\n",
    "    raw_portrait = [self.reader.user_meta[self.reader.data['train']['user_id'][rowid]]\n",
    "                    for rowid in rows]\n",
    "\n",
    "    portrait = np.array(raw_portrait)\n",
    "\n",
    "    history = []\n",
    "    history_features = []\n",
    "    for rowid in rows:\n",
    "      H = [] if empty_history else eval(f\"{self.reader.data['train']['user_mid_history'][rowid]}\")\n",
    "      H = padding_and_clip(H, self.reader.max_seq_len)\n",
    "      history.append(H)\n",
    "\n",
    "      history_features.append(self.reader.get_item_list_meta(H).astype(float))\n",
    "      return {'user_profile': portrait,\n",
    "              'history': history,\n",
    "              'history_features': np.array(history_features)}\n",
    "\n",
    "  def step(self, step_dict):\n",
    "    '''\n",
    "    @input:\n",
    "    - step_dict: {'action': (B, slate_size),\n",
    "                    'action_features': (B, slate_size, item_dim) }\n",
    "    '''\n",
    "    # actions (exposures)\n",
    "    action = step_dict['action'] # (B, slate_size), should be item ids only\n",
    "    action_features = step_dict['action_features']\n",
    "    batch_data = {\n",
    "        'user_profile': self.current_observation['user_profile'],\n",
    "        'history_features': self.current_observation['history_features'],\n",
    "        'exposure_features': action_features\n",
    "    }\n",
    "    # URM forward\n",
    "    with torch.no_grad():\n",
    "        output_dict = self.user_response_model(batch_data)\n",
    "        response = torch.bernoulli(output_dict['probs']) # (B, slate_size)\n",
    "        probs_under_temper = output_dict['probs'] # * prob_scale\n",
    "        response = torch.bernoulli(probs_under_temper).detach() # (B, slate_size)\n",
    "\n",
    "        # reward (B,)\n",
    "        immediate_reward = self.reward_func(response).detach()\n",
    "\n",
    "        # self.current_observation['min_reward'] = torch.min(immediate_reward, self.current_observation['min_reward'])\n",
    "\n",
    "        # (B, H+slate_size)\n",
    "        H_prime = torch.cat((self.current_observation['history'], action), dim = 1)\n",
    "        # (B, H+slate_size, item_dim)\n",
    "        H_prime_features = torch.cat((self.current_observation['history_features'], action_features), dim = 1)\n",
    "        # (B, H+slate_size)\n",
    "        F_prime = torch.cat((torch.ones_like(self.current_observation['history']), response), dim = 1).to(torch.long)\n",
    "        # vector, vector\n",
    "        row_indices, col_indices = (F_prime == 1).nonzero(as_tuple=True)\n",
    "        # (B,), the number of positive iteraction as history length\n",
    "        L = F_prime.sum(dim = 1)\n",
    "\n",
    "        # user history update\n",
    "        offset = 0\n",
    "        newH = torch.zeros_like(self.current_observation['history'])\n",
    "        newH_features = torch.zeros_like(self.current_observation['history_features'])\n",
    "        for row_id in range(action.shape[0]):\n",
    "            right = offset + L[row_id]\n",
    "            left = right - self.reader.max_seq_len\n",
    "            newH[row_id] = H_prime[row_id, col_indices[left:right]]\n",
    "            newH_features[row_id] = H_prime_features[row_id,col_indices[left:right],:]\n",
    "            offset += L[row_id]\n",
    "        self.current_observation['history'] = newH\n",
    "        self.current_observation['history_features'] = newH_features\n",
    "        self.current_observation['cummulative_reward'] += immediate_reward\n",
    "\n",
    "        # temper update for leave model\n",
    "        temper_down = (-immediate_reward+1) * response.shape[1] + 1\n",
    "#             temper_down = -(torch.sum(response, dim = 1) - response.shape[1] - 1)\n",
    "#             temper_down = torch.abs(torch.sum(response, dim = 1) - response.shape[1] * self.temper_sweet_point) + 1\n",
    "        self.current_observation['temper'] -= temper_down\n",
    "        # leave signal\n",
    "        done_mask = self.current_observation['temper'] < 1\n",
    "        # step update\n",
    "        self.current_observation['step'] += 1\n",
    "\n",
    "        # Replace 0 with small epsilon for safe division\n",
    "        step = self.current_observation['step']\n",
    "        safe_step = torch.where(step == 0, torch.tensor(1e-8), step)\n",
    "        \n",
    "        # Compute average reward\n",
    "        avg_reward = self.current_observation['cummulative_reward'] / safe_step\n",
    "        \n",
    "        # Optionally, mask out the values where step == 0\n",
    "        avg_reward = torch.where(step == 0, torch.tensor(0.0), avg_reward)\n",
    "        self.current_observation['min_reward'] = avg_reward\n",
    "        # run.log({'avg_reward': avg_reward.mean().item()})\n",
    "\n",
    "        # update rows where user left\n",
    "#             refresh_rows = done_mask.nonzero().view(-1)\n",
    "#             print(f\"#refresh: {refresh_rows}\")\n",
    "        if done_mask.sum() > 0:\n",
    "            final_rewards = self.current_observation['cummulative_reward'][done_mask].detach().cpu().numpy()\n",
    "            final_steps = self.current_observation['step'][done_mask].detach().cpu().numpy()\n",
    "            self.reward_history.append(final_rewards[-1])\n",
    "            self.step_history.append(final_steps[-1])\n",
    "            # sample new users to fill in the blank\n",
    "            new_sample_flag = False\n",
    "            try:\n",
    "                sample_info = next(self.iter)\n",
    "                if sample_info['user_profile'].shape[0] != done_mask.shape[0]:\n",
    "                    new_sample_flag = True\n",
    "            except:\n",
    "                new_sample_flag = True\n",
    "            if new_sample_flag:\n",
    "                self.iter = iter(DataLoader(self.reader, batch_size = done_mask.shape[0], shuffle = True,\n",
    "                                            pin_memory = True, num_workers = params[\"n_worker\"]))\n",
    "                sample_info = next(self.iter)\n",
    "            sample_info = wrap_batch(sample_info, device = self.user_response_model.device)\n",
    "            for obs_key in ['user_profile', 'history', 'history_features']:\n",
    "                self.current_observation[obs_key][done_mask] = sample_info[obs_key][done_mask]\n",
    "            self.current_observation['cummulative_reward'][done_mask] *= 0\n",
    "            self.current_observation['temper'][done_mask] *= 0\n",
    "            self.current_observation['temper'][done_mask] += self.initial_temper\n",
    "            self.current_observation['min_reward'][done_mask] *= 0\n",
    "            self.current_observation['step'][done_mask] *= 0\n",
    "#         print(f\"step: {self.current_observation['step']}\")\n",
    "    return copy.deepcopy(self.current_observation), immediate_reward, done_mask, {'response': response}\n",
    "\n",
    "\n",
    "  def stop(self):\n",
    "    self.iter = None\n",
    "\n",
    "  def get_new_iterator(self, B):\n",
    "    return iter(DataLoader(self.reader, batch_size = B, shuffle = True,\n",
    "                              pin_memory = True, num_workers = params['n_worker']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea4e8182",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.269344Z",
     "iopub.status.busy": "2025-07-22T06:38:14.269132Z",
     "iopub.status.idle": "2025-07-22T06:38:14.278350Z",
     "shell.execute_reply": "2025-07-22T06:38:14.277614Z"
    },
    "id": "3BvTCi5yZvxS",
    "papermill": {
     "duration": 0.030785,
     "end_time": "2025-07-22T06:38:14.279517",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.248732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Self-Attentive Sequential Recommendation\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "  def __init__(self, environment, params):\n",
    "    super().__init__()\n",
    "    self.n_layer = params['sasrec_n_layer']\n",
    "    self.d_model = params['sasrec_d_model']\n",
    "    self.n_head = params['sasrec_n_head']\n",
    "    self.dropout_rate = params['sasrec_dropout']\n",
    "    self.d_forward = params['sasrec_d_forward']\n",
    "\n",
    "    # item space\n",
    "    self.item_space = environment.action_space['item_id'][1]\n",
    "    self.item_dim = environment.action_space['item_feature'][1]\n",
    "    self.maxlen = environment.observation_space['history'][1]\n",
    "    self.state_dim = self.d_model\n",
    "    self.action_dim = self.d_model\n",
    "\n",
    "    # policy network modules\n",
    "    self.item_map = nn.Linear(self.item_dim, self.d_model)\n",
    "    self.pos_emb = nn.Embedding(self.maxlen, self.d_model)\n",
    "    self.pos_emb_getter = torch.arange(self.maxlen, dtype = torch.long)\n",
    "    self.emb_dropout = nn.Dropout(self.dropout_rate)\n",
    "    self.emb_norm = nn.LayerNorm(self.d_model)\n",
    "    self.attn_mask = ~torch.tril(torch.ones((self.maxlen, self.maxlen), dtype=torch.bool))\n",
    "    encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model,\n",
    "                                               nhead=self.n_head,\n",
    "                                               dim_feedforward= self.d_forward,\n",
    "                                               dropout=self.dropout_rate,\n",
    "                                               batch_first = True\n",
    "                                               )\n",
    "    self.transformer = nn.TransformerEncoder(encoder_layer= encoder_layer,\n",
    "                                             num_layers = self.n_layer)\n",
    "\n",
    "  def score(self, action_emb, item_emb, do_softmax=True):\n",
    "    item_emb = self.item_map(item_emb)\n",
    "    output = dot_scorer(action_emb, item_emb, self.d_model)\n",
    "    if do_softmax:\n",
    "      return torch.softmax(output, dim=-1)\n",
    "    else:\n",
    "      return output\n",
    "\n",
    "  def get_scorer_parameters(self):\n",
    "    return self.item_map.parameters()\n",
    "\n",
    "  def encode_state(self, feed_dict):\n",
    "    user_history = feed_dict['history_features']\n",
    "    # (1, H, d_model)\n",
    "    # for item in feed_dict.items():\n",
    "    #   print(item)\n",
    "    # print(\"user_history device:\", user_history.device)\n",
    "    # print(\"self.pos_emb_getter device:\", self.pos_emb_getter.device)\n",
    "    # print(\"self.pos_emb device\", self.pos_emb.device)\n",
    "\n",
    "    pos_emb = self.pos_emb(self.pos_emb_getter.to(user_history.device)).view(1, self.maxlen, self.d_model)\n",
    "\n",
    "    # (B, H, d_model)\n",
    "    history_item_emb = self.item_map(user_history).view(-1, self.maxlen, self.d_model)\n",
    "    history_item_emb = self.emb_norm(self.emb_dropout(history_item_emb + pos_emb))\n",
    "\n",
    "    # (B, H, d_model)\n",
    "    output_seq = self.transformer(history_item_emb, mask = self.attn_mask.to(user_history.device))\n",
    "\n",
    "    return {'output_seq': output_seq, 'state_emb': output_seq[:, -1, :]}\n",
    "\n",
    "  def forward(self, feed_dict):\n",
    "    '''\n",
    "    @input\n",
    "    - feed_dict: {'user_profile': (B, user_dim),\n",
    "                  'history_features': (B, H, item_dim),\n",
    "                  'history_mask': (B),\n",
    "                  'candicate_features': (B, L, item_dim) or (1, L, item_dim)\n",
    "                  }\n",
    "    @model\n",
    "    - user_profile --> user_emb (B, 1, f_dim)\n",
    "    - hisotry_items --> history_item_emb (B, H, f_dim)\n",
    "    - (Q:user_emb, K&V: history_item_emb) --(multi-head attn) --> user_state(B, 1, feature_dim)\n",
    "    - user_state --> action_prob (B, n_item)\n",
    "    '''\n",
    "    hist_enc = self.encode_state(feed_dict)\n",
    "\n",
    "    # user embedding (B, 1, d_model)\n",
    "    user_state = hist_enc['state_emb'].view(-1, self.d_model)\n",
    "\n",
    "    # action embedding (B, d_model)\n",
    "    action_emb = user_state\n",
    "\n",
    "    # regularization\n",
    "    reg = get_regularization(self.item_map, self.transformer)\n",
    "\n",
    "    out_dict = {\n",
    "        'action_emb': action_emb,\n",
    "        'state_emb': user_state,\n",
    "        'seq_emb': hist_enc['output_seq'],\n",
    "        'reg': reg\n",
    "    }\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc98fc83",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.319446Z",
     "iopub.status.busy": "2025-07-22T06:38:14.319245Z",
     "iopub.status.idle": "2025-07-22T06:38:14.323807Z",
     "shell.execute_reply": "2025-07-22T06:38:14.323311Z"
    },
    "id": "Dz4XwAAtzx1d",
    "papermill": {
     "duration": 0.025689,
     "end_time": "2025-07-22T06:38:14.324893",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.299204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# @title General Critic class\n",
    "class GeneralCritic(nn.Module):\n",
    "  def __init__(self, policy, params):\n",
    "    super().__init__()\n",
    "    self.state_dim = policy.state_dim\n",
    "    self.action_dim = policy.action_dim\n",
    "    self.net = DNN(self.state_dim + self.action_dim, params['critic_hidden_dims'], 1,\n",
    "                   dropout_rate=params['critic_dropout_rate'], do_batch_norm=True)\n",
    "\n",
    "  def forward(self, feed_dict):\n",
    "    '''\n",
    "    @input:\n",
    "    - feed_dict: {'state_emb': (B, state_dim), 'action_emb': (B, action_dim)}\n",
    "    '''\n",
    "    state_emb = feed_dict['state_emb']\n",
    "    action_emb = feed_dict['action_emb'].view(-1, self.action_dim)\n",
    "\n",
    "    Q = self.net(torch.cat((state_emb, action_emb), dim = -1)).view(-1)\n",
    "\n",
    "    reg = get_regularization(self.net)\n",
    "    return {'q': Q, 'reg': reg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1db81315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.365622Z",
     "iopub.status.busy": "2025-07-22T06:38:14.365424Z",
     "iopub.status.idle": "2025-07-22T06:38:14.370046Z",
     "shell.execute_reply": "2025-07-22T06:38:14.369567Z"
    },
    "papermill": {
     "duration": 0.026607,
     "end_time": "2025-07-22T06:38:14.371077",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.344470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Vector-valued Critic class for MORL\n",
    "class VectorCritic(nn.Module):\n",
    "  def __init__(self, policy, params, n_objectives=2):\n",
    "    super().__init__()\n",
    "    self.state_dim = policy.state_dim\n",
    "    self.action_dim = policy.action_dim\n",
    "    self.n_objectives = n_objectives\n",
    "\n",
    "    # Output now has shape (B, n_objectives)\n",
    "    self.net = DNN(\n",
    "        self.state_dim + self.action_dim,\n",
    "        params['critic_hidden_dims'],\n",
    "        output_dim=n_objectives,\n",
    "        dropout_rate=params['critic_dropout_rate'],\n",
    "        do_batch_norm=True\n",
    "    )\n",
    "\n",
    "  def forward(self, feed_dict):\n",
    "    '''\n",
    "    @input:\n",
    "    - feed_dict: {'state_emb': (B, state_dim), 'action_emb': (B, action_dim)}\n",
    "    @output:\n",
    "    - {'q_vector': (B, n_objectives), 'reg': scalar}\n",
    "    '''\n",
    "    state_emb = feed_dict['state_emb']\n",
    "    action_emb = feed_dict['action_emb'].view(-1, self.action_dim)\n",
    "\n",
    "    q_vector = self.net(torch.cat((state_emb, action_emb), dim=-1))  # shape: (B, n_objectives)\n",
    "    reg = get_regularization(self.net)\n",
    "    return {'q': q_vector, 'reg': reg}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b599b213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.412222Z",
     "iopub.status.busy": "2025-07-22T06:38:14.411624Z",
     "iopub.status.idle": "2025-07-22T06:38:14.416279Z",
     "shell.execute_reply": "2025-07-22T06:38:14.415606Z"
    },
    "papermill": {
     "duration": 0.025998,
     "end_time": "2025-07-22T06:38:14.417316",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.391318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ValueCritic(nn.Module):\n",
    "    \n",
    "    def __init__(self, policy, params):\n",
    "        super().__init__()\n",
    "        self.state_dim = policy.state_dim\n",
    "        self.action_dim = policy.action_dim\n",
    "#         self.state_encoder = policy.state_encoder\n",
    "        self.net = DNN(self.state_dim, params['critic_hidden_dims'], 1, \n",
    "                       dropout_rate = params['critic_dropout_rate'], do_batch_norm = True)\n",
    "        \n",
    "    def forward(self, feed_dict):\n",
    "        '''\n",
    "        @input:\n",
    "        - feed_dict: {'state_emb': (B, state_dim), 'action_emb': (B, action_dim)}\n",
    "        '''\n",
    "        state_emb = feed_dict['state_emb']\n",
    "        V = self.net(state_emb).view(-1)\n",
    "        reg = get_regularization(self.net)\n",
    "        return {'v': V, 'reg': reg}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "240dd121",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.458073Z",
     "iopub.status.busy": "2025-07-22T06:38:14.457895Z",
     "iopub.status.idle": "2025-07-22T06:38:14.480216Z",
     "shell.execute_reply": "2025-07-22T06:38:14.479532Z"
    },
    "id": "Jd56qLlk99ge",
    "papermill": {
     "duration": 0.044013,
     "end_time": "2025-07-22T06:38:14.481285",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.437272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title One Stage Facade\n",
    "class OneStageFacade():\n",
    "  def __init__(self, environment, actor, critic, params):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.env = environment\n",
    "    self.actor = actor\n",
    "    self.critic = critic\n",
    "\n",
    "    self.slate_size = params['slate_size']\n",
    "    self.noise_var = params['noise_var']\n",
    "    self.noise_decay = params['noise_var'] / params['n_iter'][-1]\n",
    "    self.q_laplace_smoothness = params['q_laplace_smoothness']\n",
    "    self.topk_rate = params['topk_rate']\n",
    "    self.empty_start_rate = params['empty_start_rate']\n",
    "\n",
    "    self.n_item = self.env.action_space['item_id'][1]\n",
    "\n",
    "    # (N)\n",
    "    self.candidate_iids = np.arange(1, self.n_item + 1)\n",
    "\n",
    "    # (N, item_dim)\n",
    "    self.candidate_features = torch.FloatTensor(\n",
    "        self.env.reader.get_item_list_meta(self.candidate_iids)).to(self.device)\n",
    "    self.candidate_iids = torch.tensor(self.candidate_iids).to(self.device)\n",
    "\n",
    "    # replay buffer is initialized in initialize_train()\n",
    "    self.buffer_size = params['buffer_size']\n",
    "    self.start_timestamp = params['start_timestamp']\n",
    "\n",
    "  def initialize_train(self):\n",
    "    '''\n",
    "    Procedures before training\n",
    "    '''\n",
    "    self.buffer = {\n",
    "        \"user_profile\": torch.zeros(self.buffer_size, self.env.reader.portrait_len),\n",
    "        \"history\":torch.zeros(self.buffer_size, self.env.reader.max_seq_len).to(torch.long),\n",
    "        \"next_history\":torch.zeros(self.buffer_size, self.env.reader.max_seq_len).to(torch.long),\n",
    "        \"state_emb\": torch.zeros(self.buffer_size, self.actor.state_dim),\n",
    "        \"action_emb\":torch.zeros(self.buffer_size, self.actor.action_dim),\n",
    "        \"action\":torch.zeros(self.buffer_size, self.slate_size, dtype=torch.long),\n",
    "        \"reward\":torch.zeros(self.buffer_size),\n",
    "        \"min_reward\": torch.zeros(self.buffer_size),\n",
    "        \"feedback\": torch.zeros(self.buffer_size, self.slate_size),\n",
    "        \"done\": torch.zeros(self.buffer_size, dtype=torch.bool)\n",
    "    }\n",
    "\n",
    "    for k, v in self.buffer.items():\n",
    "      self.buffer[k] = v.to(self.device)\n",
    "    self.buffer_head = 0\n",
    "    self.current_buffer_size = 0\n",
    "    self.n_stream_record = 0\n",
    "    self.is_training_available = False\n",
    "\n",
    "  def reset_env(self, initial_params = {'batch_size': 1}):\n",
    "    '''\n",
    "    Reset user response environment\n",
    "    '''\n",
    "    initial_params['empty_history'] = True if np.random.rand() < self.empty_start_rate else False\n",
    "    initial_observation = self.env.reset(initial_params)\n",
    "    return initial_observation\n",
    "\n",
    "  def env_step(self, policy_output):\n",
    "    action_dict = {\n",
    "      'action': policy_output['action'],\n",
    "      'action_features': policy_output['action_features']\n",
    "    }\n",
    "    observation, reward, done, info = self.env.step(action_dict)\n",
    "    return observation, reward, done, info\n",
    "\n",
    "  def stop_env(self):\n",
    "    self.env.stop()\n",
    "\n",
    "  def get_episode_report(self, n_recent = 10):\n",
    "    recent_rewards = self.env.reward_history[-n_recent:]\n",
    "    recent_steps = self.env.step_history[-n_recent:]\n",
    "    epsiode_report = {\n",
    "        'average_total_reward': np.mean(recent_rewards),\n",
    "        'reward_variance': np.var(recent_rewards),\n",
    "        'max_total_reward': np.max(recent_rewards),\n",
    "        'min_total_reward': np.min(recent_rewards),\n",
    "        'average_n_step': np.mean(recent_steps),\n",
    "        'max_n_step': np.max(recent_steps),\n",
    "        'min_n_step': np.min(recent_steps),\n",
    "        'buffer_size': self.current_buffer_size\n",
    "    }\n",
    "    return epsiode_report\n",
    "\n",
    "  def apply_critic(self, observation, policy_output, critic_model):\n",
    "    feed_dict = {\n",
    "        'state_emb': policy_output['state_emb'],\n",
    "        'action_emb': policy_output['action_emb']\n",
    "    }\n",
    "    critic_output = critic_model(feed_dict)\n",
    "    return critic_output\n",
    "\n",
    "  def apply_policy(self, observation, policy_model, epsilon = 0, \n",
    "                 do_explore = False, do_softmax = True):\n",
    "    '''\n",
    "    @input:\n",
    "    - observation: input of policy model\n",
    "    - policy_model\n",
    "    - epsilon: greedy epsilon, effective only when do_explore == True\n",
    "    - do_explore: exploration flag, True if adding noise to action\n",
    "    - do_softmax: output softmax score\n",
    "    '''\n",
    "#         feed_dict = utils.wrap_batch(observation, device = self.device)\n",
    "    feed_dict = observation\n",
    "    out_dict = policy_model(feed_dict)\n",
    "    if do_explore:\n",
    "        action_emb = out_dict['action_emb']\n",
    "        # sampling noise of action embedding\n",
    "        if np.random.rand() < epsilon:\n",
    "            action_emb = torch.clamp(torch.rand_like(action_emb)*self.noise_var, -1, 1)\n",
    "        else:\n",
    "            action_emb = action_emb + torch.clamp(torch.rand_like(action_emb)*self.noise_var, -1, 1)\n",
    "#                 self.noise_var -= self.noise_decay\n",
    "        out_dict['action_emb'] = action_emb\n",
    "        \n",
    "    if 'candidate_ids' in feed_dict:\n",
    "        # (B, L, item_dim)\n",
    "        out_dict['candidate_features'] = feed_dict['candidate_features']\n",
    "        # (B, L)\n",
    "        out_dict['candidate_ids'] = feed_dict['candidate_ids']\n",
    "        batch_wise = True\n",
    "    else:\n",
    "        # (1,L,item_dim)\n",
    "        out_dict['candidate_features'] = self.candidate_features.unsqueeze(0)\n",
    "        # (L,)\n",
    "        out_dict['candidate_ids'] = self.candidate_iids\n",
    "        batch_wise = False\n",
    "        \n",
    "    # action prob (B,L)\n",
    "    action_prob = policy_model.score(out_dict['action_emb'], \n",
    "                                     out_dict['candidate_features'], \n",
    "                                     do_softmax = do_softmax)\n",
    "\n",
    "    # two types of greedy selection\n",
    "    if np.random.rand() >= self.topk_rate:\n",
    "        # greedy random: categorical sampling\n",
    "        action, indices = utils.sample_categorical_action(action_prob, out_dict['candidate_ids'], \n",
    "                                                          self.slate_size, with_replacement = False, \n",
    "                                                          batch_wise = batch_wise, return_idx = True)\n",
    "    else:\n",
    "        # indices on action_prob\n",
    "        _, indices = torch.topk(action_prob, k = self.slate_size, dim = 1)\n",
    "        # topk action\n",
    "        if batch_wise:\n",
    "            action = torch.gather(out_dict['candidate_ids'], 1, indices).detach() # (B, slate_size)\n",
    "        else:\n",
    "            action = out_dict['candidate_ids'][indices].detach() # (B, slate_size)\n",
    "    # (B,K)\n",
    "    out_dict['action'] = action \n",
    "    # (B,K,item_dim)\n",
    "    out_dict['action_features'] = self.candidate_features[action-1]\n",
    "    # (B,K)\n",
    "    out_dict['action_prob'] = torch.gather(action_prob, 1, indices) \n",
    "    # (B,L)\n",
    "    out_dict['candidate_prob'] = action_prob\n",
    "    return out_dict\n",
    "\n",
    "  def sample_buffer(self, batch_size):\n",
    "    '''\n",
    "    @output:\n",
    "    - observation\n",
    "    - policy output\n",
    "    - reward\n",
    "    - done_mask\n",
    "    - next_observation\n",
    "    '''\n",
    "    indices = np.random.randint(0, self.current_buffer_size, size = batch_size)\n",
    "    U, H, N, S, HA, A, R, F, D, MR = self.read_buffer(indices)\n",
    "    observation = {\n",
    "        'user_profile': U,\n",
    "        'history_features': H,\n",
    "        'min_reward': MR\n",
    "    }\n",
    "    policy_output = {\n",
    "        'state_emb': S,\n",
    "        'action_emb': HA,\n",
    "        'action': A\n",
    "    }\n",
    "    reward = R\n",
    "    done_mask = D\n",
    "    next_observation = {\n",
    "        'user_profile': U,\n",
    "        'history_features': N,\n",
    "        'min_reward': MR,\n",
    "        'previous_feedback': F\n",
    "    }\n",
    "    return observation, policy_output, reward, done_mask, next_observation\n",
    "\n",
    "  # def sample_raw_data(self, batch_size):\n",
    "  #   '''\n",
    "  #   Sample supervise data from raw training data\n",
    "  #   '''\n",
    "  #   batch = self.env.sample_user(batch_size)\n",
    "\n",
    "  def update_buffer(self, observation, policy_output, reward, done_mask,\n",
    "                    next_observation, info):\n",
    "    # Overwrite old entries in buffer\n",
    "    if self.buffer_head + reward.shape[0] >= self.buffer_size:\n",
    "      tail = self.buffer_size - self.buffer_head\n",
    "      indices = [self.buffer_head + i for i in range(tail)] + \\\n",
    "       [i for i in range(reward.shape[0] - tail)]\n",
    "    else:\n",
    "      indices = [self.buffer_head  + i for i in range(reward.shape[0])]\n",
    "\n",
    "    # update buffer\n",
    "    self.buffer[\"user_profile\"][indices] = observation['user_profile']\n",
    "    self.buffer[\"history\"][indices] = observation['history']\n",
    "    self.buffer[\"min_reward\"][indices] = observation['min_reward']\n",
    "    self.buffer[\"next_history\"][indices] = next_observation['history']\n",
    "    self.buffer[\"state_emb\"][indices] = policy_output['state_emb']\n",
    "    self.buffer[\"action\"][indices] = policy_output['action']\n",
    "    self.buffer[\"action_emb\"][indices] = policy_output['action_emb']\n",
    "    self.buffer[\"reward\"][indices] = reward\n",
    "    self.buffer[\"feedback\"][indices] = info['response']\n",
    "    self.buffer[\"done\"][indices] = done_mask\n",
    "\n",
    "    # update buffer pointer\n",
    "    self.buffer_head = (self.buffer_head + reward.shape[0]) % self.buffer_size\n",
    "    self.n_stream_record += reward.shape[0]\n",
    "    self.current_buffer_size = min(self.n_stream_record, self.buffer_size)\n",
    "\n",
    "    # available training when sufficient sample buffer\n",
    "    if self.n_stream_record >= self.start_timestamp:\n",
    "      self.is_training_available = True\n",
    "  def read_buffer(self, indices):\n",
    "    U = self.buffer['user_profile'][indices]\n",
    "    # (L, item_dim)\n",
    "    H = self.candidate_features[self.buffer[\"history\"][indices] - 1]\n",
    "    N = self.candidate_features[self.buffer[\"next_history\"][indices] - 1]\n",
    "    S = self.buffer[\"state_emb\"][indices]\n",
    "    HA = self.buffer[\"action_emb\"][indices]\n",
    "    A = self.buffer[\"action\"][indices]\n",
    "    R = self.buffer[\"reward\"][indices]\n",
    "    F = self.buffer[\"feedback\"][indices]\n",
    "    D = self.buffer[\"done\"][indices]\n",
    "    MR = self.buffer['min_reward'][indices]\n",
    "    return U, H, N, S, HA, A, R, F, D, MR\n",
    "\n",
    "  def extract_behavior_data(self, observation, policy_output, next_observation):\n",
    "    '''\n",
    "    Extract supervised data from RL samples\n",
    "    '''\n",
    "    observation = {\n",
    "        \"user_profile\": observation['user_profile'],\n",
    "        \"history_features\": observation['history_features']\n",
    "    }\n",
    "    exposed_items = policy_output['action']\n",
    "    exposure = {\n",
    "        \"ids\": exposed_items,\n",
    "        \"features\": self.candidate_features[exposed_items - 1]\n",
    "    }\n",
    "    user_feedback = next_observation[\"previous_feedback\"]\n",
    "    return observation, exposure, user_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee24bf42",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.522113Z",
     "iopub.status.busy": "2025-07-22T06:38:14.521681Z",
     "iopub.status.idle": "2025-07-22T06:38:14.530740Z",
     "shell.execute_reply": "2025-07-22T06:38:14.530057Z"
    },
    "id": "_H8nHNkrZdnk",
    "papermill": {
     "duration": 0.030836,
     "end_time": "2025-07-22T06:38:14.531731",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.500895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title One Stage Facade with Hyper Action\n",
    "\n",
    "class OneStageFacade_HyperAction(OneStageFacade):\n",
    "  def __init__(self, environment, actor, critic, params):\n",
    "    super().__init__(environment, actor, critic, params)\n",
    "\n",
    "  def apply_policy(self, observation, policy_model, epsilon = 0,\n",
    "                   do_explore = False, do_softmax = True):\n",
    "    feed_dict = wrap_batch(observation, device=device)\n",
    "    # print(feed_dict.device)\n",
    "    out_dict = policy_model(feed_dict)\n",
    "    if do_explore:\n",
    "      action_emb = out_dict['action_emb']\n",
    "      # explore and exploit + clamping\n",
    "      if np.random.rand() < epsilon:\n",
    "        action_emb = torch.clamp(torch.rand_like(action_emb) * self.noise_var, -1, 1)\n",
    "      else:\n",
    "        action_emb = action_emb + torch.clamp(torch.rand_like(action_emb) * self.noise_var, -1, 1)\n",
    "\n",
    "      out_dict['action_emb'] = action_emb\n",
    "\n",
    "    # Z latent space\n",
    "    out_dict['Z'] = out_dict['action_emb']\n",
    "\n",
    "    if 'candidate_ids' in feed_dict:\n",
    "      # (B, L, item_dim)\n",
    "      out_dict['candidate_features']  = feed_dict['candidate_features']\n",
    "      # (B, L)\n",
    "      out_dict['candidate_ids'] = feed_dict['candidate_ids']\n",
    "      batch_wise = True\n",
    "    else:\n",
    "      # (1, L, item_dim)\n",
    "      out_dict['candidate_features'] = self.candidate_features.unsqueeze(0)\n",
    "      #(L, )\n",
    "      out_dict['candidate_ids'] = self.candidate_iids\n",
    "      batch_wise = False\n",
    "\n",
    "    # action pron (B, L)\n",
    "    action_prob = policy_model.score(out_dict['action_emb'],\n",
    "                                      out_dict['candidate_features'],\n",
    "                                      do_softmax=do_softmax)\n",
    "\n",
    "    # two types of greedy selection\n",
    "    if np.random.rand() >= self.topk_rate:\n",
    "      # greedy random\n",
    "      action, indices = sample_categorical_action(action_prob, out_dict['candidate_ids'],\n",
    "                                                  self.slate_size, with_replacement=False,\n",
    "                                                  batch_wise=batch_wise,\n",
    "                                                  return_idx=True)\n",
    "    else:\n",
    "      # indices on action_prob\n",
    "      _, indices = torch.topk(action_prob, k = self.slate_size, dim = 1)\n",
    "      # print(indices.shape)\n",
    "      # print(self.candidate_features.shape)\n",
    "      # top k action:\n",
    "      # (B, slate_size)\n",
    "      if batch_wise:\n",
    "        action = torch.gather(out_dict['candidate_ids'], 1, indices).detach()\n",
    "      else:\n",
    "        action = out_dict['candidate_ids'][indices].detach()\n",
    "\n",
    "    # (B, K)\n",
    "    out_dict['action'] = action\n",
    "    # (B, K, item_dim)\n",
    "    out_dict['action_features'] = self.candidate_features[indices]\n",
    "    # (B, K)\n",
    "    out_dict['action_prob'] = torch.gather(action_prob, 1, indices)\n",
    "    # (B, L)\n",
    "    out_dict['candidate_prob'] = action_prob\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "  def infer_hyper_action(self, observation, policy_output, actor):\n",
    "    '''\n",
    "    Inverse function A -> Z\n",
    "    '''\n",
    "    # (B, K)\n",
    "    A = policy_output['action']\n",
    "\n",
    "    # (B, K, item_dim)\n",
    "    item_embs = self.candidate_features[A - 1]\n",
    "\n",
    "    # (B, K, kernel_dim)\n",
    "    Z = torch.mean(actor.item_map(item_embs).view(A.shape[0], A.shape[1], -1), dim = 1)\n",
    "    return {\n",
    "        'Z': Z,\n",
    "        'action_emb': Z,\n",
    "        'state_emb': policy_output['state_emb']\n",
    "    }\n",
    "\n",
    "  def apply_critic(self, observation, policy_output, critic_model):\n",
    "    feed_dict = {\n",
    "        'state_emb': policy_output['state_emb'],\n",
    "        'action_emb': policy_output['action_emb']\n",
    "    }\n",
    "    critic_output = critic_model(feed_dict)\n",
    "    return critic_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b7676b",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.571491Z",
     "iopub.status.busy": "2025-07-22T06:38:14.571293Z",
     "iopub.status.idle": "2025-07-22T06:38:14.581777Z",
     "shell.execute_reply": "2025-07-22T06:38:14.581120Z"
    },
    "id": "wJKb3K_326B5",
    "papermill": {
     "duration": 0.031601,
     "end_time": "2025-07-22T06:38:14.582854",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.551253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Base RL Agent\n",
    "\n",
    "\n",
    "\n",
    "class BaseRLAgent():\n",
    "  def __init__(self, facade, params):\n",
    "    self.device = params['device']\n",
    "    self.gamma = params['gamma']\n",
    "    self.n_iter = [0] + params['n_iter']\n",
    "    self.train_every_n_step = params['train_every_n_step']\n",
    "    self.check_episode = params['check_episode']\n",
    "    self.save_path = params['save_path']\n",
    "    self.facade = facade\n",
    "    self.check_episode = params['check_episode']\n",
    "    self.exploration_scheduler = LinearScheduler(int(sum(self.n_iter) * params['elbow_greedy']),\n",
    "                                                 params['final_greedy_epsilon'],\n",
    "                                                 params['initial_greedy_epsilon'])\n",
    "    # if len(self.n_iter) == 2:\n",
    "    #   with open(self.save_path + \".report\", 'w') as outfile:\n",
    "    #     outfile.write()\n",
    "\n",
    "  def train(self):\n",
    "    if len(self.n_iter) > 2:\n",
    "      self.load()\n",
    "\n",
    "    t = time()\n",
    "    start_time = t\n",
    "    print(\"Run procedure before training\")\n",
    "    self.action_before_train()\n",
    "\n",
    "    print(\"Start training\")\n",
    "    observation = self.facade.reset_env({\n",
    "        'batch_size': self.episode_batch_size,\n",
    "    })\n",
    "    step_offset = sum(self.n_iter[:-1])\n",
    "    for i in tqdm(range(step_offset, step_offset + self.n_iter[-1])):\n",
    "      observation = self.run_episode_step(i, self.exploration_scheduler.value(i),\n",
    "                                          observation, True)\n",
    "      if i % self.train_every_n_step == 0:\n",
    "        self.step_train()\n",
    "\n",
    "      if i % self.check_episode == 0:\n",
    "        t_ = time()\n",
    "        # print(f\"Episode step {i}, time diff {t_ - t}, total time dif {t - start_time})\")\n",
    "        self.log_iteration(i)\n",
    "        t = t_\n",
    "        if i % (3*self.check_episode) == 0:\n",
    "            self.save()\n",
    "\n",
    "    self.action_after_train()\n",
    "\n",
    "\n",
    "  def action_before_train(self):\n",
    "    pass\n",
    "\n",
    "  def action_after_train(self):\n",
    "    self.facade.stop_env()\n",
    "\n",
    "\n",
    "  def get_report(self):\n",
    "    episode_report = self.facade.get_episode_report(10)\n",
    "    train_report = {k: np.mean(v[-10:]) for k, v in self.training_history.items()}\n",
    "    return episode_report, train_report\n",
    "\n",
    "  def log_iteration(self, step):\n",
    "    episode_report, train_report = self.get_report()\n",
    "    run.log(episode_report | train_report)\n",
    "    log_str = f\"step: {step} @ episode report: {episode_report} @ step loss: {train_report}\\n\"\n",
    "    with open(self.save_path + \".report\", 'a') as outfile:\n",
    "        outfile.write(log_str)\n",
    "    return log_str\n",
    "\n",
    "  def test(self):\n",
    "    self.load()\n",
    "    self.facade.initialize_train()\n",
    "\n",
    "    t = time()\n",
    "    start_time = t\n",
    "\n",
    "    print(\"Start testing\")\n",
    "    observation = self.facade.reset_env({\n",
    "        'batch_size': self.episode_batch_size,\n",
    "    })\n",
    "    step_offset = sum(self.n_iter[:-1])\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(step_offset, step_offset + self.n_iter[-1])):\n",
    "          observation = self.run_episode_step(i, self.exploration_scheduler.value(i),\n",
    "                                              observation, True)\n",
    "          if i % self.check_episode == 0:\n",
    "            t_ = time()\n",
    "            episode_report = self.facade.get_episode_report(10)\n",
    "            log_str = f\"step: {i} @ episode report: {episode_report}\\n\"\n",
    "            run.log(episode_report)\n",
    "            with open(self.save_path + \"_eval.report\", 'a') as outfile:\n",
    "              outfile.write(log_str)\n",
    "            # print(f\"Episode step {i}, time diff {t_ - t}, total time dif {t - start_time})\")\n",
    "            # print(log_str)\n",
    "            t = t_\n",
    "    \n",
    "\n",
    "  #######################################\n",
    "  #           Abstract function         #\n",
    "  #######################################\n",
    "  def run_episode_step(self, *episode_args):\n",
    "    pass\n",
    "\n",
    "  def step_train(self):\n",
    "    pass\n",
    "\n",
    "  def save(self):\n",
    "    pass\n",
    "\n",
    "  def load(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "701bb83c",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.622810Z",
     "iopub.status.busy": "2025-07-22T06:38:14.622610Z",
     "iopub.status.idle": "2025-07-22T06:38:14.637165Z",
     "shell.execute_reply": "2025-07-22T06:38:14.636481Z"
    },
    "id": "VBbJXf-KfvDA",
    "papermill": {
     "duration": 0.035808,
     "end_time": "2025-07-22T06:38:14.638227",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.602419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Deep Deterministic Policy Gradient\n",
    "\n",
    "\n",
    "class DDPG(BaseRLAgent):\n",
    "  def __init__(self, facade, params):\n",
    "    super().__init__(facade, params)\n",
    "    self.actor = facade.actor\n",
    "    self.actor_target = copy.deepcopy(self.actor)\n",
    "    self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr = params['actor_lr'], weight_decay = params['actor_decay'])\n",
    "\n",
    "    self.critic = facade.critic\n",
    "    self.critic_target = copy.deepcopy(self.critic)\n",
    "    self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr = params['critic_lr'], weight_decay = params['critic_decay'])\n",
    "\n",
    "    self.episode_batch_size = params['episode_batch_size']\n",
    "    self.tau = params['target_mitigate_coef']\n",
    "    self.actor_lr = params['actor_lr']\n",
    "    self.critic_lr = params['critic_lr']\n",
    "    self.actor_decay = params['actor_decay']\n",
    "    self.critic_decay = params['critic_decay']\n",
    "\n",
    "    self.batch_size = params['batch_size']\n",
    "\n",
    "    with open(self.save_path + \".report\", 'w') as outfile:\n",
    "      pass\n",
    "\n",
    "  def action_before_train(self):\n",
    "    '''\n",
    "    - facade setup\n",
    "      - buffer setup\n",
    "    - run random episodes to build-up the initial buffer\n",
    "    '''\n",
    "    self.facade.initialize_train()\n",
    "    # print(\"Facade Parameters:\")\n",
    "    # for param, value in vars(self.facade).items():\n",
    "    #     print(f\"{param}: {value}\")\n",
    "    prepare_step = 0\n",
    "    # random explore before training\n",
    "    initial_epsilon = 1.0\n",
    "    observation = self.facade.reset_env({\n",
    "        'batch_size': self.episode_batch_size,\n",
    "    })\n",
    "    while not self.facade.is_training_available:\n",
    "      observation = self.run_episode_step(0, initial_epsilon, observation, True)\n",
    "      # print(observation)\n",
    "      prepare_step += 1\n",
    "\n",
    "    # training records\n",
    "    self.training_history = {\"critic_loss\": [], \"actor_loss\": []}\n",
    "\n",
    "    print(f\"Total {prepare_step} prepare steps\")\n",
    "\n",
    "  def run_episode_step(self, *episode_args):\n",
    "    '''\n",
    "    One step of interaction\n",
    "    '''\n",
    "    episode_iter, epsilon, observation, do_buffer_update = episode_args\n",
    "    with torch.no_grad():\n",
    "      # sample action\n",
    "      policy_output = self.facade.apply_policy(observation, self.actor, epsilon,\n",
    "                                               do_explore=True)\n",
    "\n",
    "      # apply action on environment and update replay buffer\n",
    "      next_observation, reward, done, info = self.facade.env_step(policy_output)\n",
    "\n",
    "      # update replay buffer\n",
    "      if do_buffer_update:\n",
    "        self.facade.update_buffer(observation, policy_output, reward, done,\n",
    "                                  next_observation, info)\n",
    "    return next_observation\n",
    "\n",
    "  def step_train(self):\n",
    "    observation , policy_output, reward, done_mask, next_observation = self.facade.sample_buffer(params['batch_size'])\n",
    "\n",
    "    critic_loss, actor_loss = self.get_ddpg_loss(observation, policy_output, reward,\n",
    "                                                  done_mask, next_observation)\n",
    "    self.training_history[\"critic_loss\"].append(critic_loss.item())\n",
    "    self.training_history[\"actor_loss\"].append(actor_loss.item())\n",
    "\n",
    "    # Update the frozen target models\n",
    "    for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "      target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
    "\n",
    "    for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "      target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
    "\n",
    "    return {'step_loss': (self.training_history['actor_loss'][-1],\n",
    "                          self.training_history['critic_loss'][-1])}\n",
    "\n",
    "  def get_ddpg_loss(self, observation, policy_output, reward, done_mask, next_observation,\n",
    "                    do_actor_update = True, do_critic_update = True):\n",
    "    # Get current Q estimate\n",
    "    current_critic_output = self.facade.apply_critic(observation,\n",
    "                                                     wrap_batch(policy_output, device=self.device),\n",
    "                                                     self.critic)\n",
    "    current_Q = current_critic_output['q']\n",
    "\n",
    "    # Compute the target Q value\n",
    "    next_policy_output = self.facade.apply_policy(next_observation, self.actor_target)\n",
    "    target_critic_output = self.facade.apply_critic(next_observation, next_policy_output,\n",
    "                                                    self.critic_target)\n",
    "\n",
    "    target_Q = target_critic_output['q']\n",
    "    target_Q = reward + self.gamma * (done_mask * target_Q).detach()\n",
    "\n",
    "    # compute critic loss\n",
    "    # minimize current_Q predict and target_Q predict\n",
    "    critic_loss = F.mse_loss(current_Q, target_Q).mean()\n",
    "\n",
    "    if do_critic_update and self.critic_lr > 0:\n",
    "      # Optimize the critic\n",
    "      self.critic_optimizer.zero_grad()\n",
    "      critic_loss.backward()\n",
    "      self.critic_optimizer.step()\n",
    "\n",
    "    # compute actor loss\n",
    "    policy_output = self.facade.apply_policy(observation, self.actor)\n",
    "    critic_output = self.facade.apply_critic(observation, policy_output, self.critic)\n",
    "\n",
    "    # Maximize Q value\n",
    "    actor_loss = -critic_output['q'].mean()\n",
    "\n",
    "    if do_actor_update and self.actor_lr > 0:\n",
    "      # Optimize the actor\n",
    "      self.actor_optimizer.zero_grad()\n",
    "      actor_loss.backward()\n",
    "      self.actor_optimizer.step()\n",
    "    return critic_loss, actor_loss\n",
    "\n",
    "  def save(self):\n",
    "    torch.save(self.critic.state_dict(), self.save_path + \"_critic\")\n",
    "    torch.save(self.critic_optimizer.state_dict(), self.save_path + \"_critic_optimizer\")\n",
    "    torch.save(self.actor.state_dict(), self.save_path + \"_actor\")\n",
    "    torch.save(self.actor_optimizer.state_dict(), self.save_path + \"_actor_optimizer\")\n",
    "\n",
    "  def load(self):\n",
    "    self.critic.load_state_dict(torch.load(self.save_path + \"_critic\", map_location=self.device))\n",
    "    self.critic_optimizer.load_state_dict(torch.load(self.save_path + \"_critic_optimizer\", map_location=self.device))\n",
    "    self.critic_target = copy.deepcopy(self.critic)\n",
    "\n",
    "    self.actor.load_state_dict(torch.load(self.save_path + \"_actor\", map_location=self.device))\n",
    "    self.actor_optimizer.load_state_dict(torch.load(self.save_path + \"_actor_optimizer\", map_location=self.device))\n",
    "    self.actor_target = copy.deepcopy(self.actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06f1df5d",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.679870Z",
     "iopub.status.busy": "2025-07-22T06:38:14.679667Z",
     "iopub.status.idle": "2025-07-22T06:38:14.693562Z",
     "shell.execute_reply": "2025-07-22T06:38:14.692844Z"
    },
    "id": "HLBYcDpMSfuw",
    "papermill": {
     "duration": 0.035254,
     "end_time": "2025-07-22T06:38:14.694614",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.659360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# @title Hyper - Actor Critic\n",
    "class HAC(DDPG):\n",
    "  def __init__(self, facade, params):\n",
    "    super().__init__(facade, params)\n",
    "    self.behavior_lr = params['behavior_lr']\n",
    "    self.behavior_decay = params['behavior_decay']\n",
    "    self.hyper_actor_coef = params['hyper_actor_coef']\n",
    "    self.actor_behavior_optimizer = torch.optim.Adam(self.actor.parameters(),\n",
    "                                                     lr=params['behavior_lr'],\n",
    "                                                     weight_decay=params['behavior_decay'])\n",
    "\n",
    "  def action_before_train(self):\n",
    "    super().action_before_train()\n",
    "    self.training_history['hyper_actor_loss'] = []\n",
    "    self.training_history['behavior_loss'] = []\n",
    "    self.training_history['avg_per_session'] = []\n",
    "\n",
    "  def run_episode_step(self, *episode_args):\n",
    "    '''\n",
    "    One step of interaction\n",
    "    '''\n",
    "    episode_iter, epsilon, observation, do_buffer_update = episode_args\n",
    "    with torch.no_grad():\n",
    "      # sample action\n",
    "      policy_output = self.facade.apply_policy(observation, self.actor, epsilon,\n",
    "                                               do_explore=True)\n",
    "\n",
    "      # apply action on environment and update replay buffer\n",
    "      next_observation, reward, done, info = self.facade.env_step(policy_output)\n",
    "\n",
    "      # update replay buffer\n",
    "      if do_buffer_update:\n",
    "        self.facade.update_buffer(observation, policy_output, reward, done,\n",
    "                                  next_observation, info)\n",
    "    return next_observation\n",
    "\n",
    "  def step_train(self):\n",
    "    observation , policy_output, reward, done_mask, next_observation = self.facade.sample_buffer(params['batch_size'])\n",
    "    # reward  = torch.FloatTensor(reward)\n",
    "    # done_mask = torch.FloatTensor(done_mask)\n",
    "\n",
    "    critic_loss, actor_loss, hyper_actor_loss = self.get_hac_loss(observation, policy_output, reward,\n",
    "                                                  done_mask, next_observation)\n",
    "    behavior_loss = self.get_behavior_loss(observation, policy_output, next_observation)\n",
    "\n",
    "    self.training_history[\"critic_loss\"].append(critic_loss.item())\n",
    "    self.training_history[\"actor_loss\"].append(actor_loss.item())\n",
    "    self.training_history['hyper_actor_loss'].append(hyper_actor_loss.item())\n",
    "    self.training_history['behavior_loss'].append(behavior_loss.item())\n",
    "\n",
    "    # Update frozen target models\n",
    "    for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "      target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
    "\n",
    "    for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "      target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
    "\n",
    "    return {\"step_loss\": (self.training_history['actor_loss'][-1],\n",
    "                          self.training_history['critic_loss'][-1],\n",
    "                          self.training_history['hyper_actor_loss'][-1],\n",
    "                          self.training_history['behavior_loss'][-1])}\n",
    "\n",
    "  def get_hac_loss(self, observation, policy_output, reward, done_mask, next_observation,\n",
    "                    do_actor_update = True, do_critic_update = True):\n",
    "    # nsw reward\n",
    "    cummulative_r = reward\n",
    "    avg_r = observation['min_reward']\n",
    "    self.training_history['avg_per_session'].append(avg_r.mean().item())\n",
    "    # min_r = torch.where(torch.isinf(min_r), torch.zeros_like(min_r), min_r)\n",
    "    # Replace 0 with small epsilon for safe division\n",
    "    \n",
    "    # Current Q estimate\n",
    "    hyper_output = self.facade.infer_hyper_action(observation, policy_output, self.actor)\n",
    "    current_critic_output = self.facade.apply_critic(observation, hyper_output, self.critic)\n",
    "    current_Q = current_critic_output['q']\n",
    "\n",
    "    # Compute target Q value\n",
    "    next_policy_output = self.facade.apply_policy(next_observation, self.actor_target)\n",
    "    target_critic_output = self.facade.apply_critic(next_observation, next_policy_output, self.critic_target)\n",
    "\n",
    "    target_Q = target_critic_output['q']\n",
    "    mask = 1 - done_mask.float()\n",
    "    target_Q = cummulative_r + self.gamma * (mask * target_Q).detach()\n",
    "\n",
    "\n",
    "    critic_loss = F.mse_loss(current_Q, target_Q).mean()\n",
    "    if do_critic_update and self.critic_lr > 0:\n",
    "      self.critic_optimizer.zero_grad()\n",
    "      critic_loss.backward()\n",
    "      self.critic_optimizer.step()\n",
    "\n",
    "    # actor loss\n",
    "\n",
    "    if do_actor_update and self.actor_lr > 0:\n",
    "      self.actor_optimizer.zero_grad()\n",
    "      policy_output = self.facade.apply_policy(observation, self.actor)\n",
    "      critic_output = self.facade.apply_critic(observation, policy_output, self.critic)\n",
    "      actor_loss = -nsw(critic_output['q'], avg_r).mean()\n",
    "      actor_loss.backward()\n",
    "      self.actor_optimizer.step()\n",
    "\n",
    "    # hyper actor loss\n",
    "\n",
    "    if do_actor_update and self.hyper_actor_coef > 0:\n",
    "      self.actor_optimizer.zero_grad()\n",
    "      policy_output = self.facade.apply_policy(observation, self.actor)\n",
    "      inferred_hyper_output = self.facade.infer_hyper_action(observation, policy_output, self.actor)\n",
    "      hyper_actor_loss = self.hyper_actor_coef * F.mse_loss(inferred_hyper_output['Z'],\n",
    "                                                            policy_output['Z']).mean()\n",
    "\n",
    "      hyper_actor_loss.backward()\n",
    "      self.actor_optimizer.step()\n",
    "\n",
    "    return critic_loss, actor_loss, hyper_actor_loss\n",
    "\n",
    "  def get_behavior_loss(self, observation, policy_output, next_observation, do_update = True):\n",
    "    observation, exposure, feedback = self.facade.extract_behavior_data(observation, policy_output, next_observation)\n",
    "    observation['candidate_ids'] = exposure['ids']\n",
    "    observation['candidate_features'] = exposure['features']\n",
    "    policy_output = self.facade.apply_policy(observation, self.actor, do_softmax=False)\n",
    "    action_prob = torch.sigmoid(policy_output['candidate_prob'])\n",
    "    behavior_loss = F.binary_cross_entropy(action_prob, feedback)\n",
    "\n",
    "    if do_update and self.behavior_lr > 0:\n",
    "      self.actor_behavior_optimizer.zero_grad()\n",
    "      behavior_loss.backward()\n",
    "      self.actor_behavior_optimizer.step()\n",
    "\n",
    "    return behavior_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a6ffa1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T06:38:14.734225Z",
     "iopub.status.busy": "2025-07-22T06:38:14.734009Z",
     "iopub.status.idle": "2025-07-22T07:22:52.637467Z",
     "shell.execute_reply": "2025-07-22T07:22:52.636679Z"
    },
    "id": "q5dd23sM-gSN",
    "outputId": "843e44a9-4951-4d2e-941e-074c5d06af00",
    "papermill": {
     "duration": 2677.924911,
     "end_time": "2025-07-22T07:22:52.638907",
     "exception": false,
     "start_time": "2025-07-22T06:38:14.713996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m23020082\u001b[0m (\u001b[33m23020082-uet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250722_063814-mksdh2al\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfeasible-darkness-153\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC/runs/mksdh2al\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load item meta data\n",
      "{'length': 77906, 'n_item': 3952, 'item_vec_size': 18, 'user_portrait_len': 30, 'max_seq_len': 50}\n",
      "Run procedure before training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/464574493.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(params['model_path'] + \".checkpoint\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 63 prepare steps\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50000/50000 [44:30<00:00, 18.72it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           actor_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       average_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: average_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      avg_per_session \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        behavior_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          buffer_size \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          critic_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     hyper_actor_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           max_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     max_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           min_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     min_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      reward_variance \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           actor_loss -1.09477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       average_n_step 14.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: average_total_reward 13.85\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      avg_per_session 0.89685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        behavior_loss 0.13844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          buffer_size 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          critic_loss 1.92796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     hyper_actor_loss 0.00031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           max_n_step 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     max_total_reward 16.78\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           min_n_step 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     min_total_reward 11.12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      reward_variance 2.63114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mfeasible-darkness-153\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC/runs/mksdh2al\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at: \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250722_063814-mksdh2al/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# @ ML1M setting\n",
    "\n",
    "params['n_worker'] = 4\n",
    "params['max_seq_len'] = 50\n",
    "\n",
    "params['loss_type'] = 'bce'\n",
    "params['device'] = device\n",
    "params['l2_coef'] = 0.001\n",
    "params['lr'] = 0.0003\n",
    "params['feature_dim'] = 16\n",
    "params['hidden_dims'] = [256]\n",
    "params['attn_n_head'] = 2\n",
    "params['batch_size'] = 128\n",
    "params['epoch'] = 2\n",
    "params['dropout_rate'] = 0.2\n",
    "params['max_step'] = 20\n",
    "params['initial_temper'] = 20\n",
    "params['reward_function'] = mean_with_cost\n",
    "params['sasrec_n_layer'] = 2\n",
    "params['sasrec_d_model'] = 32\n",
    "params['sasrec_n_head'] = 4\n",
    "params['sasrec_dropout'] = 0.1\n",
    "params['sasrec_d_forward'] = 64\n",
    "params['critic_hidden_dims'] = [256, 64]\n",
    "params['critic_dropout_rate'] = 0.2\n",
    "params['n_iter']= [50000]\n",
    "params['slate_size'] = 10\n",
    "params['noise_var'] = 0.1\n",
    "params['q_laplace_smoothness'] = 0.5\n",
    "params['topk_rate'] = 1\n",
    "params['empty_start_rate'] = 0\n",
    "params['buffer_size'] = 100000\n",
    "params['start_timestamp'] = 2000\n",
    "params['gamma'] = 0.9\n",
    "params['train_every_n_step']= 1\n",
    "params['initial_greedy_epsilon'] = 0\n",
    "params['final_greedy_epsilon'] = 0\n",
    "params['elbow_greedy'] = 0.1\n",
    "params['check_episode'] = 10\n",
    "params['with_eval'] = False\n",
    "\n",
    "params['episode_batch_size'] = 32\n",
    "params['batch_size'] = 64\n",
    "params['actor_lr'] = 0.0003\n",
    "params['critic_lr'] = 0.001\n",
    "params['actor_decay'] = 0.00001\n",
    "params['critic_decay'] = 0.00001\n",
    "params['target_mitigate_coef'] = 0.01\n",
    "params['behavior_lr'] = 0.0003\n",
    "params['behavior_decay'] = 0.00001\n",
    "params['hyper_actor_coef'] = 0.1\n",
    "params['advantage_bias'] = 0\n",
    "params['entropy_coef'] = 0.0001\n",
    "\n",
    "config = params.copy()\n",
    "config.pop(\"train\", None)\n",
    "config.pop(\"val\", None)\n",
    "config.pop(\"item_meta\", None)\n",
    "config.pop(\"user_meta\", None)\n",
    "\n",
    "\n",
    "for seed in [19]:\n",
    "    params['seed'] = seed\n",
    "    set_random_seed(params['seed'])\n",
    "    params['save_path'] = os.path.join(path_to_output, f\"agent/ml1m_model_seed{params['seed']}\")\n",
    "    run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"23020082-uet\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"HAC\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config=config\n",
    "    )\n",
    "    os.makedirs(os.path.dirname(params['save_path']), exist_ok=True)\n",
    "    \n",
    "    env = ML1MEnvironment(params)\n",
    "    \n",
    "    policy = SASRec(env, params)\n",
    "    policy.to(device)\n",
    "    \n",
    "    \n",
    "    critic = GeneralCritic(policy, params)\n",
    "    critic.to(device)\n",
    "    \n",
    "    facade = OneStageFacade_HyperAction(env, policy, critic, params)\n",
    "    agent = HAC(facade, params)\n",
    "    \n",
    "    agent.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddacc379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:22:54.659120Z",
     "iopub.status.busy": "2025-07-22T07:22:54.658280Z",
     "iopub.status.idle": "2025-07-22T07:22:54.663765Z",
     "shell.execute_reply": "2025-07-22T07:22:54.663246Z"
    },
    "papermill": {
     "duration": 1.021467,
     "end_time": "2025-07-22T07:22:54.664805",
     "exception": false,
     "start_time": "2025-07-22T07:22:53.643338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d2d54",
   "metadata": {
    "papermill": {
     "duration": 1.013569,
     "end_time": "2025-07-22T07:22:56.701252",
     "exception": false,
     "start_time": "2025-07-22T07:22:55.687683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd4ed4d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:22:58.649460Z",
     "iopub.status.busy": "2025-07-22T07:22:58.649200Z",
     "iopub.status.idle": "2025-07-22T07:23:00.252446Z",
     "shell.execute_reply": "2025-07-22T07:23:00.251878Z"
    },
    "papermill": {
     "duration": 2.595471,
     "end_time": "2025-07-22T07:23:00.253640",
     "exception": false,
     "start_time": "2025-07-22T07:22:57.658169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>slate_of_items</th>\n",
       "      <th>user_mid</th>\n",
       "      <th>user_mid_history</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 2340, 1836, 3408, 280...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[720, 260, 919, 608, 2692, 1961, 2028, 3105, 9...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1962, 2018, 150, 1028, 1097, 914, 1287, 2797,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[661, 2918, 531, 3114, 2791, 2321, 1029, 1197,...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 1, 0, 1, 1]</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[1545, 527, 595, 2687, 745, 588, 1, 2355, 2294...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                     slate_of_items  \\\n",
       "0        1  [3186, 1270, 1721, 1022, 2340, 1836, 3408, 280...   \n",
       "1        1  [720, 260, 919, 608, 2692, 1961, 2028, 3105, 9...   \n",
       "2        1  [1962, 2018, 150, 1028, 1097, 914, 1287, 2797,...   \n",
       "3        1  [661, 2918, 531, 3114, 2791, 2321, 1029, 1197,...   \n",
       "4        1  [1545, 527, 595, 2687, 745, 588, 1, 2355, 2294...   \n",
       "\n",
       "                         user_mid  \\\n",
       "0  [1, 1, 1, 1, 0, 1, 1, 1, 1, 1]   \n",
       "1  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "2  [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "3  [0, 1, 1, 1, 1, 0, 1, 0, 1, 1]   \n",
       "4  [1, 1, 1, 0, 0, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                    user_mid_history  sequence_id  \n",
       "0                                                 []            0  \n",
       "1  [3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...            1  \n",
       "2  [3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...            2  \n",
       "3  [3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...            3  \n",
       "4  [3186, 1270, 1721, 1022, 1836, 3408, 2804, 120...            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>slate_of_items</th>\n",
       "      <th>user_mid</th>\n",
       "      <th>user_mid_history</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4794</td>\n",
       "      <td>[2087, 1073, 951, 1230, 1256, 3362, 1276, 1304...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1923, 3763, 3702, 3693, 2804, 1196, 541, 1197...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1299, 1394, 3342, 1231, 3683, 1199, 1270, 316...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1259, 3072, 3505, 1291, 1674, 2348, 3753, 969...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1200, 1201, 1240, 457, 589, 377, 2951, 2985, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                     slate_of_items  \\\n",
       "0     4794  [2087, 1073, 951, 1230, 1256, 3362, 1276, 1304...   \n",
       "1     4794  [1923, 3763, 3702, 3693, 2804, 1196, 541, 1197...   \n",
       "2     4794  [1299, 1394, 3342, 1231, 3683, 1199, 1270, 316...   \n",
       "3     4794  [1259, 3072, 3505, 1291, 1674, 2348, 3753, 969...   \n",
       "4     4794  [1200, 1201, 1240, 457, 589, 377, 2951, 2985, ...   \n",
       "\n",
       "                         user_mid  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]   \n",
       "1  [1, 1, 1, 0, 1, 1, 1, 1, 1, 1]   \n",
       "2  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1]   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
       "\n",
       "                                    user_mid_history  sequence_id  \n",
       "0  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            4  \n",
       "1  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            5  \n",
       "2  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            6  \n",
       "3  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            7  \n",
       "4  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3953, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6041, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Load data\n",
    "\n",
    "# @title Load data for ml1m\n",
    "item_info = np.load(os.path.join(path_to_data, \"item_info.npy\"))\n",
    "user_info = np.load(os.path.join(path_to_data, \"user_info.npy\"))\n",
    "train = pd.read_csv(os.path.join(path_to_data, \"all.csv\"), sep=\"@\")\n",
    "test = pd.read_csv(os.path.join(path_to_data, \"test.csv\"), sep=\"@\")\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(item_info.shape)\n",
    "display(user_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90eb3b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:23:02.357352Z",
     "iopub.status.busy": "2025-07-22T07:23:02.356552Z",
     "iopub.status.idle": "2025-07-22T07:23:02.362171Z",
     "shell.execute_reply": "2025-07-22T07:23:02.361606Z"
    },
    "papermill": {
     "duration": 1.049215,
     "end_time": "2025-07-22T07:23:02.363212",
     "exception": false,
     "start_time": "2025-07-22T07:23:01.313997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params['train'] = train\n",
    "params['val'] = test\n",
    "params['item_meta'] = item_info\n",
    "params['user_meta'] = user_info\n",
    "params['seed'] = 26\n",
    "params['model_path'] = os.path.join(path_to_output, \n",
    "                          f\"env/ml1m_user_env_lr{params['lr']}_reg{params['l2_coef']}_eval.model\")\n",
    "set_random_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "077e7b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:23:04.373367Z",
     "iopub.status.busy": "2025-07-22T07:23:04.373059Z",
     "iopub.status.idle": "2025-07-22T07:24:00.639858Z",
     "shell.execute_reply": "2025-07-22T07:24:00.638790Z"
    },
    "papermill": {
     "duration": 57.26528,
     "end_time": "2025-07-22T07:24:00.641018",
     "exception": false,
     "start_time": "2025-07-22T07:23:03.375738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load item meta data\n",
      "{'length': 97383, 'n_item': 3952, 'item_vec_size': 18, 'user_portrait_len': 30, 'max_seq_len': 50}\n",
      "epoch 0 is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97408it [00:23, 4129.69it/s]                           \n",
      "19520it [00:04, 4723.88it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 validating; auc: 0.6019\n",
      "epoch 1 is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97408it [00:24, 4014.53it/s]                           \n",
      "19520it [00:04, 4705.18it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 validating; auc: 0.6076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Train user response\n",
    "reader = ML1MDataReader(params)\n",
    "model = ML1MUserResponse(reader, params).to(device)\n",
    "\n",
    "\n",
    "# reader = RL4RSDataReader(params)\n",
    "# model = RL4RSUserResponse(reader, params).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "model.optimizer = optimizer\n",
    "\n",
    "\n",
    "epo = 0\n",
    "while epo < params['epoch']:\n",
    "  print(f\"epoch {epo} is training\")\n",
    "  epo += 1\n",
    "\n",
    "  model.train()\n",
    "  reader.set_phase(\"train\")\n",
    "  train_loader = DataLoader(reader, params['batch_size'], shuffle = True, pin_memory = True,\n",
    "                            num_workers= params['n_worker'])\n",
    "\n",
    "  t1 = time()\n",
    "  pbar = tqdm(total=len(train_loader.dataset))\n",
    "  step_loss = []\n",
    "  for i, batch_data in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    wrapped_batch = wrap_batch(batch_data, device)\n",
    "\n",
    "    out_dict = model.do_forward_and_loss(wrapped_batch)\n",
    "    loss = out_dict['loss']\n",
    "    loss.backward()\n",
    "    step_loss.append(loss.item())\n",
    "    optimizer.step()\n",
    "    pbar.update(params['batch_size'])\n",
    "    # print(model.loss)\n",
    "    # if (i + 1) % 10 == 0:\n",
    "      # print(f\"Iteration {i + 1}, loss {np.mean(step_loss[-100:])}\")\n",
    "  pbar.close()\n",
    "    # print(\"Epoch {}; time {:.4f}\".format(epo, time() - t1))\n",
    "\n",
    "  # validation\n",
    "  t2 = time()\n",
    "  reader.set_phase(\"val\")\n",
    "  val_loader = DataLoader(reader, params['batch_size'], shuffle = False, pin_memory = False,\n",
    "                          num_workers= params['n_worker'])\n",
    "  valid_probs, valid_true =  [], []\n",
    "  pbar = tqdm(total = len(val_loader.dataset))\n",
    "  with torch.no_grad():\n",
    "    for i, batch_data in enumerate(val_loader):\n",
    "      wrapped_batch = wrap_batch(batch_data, device)\n",
    "      out_dict = model.forward(wrapped_batch)\n",
    "      valid_probs.append(out_dict['probs'].cpu().numpy())\n",
    "      valid_true.append(batch_data['feedback'].cpu().numpy())\n",
    "      pbar.update(params['batch_size'])\n",
    "  pbar.close()\n",
    "  auc = roc_auc_score(np.concatenate(valid_true), np.concatenate(valid_probs))\n",
    "  print(f\"epoch {epo} validating\" + \"; auc: {:.4f}\".format(np.mean(auc)))\n",
    "  model.save_checkpoint()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25b5048e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:24:02.656904Z",
     "iopub.status.busy": "2025-07-22T07:24:02.656292Z",
     "iopub.status.idle": "2025-07-22T07:24:02.941488Z",
     "shell.execute_reply": "2025-07-22T07:24:02.940739Z"
    },
    "id": "JhQPZR_yXqHk",
    "outputId": "cce3f497-89a7-415f-da30-173f195aa5ae",
    "papermill": {
     "duration": 1.287051,
     "end_time": "2025-07-22T07:24:02.942759",
     "exception": false,
     "start_time": "2025-07-22T07:24:01.655708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>slate_of_items</th>\n",
       "      <th>user_mid</th>\n",
       "      <th>user_mid_history</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4794</td>\n",
       "      <td>[2087, 1073, 951, 1230, 1256, 3362, 1276, 1304...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1923, 3763, 3702, 3693, 2804, 1196, 541, 1197...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1299, 1394, 3342, 1231, 3683, 1199, 1270, 316...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1259, 3072, 3505, 1291, 1674, 2348, 3753, 969...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1200, 1201, 1240, 457, 589, 377, 2951, 2985, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                     slate_of_items  \\\n",
       "0     4794  [2087, 1073, 951, 1230, 1256, 3362, 1276, 1304...   \n",
       "1     4794  [1923, 3763, 3702, 3693, 2804, 1196, 541, 1197...   \n",
       "2     4794  [1299, 1394, 3342, 1231, 3683, 1199, 1270, 316...   \n",
       "3     4794  [1259, 3072, 3505, 1291, 1674, 2348, 3753, 969...   \n",
       "4     4794  [1200, 1201, 1240, 457, 589, 377, 2951, 2985, ...   \n",
       "\n",
       "                         user_mid  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]   \n",
       "1  [1, 1, 1, 0, 1, 1, 1, 1, 1, 1]   \n",
       "2  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1]   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
       "\n",
       "                                    user_mid_history  sequence_id  \n",
       "0  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            4  \n",
       "1  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            5  \n",
       "2  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            6  \n",
       "3  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            7  \n",
       "4  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>slate_of_items</th>\n",
       "      <th>user_mid</th>\n",
       "      <th>user_mid_history</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4794</td>\n",
       "      <td>[2087, 1073, 951, 1230, 1256, 3362, 1276, 1304...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1923, 3763, 3702, 3693, 2804, 1196, 541, 1197...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1299, 1394, 3342, 1231, 3683, 1199, 1270, 316...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 0, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1259, 3072, 3505, 1291, 1674, 2348, 3753, 969...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4794</td>\n",
       "      <td>[1200, 1201, 1240, 457, 589, 377, 2951, 2985, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 0, 1, 1]</td>\n",
       "      <td>[593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                     slate_of_items  \\\n",
       "0     4794  [2087, 1073, 951, 1230, 1256, 3362, 1276, 1304...   \n",
       "1     4794  [1923, 3763, 3702, 3693, 2804, 1196, 541, 1197...   \n",
       "2     4794  [1299, 1394, 3342, 1231, 3683, 1199, 1270, 316...   \n",
       "3     4794  [1259, 3072, 3505, 1291, 1674, 2348, 3753, 969...   \n",
       "4     4794  [1200, 1201, 1240, 457, 589, 377, 2951, 2985, ...   \n",
       "\n",
       "                         user_mid  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]   \n",
       "1  [1, 1, 1, 0, 1, 1, 1, 1, 1, 1]   \n",
       "2  [1, 1, 1, 1, 1, 0, 1, 0, 1, 1]   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 1, 0, 1, 1, 0, 1, 1]   \n",
       "\n",
       "                                    user_mid_history  sequence_id  \n",
       "0  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            4  \n",
       "1  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            5  \n",
       "2  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            6  \n",
       "3  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            7  \n",
       "4  [593, 1198, 2683, 2355, 1911, 3543, 3615, 2757...            8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3953, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6041, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Load data\n",
    "\n",
    "# @title Load data for ml1m\n",
    "train = pd.read_csv(os.path.join(path_to_data, \"test.csv\"), sep=\"@\")\n",
    "test = pd.read_csv(os.path.join(path_to_data, \"test.csv\"), sep=\"@\")\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(item_info.shape)\n",
    "display(user_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f34114a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T07:24:05.024179Z",
     "iopub.status.busy": "2025-07-22T07:24:05.023842Z",
     "iopub.status.idle": "2025-07-22T07:40:59.084803Z",
     "shell.execute_reply": "2025-07-22T07:40:59.083911Z"
    },
    "papermill": {
     "duration": 1015.12936,
     "end_time": "2025-07-22T07:40:59.086411",
     "exception": false,
     "start_time": "2025-07-22T07:24:03.957051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type DataFrame that is 16093252 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250722_072405-o49gvdr0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhearty-shape-154\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC/runs/o49gvdr0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load item meta data\n",
      "{'length': 19477, 'n_item': 3952, 'item_vec_size': 18, 'user_portrait_len': 30, 'max_seq_len': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/464574493.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(params['model_path'] + \".checkpoint\", map_location=device)\n",
      "/tmp/ipykernel_19/928354164.py:137: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.critic.load_state_dict(torch.load(self.save_path + \"_critic\", map_location=self.device))\n",
      "/tmp/ipykernel_19/928354164.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.critic_optimizer.load_state_dict(torch.load(self.save_path + \"_critic_optimizer\", map_location=self.device))\n",
      "/tmp/ipykernel_19/928354164.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.actor.load_state_dict(torch.load(self.save_path + \"_actor\", map_location=self.device))\n",
      "/tmp/ipykernel_19/928354164.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.actor_optimizer.load_state_dict(torch.load(self.save_path + \"_actor_optimizer\", map_location=self.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50000/50000 [16:51<00:00, 49.44it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       average_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: average_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          buffer_size \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           max_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     max_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           min_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     min_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      reward_variance \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       average_n_step 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: average_total_reward 6.779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          buffer_size 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           max_n_step 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     max_total_reward 10.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           min_n_step 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     min_total_reward 4.35\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      reward_variance 2.90181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mhearty-shape-154\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC/runs/o49gvdr0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at: \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250722_072405-o49gvdr0/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "params['train'] = test\n",
    "params['test'] = test\n",
    "config = params.copy()\n",
    "config.pop(\"train\", None)\n",
    "config.pop(\"val\", None)\n",
    "config.pop(\"item_meta\", None)\n",
    "config.pop(\"user_meta\", None)\n",
    "\n",
    "for seed in [19]:\n",
    "    params['seed'] = seed\n",
    "    set_random_seed(params['seed'])\n",
    "    params['save_path'] = os.path.join(path_to_output, f\"agent/ml1m_model_seed{params['seed']}\")\n",
    "    run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"23020082-uet\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"HAC\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config=config\n",
    "    )\n",
    "    os.makedirs(os.path.dirname(params['save_path']), exist_ok=True)\n",
    "    \n",
    "    env = ML1MEnvironment(params)\n",
    "    \n",
    "    policy = SASRec(env, params)\n",
    "    policy.to(device)\n",
    "    \n",
    "    \n",
    "    critic = GeneralCritic(policy, params)\n",
    "    critic.to(device)\n",
    "    \n",
    "    facade = OneStageFacade_HyperAction(env, policy, critic, params)\n",
    "    agent = HAC(facade, params)\n",
    "    \n",
    "    agent.test()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc783b4c",
   "metadata": {
    "papermill": {
     "duration": 1.420248,
     "end_time": "2025-07-22T07:41:01.839577",
     "exception": false,
     "start_time": "2025-07-22T07:41:00.419329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7122510,
     "sourceId": 11683390,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 300659,
     "modelInstanceId": 279738,
     "sourceId": 334090,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3838.669846,
   "end_time": "2025-07-22T07:41:06.045565",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-22T06:37:07.375719",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
