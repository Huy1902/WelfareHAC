{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66753428",
   "metadata": {
    "id": "36GFFPEquVlH",
    "papermill": {
     "duration": 0.007721,
     "end_time": "2025-07-10T11:38:13.155838",
     "exception": false,
     "start_time": "2025-07-10T11:38:13.148117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63004b1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:38:13.170732Z",
     "iopub.status.busy": "2025-07-10T11:38:13.170492Z",
     "iopub.status.idle": "2025-07-10T11:38:16.044325Z",
     "shell.execute_reply": "2025-07-10T11:38:16.043262Z"
    },
    "papermill": {
     "duration": 2.883746,
     "end_time": "2025-07-10T11:38:16.046294",
     "exception": false,
     "start_time": "2025-07-10T11:38:13.162548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n"
     ]
    }
   ],
   "source": [
    "!wandb login --relogin c2aabf528c3a17ca15b2306fdef1f0f0d24798bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e43184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:38:16.064987Z",
     "iopub.status.busy": "2025-07-10T11:38:16.064261Z",
     "iopub.status.idle": "2025-07-10T11:38:23.329040Z",
     "shell.execute_reply": "2025-07-10T11:38:23.327928Z"
    },
    "id": "lJ3KHm7bdEpB",
    "outputId": "e85fb76f-ac93-4310-ed56-b532d2b2cbc9",
    "papermill": {
     "duration": 7.274472,
     "end_time": "2025-07-10T11:38:23.330813",
     "exception": false,
     "start_time": "2025-07-10T11:38:16.056341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/hac-rl4rs/item_info.csv\n",
      "/kaggle/input/hac-rl4rs/all.csv\n",
      "/kaggle/input/hac-rl4rs/train.csv\n",
      "/kaggle/input/hac-rl4rs/test.csv\n",
      "/kaggle/input/hac/pytorch/default/1/model_actor\n",
      "/kaggle/input/hac/pytorch/default/1/model_actor_optimizer\n",
      "/kaggle/input/hac/pytorch/default/1/model_critic_optimizer\n",
      "/kaggle/input/hac/pytorch/default/1/model_critic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "from time import time\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544d493c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:38:23.346821Z",
     "iopub.status.busy": "2025-07-10T11:38:23.346440Z",
     "iopub.status.idle": "2025-07-10T11:38:23.602419Z",
     "shell.execute_reply": "2025-07-10T11:38:23.601294Z"
    },
    "papermill": {
     "duration": 0.264923,
     "end_time": "2025-07-10T11:38:23.604069",
     "exception": false,
     "start_time": "2025-07-10T11:38:23.339146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p /kaggle/working/env\n",
    "!mkdir -p /kaggle/working/agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596492ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:38:23.618767Z",
     "iopub.status.busy": "2025-07-10T11:38:23.618497Z",
     "iopub.status.idle": "2025-07-10T11:38:23.709151Z",
     "shell.execute_reply": "2025-07-10T11:38:23.708363Z"
    },
    "id": "batCUlrPrPpR",
    "papermill": {
     "duration": 0.09934,
     "end_time": "2025-07-10T11:38:23.710444",
     "exception": false,
     "start_time": "2025-07-10T11:38:23.611104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Hyperparameter\n",
    "\n",
    "path_to_data = \"/kaggle/input/hac-rl4rs\"\n",
    "path_to_output = \"/kaggle/working/\"\n",
    "\n",
    "\n",
    "cuda = 0\n",
    "if cuda >= 0 and torch.cuda.is_available():\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(cuda)\n",
    "    torch.cuda.set_device(cuda)\n",
    "    device = f\"cuda:{cuda}\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58625c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:38:23.724953Z",
     "iopub.status.busy": "2025-07-10T11:38:23.724712Z",
     "iopub.status.idle": "2025-07-10T11:39:10.849724Z",
     "shell.execute_reply": "2025-07-10T11:39:10.848991Z"
    },
    "papermill": {
     "duration": 47.139057,
     "end_time": "2025-07-10T11:39:10.856589",
     "exception": false,
     "start_time": "2025-07-10T11:38:23.717532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>exposed_items</th>\n",
       "      <th>user_feedback</th>\n",
       "      <th>user_seqfeature</th>\n",
       "      <th>user_protrait</th>\n",
       "      <th>item_feature</th>\n",
       "      <th>behavior_policy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>442720</td>\n",
       "      <td>348225</td>\n",
       "      <td>2</td>\n",
       "      <td>29,25,16,106,114,45,213,196,148</td>\n",
       "      <td>1,1,1,1,1,1,1,1,0</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458306</td>\n",
       "      <td>348226</td>\n",
       "      <td>1</td>\n",
       "      <td>5,6,36,110,61,127,172,239,199</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1352,1.3293,-0.7099...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458307</td>\n",
       "      <td>348226</td>\n",
       "      <td>2</td>\n",
       "      <td>1,4,26,107,61,79,199,164,235</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.0489,-0.3633,-0.1349,1.8061,0.4482,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476558</td>\n",
       "      <td>348227</td>\n",
       "      <td>1</td>\n",
       "      <td>26,14,4,79,113,96,235,199,172</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>0.6758,0.3057,-0.3633,-0.143,1.3991,-0.3773,-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>476559</td>\n",
       "      <td>348227</td>\n",
       "      <td>2</td>\n",
       "      <td>4,14,26,61,113,127,212,239,164</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1423,1.7014,-0.2719...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  session_id  sequence_id                    exposed_items  \\\n",
       "0     442720      348225            2  29,25,16,106,114,45,213,196,148   \n",
       "1     458306      348226            1    5,6,36,110,61,127,172,239,199   \n",
       "2     458307      348226            2     1,4,26,107,61,79,199,164,235   \n",
       "3     476558      348227            1    26,14,4,79,113,96,235,199,172   \n",
       "4     476559      348227            2   4,14,26,61,113,127,212,239,164   \n",
       "\n",
       "       user_feedback                                    user_seqfeature  \\\n",
       "0  1,1,1,1,1,1,1,1,0  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "1  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "2  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "3  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "4  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "\n",
       "                                       user_protrait  \\\n",
       "0  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "1  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "2  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "3  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "4  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "\n",
       "                                        item_feature  behavior_policy_id  \n",
       "0  1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...                   1  \n",
       "1  -0.2137,-0.7579,-0.3633,-0.1352,1.3293,-0.7099...                   1  \n",
       "2  -0.2137,-0.0489,-0.3633,-0.1349,1.8061,0.4482,...                   1  \n",
       "3  0.6758,0.3057,-0.3633,-0.143,1.3991,-0.3773,-1...                   1  \n",
       "4  -0.2137,-0.7579,-0.3633,-0.1423,1.7014,-0.2719...                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>exposed_items</th>\n",
       "      <th>user_feedback</th>\n",
       "      <th>user_seqfeature</th>\n",
       "      <th>user_protrait</th>\n",
       "      <th>item_feature</th>\n",
       "      <th>behavior_policy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>530551</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28,32,5,77,130,76,196,199,172</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>0</td>\n",
       "      <td>64054,2901,63021,88510,10205,7615,54240,37294,...</td>\n",
       "      <td>1.5653,0.6602,-0.3633,-0.1267,1.8759,-0.856,-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>531709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30,28,21,77,73,130,235,196,172</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>0</td>\n",
       "      <td>64054,2901,63021,88510,10205,7615,54240,37294,...</td>\n",
       "      <td>1.5653,2.0783,-0.3633,-0.1426,0.9766,-0.5926,-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550062</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15,36,35,134,128,40,200,219,165</td>\n",
       "      <td>1,1,1,1,1,1,0,1,0</td>\n",
       "      <td>28,32,5,77,130,76,196,172,199,28,30,21,130,73,...</td>\n",
       "      <td>64054,38043,93755,88510,10205,7615,54240,37294...</td>\n",
       "      <td>0.6758,-0.0489,-0.3633,-0.1389,1.8565,-0.0384,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568391</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29,30,34,132,81,57,164,192,212</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>28,32,5,77,130,76,196,172,199,28,30,21,130,73,...</td>\n",
       "      <td>64054,50212,93755,88510,10205,7615,54240,37294...</td>\n",
       "      <td>1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595031</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2,18,21,60,75,85,167,196,237</td>\n",
       "      <td>1,1,1,1,1,1,0,1,1</td>\n",
       "      <td>28,32,5,77,130,76,196,172,199,28,30,21,130,73,...</td>\n",
       "      <td>64054,50212,93755,88510,10205,7615,54240,37294...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1377,1.5852,-0.9129...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  session_id  sequence_id                    exposed_items  \\\n",
       "0     530551           1            1    28,32,5,77,130,76,196,199,172   \n",
       "1     531709           1            2   30,28,21,77,73,130,235,196,172   \n",
       "2     550062           2            1  15,36,35,134,128,40,200,219,165   \n",
       "3     568391           3            1   29,30,34,132,81,57,164,192,212   \n",
       "4     595031           4            1     2,18,21,60,75,85,167,196,237   \n",
       "\n",
       "       user_feedback                                    user_seqfeature  \\\n",
       "0  1,1,1,1,1,1,1,1,1                                                  0   \n",
       "1  1,1,1,1,1,1,1,1,1                                                  0   \n",
       "2  1,1,1,1,1,1,0,1,0  28,32,5,77,130,76,196,172,199,28,30,21,130,73,...   \n",
       "3  1,1,1,1,1,1,1,1,1  28,32,5,77,130,76,196,172,199,28,30,21,130,73,...   \n",
       "4  1,1,1,1,1,1,0,1,1  28,32,5,77,130,76,196,172,199,28,30,21,130,73,...   \n",
       "\n",
       "                                       user_protrait  \\\n",
       "0  64054,2901,63021,88510,10205,7615,54240,37294,...   \n",
       "1  64054,2901,63021,88510,10205,7615,54240,37294,...   \n",
       "2  64054,38043,93755,88510,10205,7615,54240,37294...   \n",
       "3  64054,50212,93755,88510,10205,7615,54240,37294...   \n",
       "4  64054,50212,93755,88510,10205,7615,54240,37294...   \n",
       "\n",
       "                                        item_feature  behavior_policy_id  \n",
       "0  1.5653,0.6602,-0.3633,-0.1267,1.8759,-0.856,-1...                   1  \n",
       "1  1.5653,2.0783,-0.3633,-0.1426,0.9766,-0.5926,-...                   1  \n",
       "2  0.6758,-0.0489,-0.3633,-0.1389,1.8565,-0.0384,...                   1  \n",
       "3  1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...                   1  \n",
       "4  -0.2137,-0.7579,-0.3633,-0.1377,1.5852,-0.9129...                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(283, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Load data\n",
    "item_info = pd.read_csv(os.path.join(path_to_data, \"item_info.csv\"), sep = \" \")\n",
    "test = pd.read_csv(os.path.join(path_to_data, \"test.csv\"), sep=\"@\")\n",
    "train = pd.read_csv(os.path.join(path_to_data, \"train.csv\"), sep=\"@\")\n",
    "\n",
    "display(test.head())\n",
    "display(train.head())\n",
    "display(item_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aee1c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:10.871197Z",
     "iopub.status.busy": "2025-07-10T11:39:10.870970Z",
     "iopub.status.idle": "2025-07-10T11:39:10.970019Z",
     "shell.execute_reply": "2025-07-10T11:39:10.969392Z"
    },
    "papermill": {
     "duration": 0.10767,
     "end_time": "2025-07-10T11:39:10.971175",
     "exception": false,
     "start_time": "2025-07-10T11:39:10.863505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>behavior_policy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>625093.000000</td>\n",
       "      <td>625093.000000</td>\n",
       "      <td>625093.000000</td>\n",
       "      <td>625093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>439888.458172</td>\n",
       "      <td>170087.854942</td>\n",
       "      <td>1.524293</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>111787.863723</td>\n",
       "      <td>100251.171644</td>\n",
       "      <td>0.661042</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>255612.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>347310.000000</td>\n",
       "      <td>82483.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>440033.000000</td>\n",
       "      <td>169611.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>533000.000000</td>\n",
       "      <td>255075.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>650957.000000</td>\n",
       "      <td>348225.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp     session_id    sequence_id  behavior_policy_id\n",
       "count  625093.000000  625093.000000  625093.000000            625093.0\n",
       "mean   439888.458172  170087.854942       1.524293                 1.0\n",
       "std    111787.863723  100251.171644       0.661042                 0.0\n",
       "min    255612.000000       1.000000       1.000000                 1.0\n",
       "25%    347310.000000   82483.000000       1.000000                 1.0\n",
       "50%    440033.000000  169611.000000       1.000000                 1.0\n",
       "75%    533000.000000  255075.000000       2.000000                 1.0\n",
       "max    650957.000000  348225.000000       4.000000                 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>behavior_policy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156274.000000</td>\n",
       "      <td>156274.000000</td>\n",
       "      <td>156274.000000</td>\n",
       "      <td>156274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>443958.901135</td>\n",
       "      <td>393571.731542</td>\n",
       "      <td>1.451399</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>110619.434687</td>\n",
       "      <td>26343.691773</td>\n",
       "      <td>0.568777</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>255612.000000</td>\n",
       "      <td>348225.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>348716.500000</td>\n",
       "      <td>370636.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>441514.000000</td>\n",
       "      <td>393567.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>534752.000000</td>\n",
       "      <td>416393.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>650957.000000</td>\n",
       "      <td>439131.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp     session_id    sequence_id  behavior_policy_id\n",
       "count  156274.000000  156274.000000  156274.000000            156274.0\n",
       "mean   443958.901135  393571.731542       1.451399                 1.0\n",
       "std    110619.434687   26343.691773       0.568777                 0.0\n",
       "min    255612.000000  348225.000000       1.000000                 1.0\n",
       "25%    348716.500000  370636.000000       1.000000                 1.0\n",
       "50%    441514.000000  393567.000000       1.000000                 1.0\n",
       "75%    534752.000000  416393.750000       2.000000                 1.0\n",
       "max    650957.000000  439131.000000       4.000000                 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.describe())\n",
    "display(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6071136",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:10.986728Z",
     "iopub.status.busy": "2025-07-10T11:39:10.986523Z",
     "iopub.status.idle": "2025-07-10T11:39:10.997247Z",
     "shell.execute_reply": "2025-07-10T11:39:10.996713Z"
    },
    "id": "6uAs4kp4whrk",
    "papermill": {
     "duration": 0.019572,
     "end_time": "2025-07-10T11:39:10.998171",
     "exception": false,
     "start_time": "2025-07-10T11:39:10.978599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Support function\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def padding_and_clip(sequence, max_len, padding_direction = 'left'):\n",
    "    if len(sequence) < max_len:\n",
    "        sequence = [0] * (max_len - len(sequence)) + sequence if padding_direction == 'left' else sequence + [0] * (max_len - len(sequence))\n",
    "    sequence = sequence[-max_len:] if padding_direction == 'left' else sequence[:max_len]\n",
    "    # print(f\"sequence{sequence}\")\n",
    "    return sequence\n",
    "\n",
    "def get_regularization(*modules):\n",
    "  \"\"\"\n",
    "  Customized L2 regularization\n",
    "  \"\"\"\n",
    "  reg = 0\n",
    "  for m in modules:\n",
    "    for p in m.parameters():\n",
    "      reg = torch.mean(p * p) + reg\n",
    "  return reg\n",
    "\n",
    "def wrap_batch(batch, device):\n",
    "  \"\"\"\n",
    "  Build feed_dict from batch data and move data to device\n",
    "  \"\"\"\n",
    "  for k,val in batch.items():\n",
    "    if type(val).__module__ == np.__name__:\n",
    "        batch[k] = torch.from_numpy(val)\n",
    "    elif torch.is_tensor(val):\n",
    "        batch[k] = val\n",
    "    elif type(val) is list:\n",
    "        batch[k] = torch.tensor(val)\n",
    "    else:\n",
    "        continue\n",
    "    if batch[k].type() == \"torch.DoubleTensor\":\n",
    "        batch[k] = batch[k].float()\n",
    "    batch[k] = batch[k].to(device)\n",
    "  return batch\n",
    "\n",
    "def sample_categorical_action(action_prob, candidate_ids, slate_size,\n",
    "                              with_replacement=True, batch_wise=False,\n",
    "                              return_idx=False):\n",
    "  '''\n",
    "  @input:\n",
    "  - action_prob: (B, L)\n",
    "  - candidate_ids: (B, L) or (1, L)\n",
    "  - slate_size: K\n",
    "  - with_replacement: sample with replacement\n",
    "  - batch_wise: do batch wise candidate selection\n",
    "  '''\n",
    "  if with_replacement:\n",
    "    # (K, B)\n",
    "    indices = Categorical(action_prob).sample(sample_shape = (slate_size,))\n",
    "    # (B, K)\n",
    "    indices = torch.transpose(indices, 0, 1)\n",
    "  else:\n",
    "    indices = torch.cat([torch.multinomial(prob, slate_size, replacement=False).view(1, -1) \\\n",
    "                         for prob in action_prob], dim = 0)\n",
    "  action = torch.gather(candidate_ids, 1, indices) if batch_wise else candidate_ids[indices]\n",
    "  if return_idx:\n",
    "    return action.detach(), indices.detach()\n",
    "  else:\n",
    "    return action.detach()\n",
    "\n",
    "\n",
    "##################\n",
    "#   Learning     #\n",
    "##################\n",
    "\n",
    "class LinearScheduler(object):\n",
    "  def __init__(self, schedule_timesteps, final_p, initial_p=1.0):\n",
    "    self.schedule_timesteps = schedule_timesteps\n",
    "    self.final_p = final_p\n",
    "    self.initial_p = initial_p\n",
    "\n",
    "  def value(self, t):\n",
    "    '''\n",
    "    see Schedule.value\n",
    "    '''\n",
    "    fraction = min(float(t) / self.schedule_timesteps, 1.0)\n",
    "    return self.initial_p + fraction * (self.final_p - self.initial_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef882b22",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:11.013109Z",
     "iopub.status.busy": "2025-07-10T11:39:11.012902Z",
     "iopub.status.idle": "2025-07-10T11:39:11.023049Z",
     "shell.execute_reply": "2025-07-10T11:39:11.022528Z"
    },
    "id": "I_-339N7XCzA",
    "papermill": {
     "duration": 0.018775,
     "end_time": "2025-07-10T11:39:11.024006",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.005231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Plot Function\n",
    "\n",
    "def smooth(values, window = 3):\n",
    "  left = window // 2\n",
    "  new_values = [np.mean(values[max(0,idx-left):min(idx-left+window,len(values))]) for idx in range(len(values))]\n",
    "  return new_values\n",
    "\n",
    "\n",
    "def get_rl_training_info(log_path, training_losses = ['actor_loss', 'critic_loss']):\n",
    "  episode = []\n",
    "  average_total_reward, reward_variance, max_total_reward, min_total_reward, average_n_step, max_n_step, min_n_step \\\n",
    "          = [], [], [], [], [], [], []\n",
    "  training_loss_records = {k: [] for k in training_losses}\n",
    "  with open(log_path, 'r') as infile:\n",
    "    for line in tqdm(infile):\n",
    "      split = line.split('@')\n",
    "      # episode\n",
    "      episode.append(eval(split[0].split(':')[1]))\n",
    "      # episode report\n",
    "      episode_report = eval(split[1].strip()[len(\"episode report:\"):])\n",
    "      average_total_reward.append(episode_report['average_total_reward'])\n",
    "      reward_variance.append(episode_report['reward_variance'])\n",
    "      max_total_reward.append(episode_report['max_total_reward'])\n",
    "      min_total_reward.append(episode_report['min_total_reward'])\n",
    "      average_n_step.append(episode_report['average_n_step'])\n",
    "      max_n_step.append(episode_report['max_n_step'])\n",
    "      min_n_step.append(episode_report['min_n_step'])\n",
    "      # loss report\n",
    "      if training_losses:\n",
    "          loss_report = eval(split[2].strip()[len(\"step loss:\"):])\n",
    "          for k in training_losses:\n",
    "              training_loss_records[k].append(loss_report[k])\n",
    "  info = {\n",
    "      \"episode\": episode,\n",
    "      \"average_total_reward\": average_total_reward,\n",
    "      \"reward_variance\": reward_variance,\n",
    "      \"max_total_reward\": max_total_reward,\n",
    "      \"min_total_reward\": min_total_reward,\n",
    "      \"average_depth_per_episode\": average_n_step,\n",
    "      \"max_depth_per_episode\": max_n_step,\n",
    "      \"min_depth_per_episode\": min_n_step\n",
    "  }\n",
    "  if training_losses:\n",
    "      for k in training_losses:\n",
    "        info[k] = training_loss_records[k]\n",
    "  return info\n",
    "\n",
    "def plot_multiple_line(legend_names, list_of_stats, x_name, ncol = 2, row_height = 4, save_path=\"/kaggle/working/fig/rl.png\"):\n",
    "  '''\n",
    "  @input:\n",
    "  - legend_names: [legend]\n",
    "  - list_of_stats: [{field_name: [values]}]\n",
    "  - x_name: x-axis field_name\n",
    "  - ncol: number of subplots in each row\n",
    "  '''\n",
    "  plt.rcParams.update({'font.size': 14})\n",
    "  assert ncol > 0\n",
    "  features = list(list_of_stats[0].keys())\n",
    "  features.remove(x_name)\n",
    "  N = len(features)\n",
    "  fig_height = 12 // ncol if len(features) == 1 else row_height*((N-1)//ncol+1)\n",
    "  plt.figure(figsize = (16, fig_height))\n",
    "  for i,field in enumerate(features):\n",
    "      plt.subplot((N-1)//ncol+1,ncol,i+1)\n",
    "      minY,maxY = float('inf'),float('-inf')\n",
    "      for j,L in enumerate(legend_names):\n",
    "          X = list_of_stats[j][x_name]\n",
    "          value_list = list_of_stats[j][field]\n",
    "          minY,maxY = min(minY,min(value_list)),max(maxY,max(value_list))\n",
    "          plt.plot(X[:len(value_list)], value_list, label = L)\n",
    "      plt.ylabel(field)\n",
    "      plt.xlabel(x_name)\n",
    "      scale = 1e-4 + maxY - minY\n",
    "      plt.ylim(minY - scale * 0.05, maxY + scale * 0.05)\n",
    "      plt.legend()\n",
    "  plt.savefig(save_path)\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c7c0e18",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:11.038712Z",
     "iopub.status.busy": "2025-07-10T11:39:11.038529Z",
     "iopub.status.idle": "2025-07-10T11:39:11.042082Z",
     "shell.execute_reply": "2025-07-10T11:39:11.041443Z"
    },
    "id": "HVUXZjicg3kg",
    "papermill": {
     "duration": 0.012012,
     "end_time": "2025-07-10T11:39:11.043085",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.031073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Socrer function\n",
    "def dot_scorer(action_emb, item_emb, item_dim):\n",
    "  '''\n",
    "  score = item_emb * weight\n",
    "\n",
    "  @input:\n",
    "  - action_emb: (B, i_dim)\n",
    "  - item_emb: (B, L, i_dim) or (1, L, i_dim)\n",
    "  @output:\n",
    "  - score: (B, L)\n",
    "  '''\n",
    "  output = torch.sum(action_emb.view(-1, 1, item_dim) * item_emb, dim=-1)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5404489e",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:11.057809Z",
     "iopub.status.busy": "2025-07-10T11:39:11.057598Z",
     "iopub.status.idle": "2025-07-10T11:39:11.062567Z",
     "shell.execute_reply": "2025-07-10T11:39:11.061912Z"
    },
    "id": "t-f8lshQUlDz",
    "papermill": {
     "duration": 0.013457,
     "end_time": "2025-07-10T11:39:11.063579",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.050122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Dense Neural Network\n",
    "\n",
    "class DNN(nn.Module):\n",
    "  def __init__(self, in_dim, hidden_dims, out_dim=1, dropout_rate= 0.,\n",
    "               do_batch_norm=True):\n",
    "    super(DNN, self).__init__()\n",
    "    self.in_dim = in_dim\n",
    "    layers = []\n",
    "\n",
    "    for hidden_dim in hidden_dims:\n",
    "      linear_layer = nn.Linear(in_dim, hidden_dim)\n",
    "\n",
    "      layers.append(linear_layer)\n",
    "      in_dim = hidden_dim\n",
    "      layers.append(nn.ReLU())\n",
    "      if dropout_rate > 0:\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "      if do_batch_norm:\n",
    "        layers.append(nn.LayerNorm(hidden_dim))\n",
    "\n",
    "    # Prediction layer\n",
    "    last_layer = nn.Linear(in_dim, out_dim)\n",
    "    layers.append(last_layer)\n",
    "\n",
    "    self.layers = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, self.in_dim)\n",
    "    logit = self.layers(x)\n",
    "    return logit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9fb245a",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:11.078047Z",
     "iopub.status.busy": "2025-07-10T11:39:11.077854Z",
     "iopub.status.idle": "2025-07-10T11:39:11.082499Z",
     "shell.execute_reply": "2025-07-10T11:39:11.081859Z"
    },
    "id": "EcNXI4e7tyGR",
    "papermill": {
     "duration": 0.012899,
     "end_time": "2025-07-10T11:39:11.083483",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.070584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title # Data Reader class\n",
    "\n",
    "class BaseDataReader(Dataset):\n",
    "  def __init__(self, params):\n",
    "    self.phase = 'train'\n",
    "    self.n_worker = params['n_worker']\n",
    "    self._read_data(params)\n",
    "\n",
    "  def _read_data(self, params):\n",
    "    self.data = dict()\n",
    "    self.data['train'] = params['train']\n",
    "    self.data['val'] = params['val']\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    pass\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data[self.phase])\n",
    "\n",
    "  def get_statistics(self):\n",
    "    return {'length': len(self)}\n",
    "\n",
    "  def set_phase(self, phase):\n",
    "    assert phase in ['train', 'val', 'test']\n",
    "    self.phase = phase\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b4d513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:11.098328Z",
     "iopub.status.busy": "2025-07-10T11:39:11.098127Z",
     "iopub.status.idle": "2025-07-10T11:39:11.106376Z",
     "shell.execute_reply": "2025-07-10T11:39:11.105735Z"
    },
    "papermill": {
     "duration": 0.016677,
     "end_time": "2025-07-10T11:39:11.107368",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.090691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title RL4RS Data Reader\n",
    "\n",
    "class RL4RSDataReader(BaseDataReader):\n",
    "        \n",
    "    def log(self):\n",
    "        super().log()\n",
    "        \n",
    "    def __init__(self, params):\n",
    "        '''\n",
    "        - from BaseReader:\n",
    "            - phase\n",
    "            - data: will add Position column\n",
    "        '''\n",
    "        self.max_seq_len = params['max_seq_len']\n",
    "        super().__init__(params)\n",
    "        \n",
    "    def _read_data(self, params):\n",
    "        # read data_file\n",
    "        super()._read_data(params)\n",
    "        print(\"Load item meta data\")\n",
    "        self.item_meta = params['item_meta']\n",
    "        self.item_vec_size = len(eval(self.item_meta.iloc[0]['item_vec']))\n",
    "        self.portrait_len = len(eval(self.data['train']['user_protrait'][0]))\n",
    "    \n",
    "    ###########################\n",
    "    #        Iterator         #\n",
    "    ###########################\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        train batch after collate:\n",
    "        {\n",
    "        'timestamp': (B,), \n",
    "        'exposure': (B,K) \n",
    "        'exposure_features': (B,K,item_dim)\n",
    "        'feedback': (B,K)\n",
    "        'history': (B,H)\n",
    "        'history_features': (B,H,item_dim) \n",
    "        'history_features': (B,) \n",
    "        'user_profile': (B,user_dim) \n",
    "        }\n",
    "        '''\n",
    "        timestamp, _, __, exposure, feedback, history, portrait, ___, ____ = self.data[self.phase].iloc[idx]\n",
    "        # timestamp@session_id@sequence_id@exposed_items@user_feedback@user_seqfeature@user_protrait@item_feature@behavior_policy_id\n",
    "        exposure = eval(exposure)\n",
    "        history = eval(f\"[{history}]\")\n",
    "        hist_length = int(min(len(history), self.max_seq_len))\n",
    "        history = padding_and_clip(history, self.max_seq_len)\n",
    "        feedback = eval(feedback)\n",
    "        record = {\n",
    "            'timestamp': int(timestamp),\n",
    "            'exposure': np.array(exposure).astype(int), \n",
    "            'exposure_features': self.get_item_list_meta(exposure).astype(float),\n",
    "            'feedback': np.array(feedback).astype(float),\n",
    "            'history': np.array(history).astype(int),\n",
    "            'history_features': self.get_item_list_meta(history).astype(float),\n",
    "            'history_length': hist_length,\n",
    "            'history_mask': np.array(padding_and_clip([1]*hist_length, self.max_seq_len)),\n",
    "            'user_profile': np.log(np.array(eval(portrait)) + 1)\n",
    "        }\n",
    "        return record\n",
    "        \n",
    "    def get_item_list_meta(self, iid_list, from_idx = False):\n",
    "        '''\n",
    "        @input:\n",
    "        - iid_list: item id list\n",
    "        @output:\n",
    "        - meta_data: {field_name: (B,feature_size)}\n",
    "        '''\n",
    "        features = []\n",
    "        for iid in iid_list:\n",
    "            if iid == 0:\n",
    "                features.append([0]*self.item_vec_size)\n",
    "            else:\n",
    "                features.append(eval(self.item_meta.iloc[iid-1]['item_vec']))\n",
    "        return np.array(features)\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        '''\n",
    "        - n_user\n",
    "        - n_item\n",
    "        - s_parsity\n",
    "        - from BaseReader:\n",
    "            - length\n",
    "            - fields\n",
    "        '''\n",
    "        stats = super().get_statistics()\n",
    "        stats[\"n_item\"] = len(self.item_meta)\n",
    "        stats[\"item_vec_size\"] = self.item_vec_size\n",
    "        stats[\"user_portrait_len\"] = self.portrait_len\n",
    "        stats[\"max_seq_len\"] = self.max_seq_len\n",
    "        stats[\"n_feedback\"] = 2\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b476d8",
   "metadata": {
    "id": "BZu5Gr-atrEE",
    "papermill": {
     "duration": 0.006873,
     "end_time": "2025-07-10T11:39:11.121268",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.114395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d487ca14",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:11.135802Z",
     "iopub.status.busy": "2025-07-10T11:39:11.135604Z",
     "iopub.status.idle": "2025-07-10T11:39:11.143720Z",
     "shell.execute_reply": "2025-07-10T11:39:11.143038Z"
    },
    "id": "aE05j2QDr6lh",
    "papermill": {
     "duration": 0.016659,
     "end_time": "2025-07-10T11:39:11.144870",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.128211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Base Model\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "  def __init__(self, reader, params):\n",
    "    super().__init__()\n",
    "    self.display_name = \"BaseModel\"\n",
    "    self.reader = reader\n",
    "    self.model_path = params['model_path']\n",
    "    self.loss_type = params['loss_type']\n",
    "    self.l2_coef = params['l2_coef']\n",
    "    self.device = params['device']\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self._define_params(reader, params)\n",
    "\n",
    "  def get_regularization(self, *modules):\n",
    "    return get_regularization(*modules)\n",
    "\n",
    "  def do_forward_and_loss(self, feed_dict: dict) -> dict:\n",
    "    '''\n",
    "    Used during training to compute predictions and the loss.\n",
    "    '''\n",
    "    out_dict = self.get_forward(feed_dict)\n",
    "    out_dict['loss'] = self.get_loss(feed_dict, out_dict)\n",
    "    return out_dict\n",
    "\n",
    "  def forward(self, feed_dict: dict, return_prob=True) -> dict:\n",
    "    '''\n",
    "      Used during evaluation/prediction to generate predictions and probabilities\n",
    "    '''\n",
    "    out_dict = self.get_forward(feed_dict)\n",
    "    if return_prob:\n",
    "      out_dict['probs'] = self.sigmoid(out_dict['preds'])\n",
    "    return out_dict\n",
    "\n",
    "  def wrap_batch (self, batch):\n",
    "    '''\n",
    "    Build feed_dict from batch data and move data to self.device\n",
    "    '''\n",
    "    for k, val in batch.items():\n",
    "      if type(val).__module__ == np.__name__:\n",
    "        batch[k] = torch.from_numpy(val)\n",
    "      elif torch.is_tensor(val):\n",
    "        batch[k] = val\n",
    "      elif type(val) is list:\n",
    "        batch[k] = torch.tensor(val)\n",
    "      else:\n",
    "        continue # No compatiable type\n",
    "      if batch[k].type() == 'torch.DoubleTensor':\n",
    "        batch[k] = batch[k].type(torch.FloatTensor)\n",
    "      batch[k] = batch[k].to(self.device)\n",
    "    return batch\n",
    "\n",
    "  def save_checkpoint(self):\n",
    "    torch.save({\n",
    "        \"model_state_dict\": self.state_dict(),\n",
    "        \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "    }, self.model_path + \".checkpoint\")\n",
    "\n",
    "  def load_checkpoint(self, model_path, with_optimizer=True):\n",
    "    checkpoint = torch.load(model_path + \".checkpoint\",\n",
    "                            map_location=self.device)\n",
    "    self.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    if with_optimizer:\n",
    "      self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    self.model_path = model_path\n",
    "\n",
    "  def _define_params(self, reader, params):\n",
    "    pass\n",
    "\n",
    "  def get_forward(self, feed_dict: dict) -> dict:\n",
    "    pass\n",
    "\n",
    "  def get_loss(self, feed_dict: dict, out_dict: dict) -> dict:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cdffbea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:11.160072Z",
     "iopub.status.busy": "2025-07-10T11:39:11.159879Z",
     "iopub.status.idle": "2025-07-10T11:39:11.167356Z",
     "shell.execute_reply": "2025-07-10T11:39:11.166858Z"
    },
    "papermill": {
     "duration": 0.016333,
     "end_time": "2025-07-10T11:39:11.168370",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.152037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RL4RSUserResponse(BaseModel):\n",
    "        \n",
    "    def __init__(self,reader, params):\n",
    "        super().__init__(reader, params)\n",
    "        \n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(reduction = 'none')\n",
    "        self.loss = []\n",
    "        \n",
    "    def _define_params(self, reader, params):\n",
    "        stats = reader.get_statistics()\n",
    "        self.portrait_len = stats['user_portrait_len']\n",
    "        self.item_dim = stats['item_vec_size']\n",
    "        self.hidden_dims = params['hidden_dims']\n",
    "        self.feature_dim = params['feature_dim']\n",
    "        self.dropout_rate = params['dropout_rate']\n",
    "        self.attn_n_head = params['attn_n_head']\n",
    "        # portrait embedding\n",
    "        \n",
    "        self.portrait_encoding_layer = DNN(self.portrait_len, self.hidden_dims, self.feature_dim, \n",
    "                                           dropout_rate = self.dropout_rate, do_batch_norm = False)\n",
    "        # item_emb\n",
    "        self.item_emb_layer = nn.Linear(self.item_dim, self.feature_dim)\n",
    "        # user history encoder\n",
    "        self.seq_self_attn_layer = nn.MultiheadAttention(self.feature_dim, self.attn_n_head, batch_first = True)\n",
    "        self.seq_user_attn_layer = nn.MultiheadAttention(self.feature_dim, self.attn_n_head, batch_first = True)\n",
    "    \n",
    "    def get_forward(self, feed_dict: dict) -> dict:\n",
    "        # user embedding (B,1,f_dim)\n",
    "        user_emb = self.portrait_encoding_layer(feed_dict['user_profile']).view(-1,1,self.feature_dim) \n",
    "        # history embedding (B,H,f_dim)\n",
    "        history_item_emb = self.item_emb_layer(feed_dict['history_features'])\n",
    "        # sequence self attention, encoded sequence is (B,H,f_dim)\n",
    "        seq_encoding, attn_weight = self.seq_self_attn_layer(history_item_emb, history_item_emb, history_item_emb)\n",
    "        # cross attention, encoded history is (B,1,f_dim)\n",
    "        user_interest, attn_weight = self.seq_user_attn_layer(user_emb, seq_encoding, seq_encoding)\n",
    "        # rec item embedding (B,L,f_dim)\n",
    "        exposure_item_emb = self.item_emb_layer(feed_dict['exposure_features'])\n",
    "\n",
    "        # rec item attention score (B,L)\n",
    "        score = torch.sum(exposure_item_emb * user_interest, dim = -1)\n",
    "        # regularization terms\n",
    "        reg = self.get_regularization(self.portrait_encoding_layer, self.item_emb_layer, \n",
    "                                      self.seq_user_attn_layer, self.seq_self_attn_layer)\n",
    "        return {'preds': score, 'reg': reg}\n",
    "    \n",
    "    def get_loss(self, feed_dict: dict, out_dict: dict):\n",
    "        \"\"\"\n",
    "        @input:\n",
    "        - feed_dict: {...}\n",
    "        - out_dict: {\"preds\":, \"reg\":}\n",
    "        \n",
    "        Loss terms implemented:\n",
    "        - BCE\n",
    "        \"\"\"\n",
    "        \n",
    "        preds, reg = out_dict[\"preds\"].view(-1), out_dict[\"reg\"] # (B,L), scalar\n",
    "        target = feed_dict['feedback'].view(-1).to(torch.float) # (B,L)\n",
    "        # loss\n",
    "        loss = torch.mean(self.bce_loss(self.sigmoid(preds), target))\n",
    "        loss = loss + self.l2_coef * reg\n",
    "        self.loss.append(loss.item())\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad04193",
   "metadata": {
    "id": "EPzAu5L7uFO5",
    "papermill": {
     "duration": 0.006688,
     "end_time": "2025-07-10T11:39:11.182164",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.175476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffcba2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:11.196428Z",
     "iopub.status.busy": "2025-07-10T11:39:11.196237Z",
     "iopub.status.idle": "2025-07-10T11:39:11.204463Z",
     "shell.execute_reply": "2025-07-10T11:39:11.203832Z"
    },
    "papermill": {
     "duration": 0.01643,
     "end_time": "2025-07-10T11:39:11.205442",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.189012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['train'] = train\n",
    "params['val'] = test\n",
    "params['item_meta'] = item_info\n",
    "params['n_worker'] = 4\n",
    "params['max_seq_len'] = 50\n",
    "\n",
    "params['loss_type'] = 'bce'\n",
    "params['device'] = device\n",
    "params['l2_coef'] = 0.001\n",
    "params['lr'] = 0.0003\n",
    "params['feature_dim'] = 16\n",
    "params['hidden_dims'] = [256]\n",
    "params['attn_n_head'] = 2\n",
    "params['batch_size'] = 128\n",
    "params['seed'] = 11\n",
    "params['epoch'] = 2\n",
    "params['dropout_rate'] = 0.2\n",
    "params['model_path'] = os.path.join(path_to_output, \n",
    "                          f\"env/rl4rs_user_env_lr{params['lr']}_reg{params['l2_coef']}.model\")\n",
    "set_random_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c763188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:39:11.220050Z",
     "iopub.status.busy": "2025-07-10T11:39:11.219854Z",
     "iopub.status.idle": "2025-07-10T12:48:33.117516Z",
     "shell.execute_reply": "2025-07-10T12:48:33.116631Z"
    },
    "id": "pUiyHg58pQk3",
    "outputId": "de7d8a66-a100-4cfe-b476-963ac617cda0",
    "papermill": {
     "duration": 4161.9066,
     "end_time": "2025-07-10T12:48:33.118994",
     "exception": false,
     "start_time": "2025-07-10T11:39:11.212394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load item meta data\n",
      "epoch 0 is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625152it [27:45, 375.41it/s]                            \n",
      "156288it [06:42, 388.57it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 validating; auc: 0.7725\n",
      "epoch 1 is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625152it [28:03, 371.24it/s]                            \n",
      "156288it [06:45, 385.14it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 validating; auc: 0.7790\n"
     ]
    }
   ],
   "source": [
    "# @title Train user response\n",
    "reader = RL4RSDataReader(params)\n",
    "model = RL4RSUserResponse(reader, params).to(device)\n",
    "\n",
    "\n",
    "# reader = RL4RSDataReader(params)\n",
    "# model = RL4RSUserResponse(reader, params).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "model.optimizer = optimizer\n",
    "\n",
    "\n",
    "epo = 0\n",
    "while epo < params['epoch']:\n",
    "  print(f\"epoch {epo} is training\")\n",
    "  epo += 1\n",
    "\n",
    "  model.train()\n",
    "  reader.set_phase(\"train\")\n",
    "  train_loader = DataLoader(reader, params['batch_size'], shuffle = True, pin_memory = True,\n",
    "                            num_workers= params['n_worker'])\n",
    "\n",
    "  t1 = time()\n",
    "  pbar = tqdm(total=len(train_loader.dataset))\n",
    "  step_loss = []\n",
    "  for i, batch_data in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    wrapped_batch = wrap_batch(batch_data, device)\n",
    "\n",
    "    out_dict = model.do_forward_and_loss(wrapped_batch)\n",
    "    loss = out_dict['loss']\n",
    "    loss.backward()\n",
    "    step_loss.append(loss.item())\n",
    "    optimizer.step()\n",
    "    pbar.update(params['batch_size'])\n",
    "    # print(model.loss)\n",
    "    # if (i + 1) % 10 == 0:\n",
    "      # print(f\"Iteration {i + 1}, loss {np.mean(step_loss[-100:])}\")\n",
    "  pbar.close()\n",
    "    # print(\"Epoch {}; time {:.4f}\".format(epo, time() - t1))\n",
    "\n",
    "  # validation\n",
    "  t2 = time()\n",
    "  reader.set_phase(\"val\")\n",
    "  val_loader = DataLoader(reader, params['batch_size'], shuffle = False, pin_memory = False,\n",
    "                          num_workers= params['n_worker'])\n",
    "  valid_probs, valid_true =  [], []\n",
    "  pbar = tqdm(total = len(val_loader.dataset))\n",
    "  with torch.no_grad():\n",
    "    for i, batch_data in enumerate(val_loader):\n",
    "      wrapped_batch = wrap_batch(batch_data, device)\n",
    "      out_dict = model.forward(wrapped_batch)\n",
    "      valid_probs.append(out_dict['probs'].cpu().numpy())\n",
    "      valid_true.append(batch_data['feedback'].cpu().numpy())\n",
    "      pbar.update(params['batch_size'])\n",
    "  pbar.close()\n",
    "  auc = roc_auc_score(np.concatenate(valid_true), np.concatenate(valid_probs))\n",
    "  print(f\"epoch {epo} validating\" + \"; auc: {:.4f}\".format(np.mean(auc)))\n",
    "  model.save_checkpoint()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f4a9969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:33.651313Z",
     "iopub.status.busy": "2025-07-10T12:48:33.649937Z",
     "iopub.status.idle": "2025-07-10T12:48:33.987711Z",
     "shell.execute_reply": "2025-07-10T12:48:33.987004Z"
    },
    "id": "eqgPbcAsID16",
    "outputId": "ca1dea56-cb24-4412-b8bb-133c693198cd",
    "papermill": {
     "duration": 0.634416,
     "end_time": "2025-07-10T12:48:33.988964",
     "exception": false,
     "start_time": "2025-07-10T12:48:33.354548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Plot loss\n",
    "\n",
    "def plot_line(labels, data_dicts, x_name='X-Axis', y_name='Y-Axis'):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for label, data_dict in zip(labels, data_dicts):\n",
    "        for key, values in data_dict.items():\n",
    "            plt.plot(values, label=f\"{label} - {key}\")\n",
    "    plt.xlabel(x_name)\n",
    "    plt.ylabel(y_name)\n",
    "    plt.title('Loss Plot')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "loss_values = model.loss\n",
    "smoothed_loss = smooth(np.array(loss_values), window=300)  # Adjust smoothness if needed\n",
    "\n",
    "info = {'Loss': smoothed_loss}\n",
    "plot_line(['Model'], [info], x_name='Epoch', y_name='Loss Value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602524b",
   "metadata": {
    "papermill": {
     "duration": 0.23609,
     "end_time": "2025-07-10T12:48:34.463211",
     "exception": false,
     "start_time": "2025-07-10T12:48:34.227121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train HAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2830fdc8",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:34.934312Z",
     "iopub.status.busy": "2025-07-10T12:48:34.934075Z",
     "iopub.status.idle": "2025-07-10T12:48:34.938959Z",
     "shell.execute_reply": "2025-07-10T12:48:34.938422Z"
    },
    "id": "Q7IfdzX4LFTk",
    "papermill": {
     "duration": 0.240933,
     "end_time": "2025-07-10T12:48:34.940054",
     "exception": false,
     "start_time": "2025-07-10T12:48:34.699121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Cost function\n",
    "def mean_with_cost(feedback, zero_reward_cost=0.1):\n",
    "  B, L = feedback.shape\n",
    "  cost = torch.zeros_like(feedback)\n",
    "  cost[feedback == 0] = -zero_reward_cost\n",
    "  reward = torch.mean(feedback + cost, dim=-1)\n",
    "  return reward\n",
    "\n",
    "def nsw(avg_r, min_r, lambda_nsw=1e-4, epsilon=1e-8):\n",
    "    r_vec = torch.stack([avg_r, min_r + lambda_nsw], dim=-1)\n",
    "    r_vec = torch.clamp(r_vec, min=epsilon)\n",
    "    return torch.sum(torch.log(r_vec), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c9e1223",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:35.496404Z",
     "iopub.status.busy": "2025-07-10T12:48:35.496142Z",
     "iopub.status.idle": "2025-07-10T12:48:35.500295Z",
     "shell.execute_reply": "2025-07-10T12:48:35.499773Z"
    },
    "id": "KP_0zmoEFwta",
    "papermill": {
     "duration": 0.271542,
     "end_time": "2025-07-10T12:48:35.501309",
     "exception": false,
     "start_time": "2025-07-10T12:48:35.229767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title BaseRL Environment\n",
    "class BaseEnv():\n",
    "  def __init__(self, params):\n",
    "    super().__init__()\n",
    "    self.reward_func = params['reward_function']\n",
    "    self.max_step_per_episode = params['max_step']\n",
    "    self.initial_temper = params[\"initial_temper\"]\n",
    "\n",
    "  def reset(self, paras):\n",
    "    pass\n",
    "  def step(self, action):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a08760",
   "metadata": {
    "papermill": {
     "duration": 0.233872,
     "end_time": "2025-07-10T12:48:35.972069",
     "exception": false,
     "start_time": "2025-07-10T12:48:35.738197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1. Environment define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b114c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:36.503902Z",
     "iopub.status.busy": "2025-07-10T12:48:36.503616Z",
     "iopub.status.idle": "2025-07-10T12:48:36.522097Z",
     "shell.execute_reply": "2025-07-10T12:48:36.521597Z"
    },
    "papermill": {
     "duration": 0.314138,
     "end_time": "2025-07-10T12:48:36.523156",
     "exception": false,
     "start_time": "2025-07-10T12:48:36.209018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RL4RSEnvironment(BaseEnv):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        super().__init__(params)\n",
    "        self.reader = RL4RSDataReader(params)\n",
    "        self.user_response_model = RL4RSUserResponse(self.reader, params)\n",
    "        checkpoint = torch.load(params['model_path'] + \".checkpoint\", map_location=device)\n",
    "        self.user_response_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.user_response_model.to(device)\n",
    "    \n",
    "        # spaces\n",
    "        stats = self.reader.get_statistics()\n",
    "        self.action_space = {'item_id': ('nomial', stats['n_item']),\n",
    "                             'item_feature': ('continuous', stats['item_vec_size'], 'normal')}\n",
    "        self.observation_space = {'user_profile': ('continuous', stats['user_portrait_len'], 'positive'),\n",
    "                                  'history': ('sequence', stats['max_seq_len'], ('continuous', stats['item_vec_size']))}\n",
    "        self.n_worker = params['n_worker']\n",
    "        \n",
    "    def reset(self, params = {'batch_size': 1, 'empty_history': True}):\n",
    "        '''\n",
    "        Reset environment with new sampled users\n",
    "        @input:\n",
    "        - params: {'batch_size': scalar, \n",
    "                    'empty_history': True if start from empty history, \n",
    "                    'initial_history': start with initial history, mu }\n",
    "        @output:\n",
    "        - observation: {'user_profile': (B, portrait_dim), \n",
    "                        'history': (B, H), \n",
    "                        'history_feature': (B, H, item_dim)\n",
    "                        'history_feedback': (B, H, item_dim)}\n",
    "        '''\n",
    "        self.empty_history_flag = params['empty_history'] if 'empty_history' not in params else True\n",
    "        BS = params['batch_size']\n",
    "        observation = {'batch_size': BS}\n",
    "        if 'sample' in params:\n",
    "            sample_info = params['sample']\n",
    "        else:\n",
    "            self.iter = iter(DataLoader(self.reader, batch_size = BS, shuffle = True, \n",
    "                                        pin_memory = True, num_workers = self.n_worker))\n",
    "            sample_info = next(self.iter)\n",
    "            sample_info = wrap_batch(sample_info, device = self.user_response_model.device)\n",
    "        self.current_observation = {\n",
    "            'user_profile': sample_info['user_profile'],  # (B, user_dim)\n",
    "            'history': sample_info['history'],  # (B, H)\n",
    "            'history_features': sample_info['history_features'], # (B, H, item_dim)\n",
    "            'cummulative_reward': torch.zeros(BS).to(self.user_response_model.device),\n",
    "            'min_reward': torch.full((BS,), float('inf'), device=self.user_response_model.device),\n",
    "            'temper': torch.ones(BS).to(self.user_response_model.device) * self.initial_temper,\n",
    "            'step': torch.zeros(BS).to(self.user_response_model.device),\n",
    "        }\n",
    "        self.reward_history = [0.]\n",
    "        self.step_history = [0.]\n",
    "        return copy.deepcopy(self.current_observation)\n",
    "        \n",
    "    \n",
    "    def step(self, step_dict):\n",
    "        '''\n",
    "        @input:\n",
    "        - step_dict: {'action': (B, slate_size),\n",
    "                        'action_features': (B, slate_size, item_dim) }\n",
    "        '''\n",
    "        # actions (exposures)\n",
    "        action = step_dict['action'] # (B, slate_size), should be item ids only\n",
    "        action_features = step_dict['action_features']\n",
    "        batch_data = {\n",
    "            'user_profile': self.current_observation['user_profile'],\n",
    "            'history_features': self.current_observation['history_features'],\n",
    "            'exposure_features': action_features\n",
    "        }\n",
    "        # URM forward\n",
    "        with torch.no_grad():\n",
    "            output_dict = self.user_response_model(batch_data)\n",
    "            response = torch.bernoulli(output_dict['probs']) # (B, slate_size)\n",
    "#             prob_scale = (self.current_observation['temper'].clone().detach().view(-1,1) + self.temper_prob_lag) / (self.initial_temper + self.temper_prob_lag)\n",
    "            probs_under_temper = output_dict['probs'] # * prob_scale\n",
    "            response = torch.bernoulli(probs_under_temper).detach() # (B, slate_size)\n",
    "\n",
    "            # reward (B,)\n",
    "            immediate_reward = self.reward_func(response).detach()\n",
    "            # immediate_reward = -torch.abs(immediate_reward - self.temper_sweet_point) + 1\n",
    "            self.current_observation['min_reward'] = torch.min(immediate_reward, self.current_observation['min_reward'])\n",
    "\n",
    "            # (B, H+slate_size)\n",
    "            H_prime = torch.cat((self.current_observation['history'], action), dim = 1) \n",
    "            # (B, H+slate_size, item_dim)\n",
    "            H_prime_features = torch.cat((self.current_observation['history_features'], action_features), dim = 1) \n",
    "            # (B, H+slate_size)\n",
    "            F_prime = torch.cat((torch.ones_like(self.current_observation['history']), response), dim = 1).to(torch.long) \n",
    "            # vector, vector\n",
    "            row_indices, col_indices = (F_prime == 1).nonzero(as_tuple=True) \n",
    "            # (B,), the number of positive iteraction as history length\n",
    "            L = F_prime.sum(dim = 1) \n",
    "            \n",
    "            # user history update\n",
    "            offset = 0\n",
    "            newH = torch.zeros_like(self.current_observation['history'])\n",
    "            newH_features = torch.zeros_like(self.current_observation['history_features'])\n",
    "            for row_id in range(action.shape[0]):\n",
    "                right = offset + L[row_id]\n",
    "                left = right - self.reader.max_seq_len\n",
    "                newH[row_id] = H_prime[row_id, col_indices[left:right]]\n",
    "                newH_features[row_id] = H_prime_features[row_id,col_indices[left:right],:]\n",
    "                offset += L[row_id]\n",
    "            self.current_observation['history'] = newH\n",
    "            self.current_observation['history_features'] = newH_features\n",
    "            self.current_observation['cummulative_reward'] += immediate_reward\n",
    "\n",
    "            # temper update for leave model\n",
    "            temper_down = (-immediate_reward+1) * response.shape[1] + 1\n",
    "            self.current_observation['temper'] -= temper_down\n",
    "            # leave signal\n",
    "            done_mask = self.current_observation['temper'] < 1\n",
    "            # step update\n",
    "            self.current_observation['step'] += 1\n",
    "\n",
    "            # update rows where user left\n",
    "#             refresh_rows = done_mask.nonzero().view(-1)\n",
    "#             print(f\"#refresh: {refresh_rows}\")\n",
    "            if done_mask.sum() > 0:\n",
    "                final_rewards = self.current_observation['cummulative_reward'][done_mask].detach().cpu().numpy()\n",
    "                final_steps = self.current_observation['step'][done_mask].detach().cpu().numpy()\n",
    "                self.reward_history.append(final_rewards[-1])\n",
    "                self.step_history.append(final_steps[-1])\n",
    "                # sample new users to fill in the blank\n",
    "                new_sample_flag = False\n",
    "                try:\n",
    "                    sample_info = next(self.iter)\n",
    "                    if sample_info['user_profile'].shape[0] != done_mask.shape[0]:\n",
    "                        new_sample_flag = True\n",
    "                except:\n",
    "                    new_sample_flag = True\n",
    "                if new_sample_flag:\n",
    "                    self.iter = iter(DataLoader(self.reader, batch_size = done_mask.shape[0], shuffle = True, \n",
    "                                                pin_memory = True, num_workers = params['n_worker']))\n",
    "                    sample_info = next(self.iter)\n",
    "                sample_info = wrap_batch(sample_info, device = self.user_response_model.device)\n",
    "                for obs_key in ['user_profile', 'history', 'history_features']:\n",
    "                    self.current_observation[obs_key][done_mask] = sample_info[obs_key][done_mask]\n",
    "                self.current_observation['cummulative_reward'][done_mask] *= 0\n",
    "                self.current_observation['min_reward'][done_mask] = float('inf')\n",
    "                self.current_observation['temper'][done_mask] *= 0\n",
    "                self.current_observation['temper'][done_mask] += self.initial_temper\n",
    "            self.current_observation['step'][done_mask] *= 0\n",
    "#         print(f\"step: {self.current_observation['step']}\")\n",
    "        return copy.deepcopy(self.current_observation), immediate_reward, done_mask, {'response': response}\n",
    "    \n",
    "    def stop(self):\n",
    "        self.iter = None\n",
    "    \n",
    "    def get_new_iterator(self, B):\n",
    "        return iter(DataLoader(self.reader, batch_size = B, shuffle = True, \n",
    "                               pin_memory = True, num_workers = params['n_worker']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaa5d5a2",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:36.990670Z",
     "iopub.status.busy": "2025-07-10T12:48:36.990359Z",
     "iopub.status.idle": "2025-07-10T12:48:37.000359Z",
     "shell.execute_reply": "2025-07-10T12:48:36.999829Z"
    },
    "id": "3BvTCi5yZvxS",
    "papermill": {
     "duration": 0.245173,
     "end_time": "2025-07-10T12:48:37.001463",
     "exception": false,
     "start_time": "2025-07-10T12:48:36.756290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Self-Attentive Sequential Recommendation\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "  def __init__(self, environment, params):\n",
    "    super().__init__()\n",
    "    self.n_layer = params['sasrec_n_layer']\n",
    "    self.d_model = params['sasrec_d_model']\n",
    "    self.n_head = params['sasrec_n_head']\n",
    "    self.dropout_rate = params['sasrec_dropout']\n",
    "    self.d_forward = params['sasrec_d_forward']\n",
    "\n",
    "    # item space\n",
    "    self.item_space = environment.action_space['item_id'][1]\n",
    "    self.item_dim = environment.action_space['item_feature'][1]\n",
    "    self.maxlen = environment.observation_space['history'][1]\n",
    "    self.state_dim = self.d_model\n",
    "    self.action_dim = self.d_model\n",
    "\n",
    "    # policy network modules\n",
    "    self.item_map = nn.Linear(self.item_dim, self.d_model)\n",
    "    self.pos_emb = nn.Embedding(self.maxlen, self.d_model)\n",
    "    self.pos_emb_getter = torch.arange(self.maxlen, dtype = torch.long)\n",
    "    self.emb_dropout = nn.Dropout(self.dropout_rate)\n",
    "    self.emb_norm = nn.LayerNorm(self.d_model)\n",
    "    self.attn_mask = ~torch.tril(torch.ones((self.maxlen, self.maxlen), dtype=torch.bool))\n",
    "    encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model,\n",
    "                                               nhead=self.n_head,\n",
    "                                               dim_feedforward= self.d_forward,\n",
    "                                               dropout=self.dropout_rate,\n",
    "                                               batch_first = True\n",
    "                                               )\n",
    "    self.transformer = nn.TransformerEncoder(encoder_layer= encoder_layer,\n",
    "                                             num_layers = self.n_layer)\n",
    "\n",
    "  def score(self, action_emb, item_emb, do_softmax=True):\n",
    "    item_emb = self.item_map(item_emb)\n",
    "    output = dot_scorer(action_emb, item_emb, self.d_model)\n",
    "    if do_softmax:\n",
    "      return torch.softmax(output, dim=-1)\n",
    "    else:\n",
    "      return output\n",
    "\n",
    "  def get_scorer_parameters(self):\n",
    "    return self.item_map.parameters()\n",
    "\n",
    "  def encode_state(self, feed_dict):\n",
    "    user_history = feed_dict['history_features']\n",
    "    # (1, H, d_model)\n",
    "    # for item in feed_dict.items():\n",
    "    #   print(item)\n",
    "    # print(\"user_history device:\", user_history.device)\n",
    "    # print(\"self.pos_emb_getter device:\", self.pos_emb_getter.device)\n",
    "    # print(\"self.pos_emb device\", self.pos_emb.device)\n",
    "\n",
    "    pos_emb = self.pos_emb(self.pos_emb_getter.to(user_history.device)).view(1, self.maxlen, self.d_model)\n",
    "\n",
    "    # (B, H, d_model)\n",
    "    history_item_emb = self.item_map(user_history).view(-1, self.maxlen, self.d_model)\n",
    "    history_item_emb = self.emb_norm(self.emb_dropout(history_item_emb + pos_emb))\n",
    "\n",
    "    # (B, H, d_model)\n",
    "    output_seq = self.transformer(history_item_emb, mask = self.attn_mask.to(user_history.device))\n",
    "\n",
    "    return {'output_seq': output_seq, 'state_emb': output_seq[:, -1, :]}\n",
    "\n",
    "  def forward(self, feed_dict):\n",
    "    '''\n",
    "    @input\n",
    "    - feed_dict: {'user_profile': (B, user_dim),\n",
    "                  'history_features': (B, H, item_dim),\n",
    "                  'history_mask': (B),\n",
    "                  'candicate_features': (B, L, item_dim) or (1, L, item_dim)\n",
    "                  }\n",
    "    @model\n",
    "    - user_profile --> user_emb (B, 1, f_dim)\n",
    "    - hisotry_items --> history_item_emb (B, H, f_dim)\n",
    "    - (Q:user_emb, K&V: history_item_emb) --(multi-head attn) --> user_state(B, 1, feature_dim)\n",
    "    - user_state --> action_prob (B, n_item)\n",
    "    '''\n",
    "    hist_enc = self.encode_state(feed_dict)\n",
    "\n",
    "    # user embedding (B, 1, d_model)\n",
    "    user_state = hist_enc['state_emb'].view(-1, self.d_model)\n",
    "\n",
    "    # action embedding (B, d_model)\n",
    "    action_emb = user_state\n",
    "\n",
    "    # regularization\n",
    "    reg = get_regularization(self.item_map, self.transformer)\n",
    "\n",
    "    out_dict = {\n",
    "        'action_emb': action_emb,\n",
    "        'state_emb': user_state,\n",
    "        'seq_emb': hist_enc['output_seq'],\n",
    "        'reg': reg\n",
    "    }\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d93e9510",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:37.472063Z",
     "iopub.status.busy": "2025-07-10T12:48:37.471266Z",
     "iopub.status.idle": "2025-07-10T12:48:37.476441Z",
     "shell.execute_reply": "2025-07-10T12:48:37.475913Z"
    },
    "id": "Dz4XwAAtzx1d",
    "papermill": {
     "duration": 0.240056,
     "end_time": "2025-07-10T12:48:37.477537",
     "exception": false,
     "start_time": "2025-07-10T12:48:37.237481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# @title General Critic class\n",
    "class GeneralCritic(nn.Module):\n",
    "  def __init__(self, policy, params):\n",
    "    super().__init__()\n",
    "    self.state_dim = policy.state_dim\n",
    "    self.action_dim = policy.action_dim\n",
    "    self.net = DNN(self.state_dim + self.action_dim, params['critic_hidden_dims'], 1,\n",
    "                   dropout_rate=params['critic_dropout_rate'], do_batch_norm=True)\n",
    "\n",
    "  def forward(self, feed_dict):\n",
    "    '''\n",
    "    @input:\n",
    "    - feed_dict: {'state_emb': (B, state_dim), 'action_emb': (B, action_dim)}\n",
    "    '''\n",
    "    state_emb = feed_dict['state_emb']\n",
    "    action_emb = feed_dict['action_emb'].view(-1, self.action_dim)\n",
    "\n",
    "    Q = self.net(torch.cat((state_emb, action_emb), dim = -1)).view(-1)\n",
    "\n",
    "    reg = get_regularization(self.net)\n",
    "    return {'q': Q, 'reg': reg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5695f2bb",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:38.006847Z",
     "iopub.status.busy": "2025-07-10T12:48:38.006568Z",
     "iopub.status.idle": "2025-07-10T12:48:38.029005Z",
     "shell.execute_reply": "2025-07-10T12:48:38.028449Z"
    },
    "id": "Jd56qLlk99ge",
    "papermill": {
     "duration": 0.31421,
     "end_time": "2025-07-10T12:48:38.030156",
     "exception": false,
     "start_time": "2025-07-10T12:48:37.715946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title One Stage Facade\n",
    "class OneStageFacade():\n",
    "  def __init__(self, environment, actor, critic, params):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.env = environment\n",
    "    self.actor = actor\n",
    "    self.critic = critic\n",
    "\n",
    "    self.slate_size = params['slate_size']\n",
    "    self.noise_var = params['noise_var']\n",
    "    self.noise_decay = params['noise_var'] / params['n_iter'][-1]\n",
    "    self.q_laplace_smoothness = params['q_laplace_smoothness']\n",
    "    self.topk_rate = params['topk_rate']\n",
    "    self.empty_start_rate = params['empty_start_rate']\n",
    "\n",
    "    self.n_item = self.env.action_space['item_id'][1]\n",
    "\n",
    "    # (N)\n",
    "    self.candidate_iids = np.arange(1, self.n_item + 1)\n",
    "\n",
    "    # (N, item_dim)\n",
    "    self.candidate_features = torch.FloatTensor(\n",
    "        self.env.reader.get_item_list_meta(self.candidate_iids)).to(self.device)\n",
    "    self.candidate_iids = torch.tensor(self.candidate_iids).to(self.device)\n",
    "\n",
    "    # replay buffer is initialized in initialize_train()\n",
    "    self.buffer_size = params['buffer_size']\n",
    "    self.start_timestamp = params['start_timestamp']\n",
    "\n",
    "  def initialize_train(self):\n",
    "    '''\n",
    "    Procedures before training\n",
    "    '''\n",
    "    self.buffer = {\n",
    "        \"user_profile\": torch.zeros(self.buffer_size, self.env.reader.portrait_len),\n",
    "        \"history\":torch.zeros(self.buffer_size, self.env.reader.max_seq_len).to(torch.long),\n",
    "        \"next_history\":torch.zeros(self.buffer_size, self.env.reader.max_seq_len).to(torch.long),\n",
    "        \"state_emb\": torch.zeros(self.buffer_size, self.actor.state_dim),\n",
    "        \"action_emb\":torch.zeros(self.buffer_size, self.actor.action_dim),\n",
    "        \"action\":torch.zeros(self.buffer_size, self.slate_size, dtype=torch.long),\n",
    "        \"reward\":torch.zeros(self.buffer_size),\n",
    "        \"min_reward\": torch.zeros(self.buffer_size),\n",
    "        \"feedback\": torch.zeros(self.buffer_size, self.slate_size),\n",
    "        \"done\": torch.zeros(self.buffer_size, dtype=torch.bool)\n",
    "    }\n",
    "\n",
    "    for k, v in self.buffer.items():\n",
    "      self.buffer[k] = v.to(self.device)\n",
    "    self.buffer_head = 0\n",
    "    self.current_buffer_size = 0\n",
    "    self.n_stream_record = 0\n",
    "    self.is_training_available = False\n",
    "\n",
    "  def reset_env(self, initial_params = {'batch_size': 1}):\n",
    "    '''\n",
    "    Reset user response environment\n",
    "    '''\n",
    "    initial_params['empty_history'] = True if np.random.rand() < self.empty_start_rate else False\n",
    "    initial_observation = self.env.reset(initial_params)\n",
    "    return initial_observation\n",
    "\n",
    "  def env_step(self, policy_output):\n",
    "    action_dict = {\n",
    "      'action': policy_output['action'],\n",
    "      'action_features': policy_output['action_features']\n",
    "    }\n",
    "    observation, reward, done, info = self.env.step(action_dict)\n",
    "    return observation, reward, done, info\n",
    "\n",
    "  def stop_env(self):\n",
    "    self.env.stop()\n",
    "\n",
    "  def get_episode_report(self, n_recent = 10):\n",
    "    recent_rewards = self.env.reward_history[-n_recent:]\n",
    "    recent_steps = self.env.step_history[-n_recent:]\n",
    "    epsiode_report = {\n",
    "        'average_total_reward': np.mean(recent_rewards),\n",
    "        'reward_variance': np.var(recent_rewards),\n",
    "        'max_total_reward': np.max(recent_rewards),\n",
    "        'min_total_reward': np.min(recent_rewards),\n",
    "        'average_n_step': np.mean(recent_steps),\n",
    "        'max_n_step': np.max(recent_steps),\n",
    "        'min_n_step': np.min(recent_steps),\n",
    "        'buffer_size': self.current_buffer_size\n",
    "    }\n",
    "    return epsiode_report\n",
    "\n",
    "  def apply_critic(self, observation, policy_output, critic_model):\n",
    "    feed_dict = {\n",
    "        'state_emb': policy_output['state_emb'],\n",
    "        'action_emb': policy_output['action_emb']\n",
    "    }\n",
    "    critic_output = critic_model(feed_dict)\n",
    "    return critic_output\n",
    "\n",
    "  def apply_policy(self, observation, policy_model, epsilon = 0, \n",
    "                 do_explore = False, do_softmax = True):\n",
    "    '''\n",
    "    @input:\n",
    "    - observation: input of policy model\n",
    "    - policy_model\n",
    "    - epsilon: greedy epsilon, effective only when do_explore == True\n",
    "    - do_explore: exploration flag, True if adding noise to action\n",
    "    - do_softmax: output softmax score\n",
    "    '''\n",
    "#         feed_dict = utils.wrap_batch(observation, device = self.device)\n",
    "    feed_dict = observation\n",
    "    out_dict = policy_model(feed_dict)\n",
    "    if do_explore:\n",
    "        action_emb = out_dict['action_emb']\n",
    "        # sampling noise of action embedding\n",
    "        if np.random.rand() < epsilon:\n",
    "            action_emb = torch.clamp(torch.rand_like(action_emb)*self.noise_var, -1, 1)\n",
    "        else:\n",
    "            action_emb = action_emb + torch.clamp(torch.rand_like(action_emb)*self.noise_var, -1, 1)\n",
    "#                 self.noise_var -= self.noise_decay\n",
    "        out_dict['action_emb'] = action_emb\n",
    "        \n",
    "    if 'candidate_ids' in feed_dict:\n",
    "        # (B, L, item_dim)\n",
    "        out_dict['candidate_features'] = feed_dict['candidate_features']\n",
    "        # (B, L)\n",
    "        out_dict['candidate_ids'] = feed_dict['candidate_ids']\n",
    "        batch_wise = True\n",
    "    else:\n",
    "        # (1,L,item_dim)\n",
    "        out_dict['candidate_features'] = self.candidate_features.unsqueeze(0)\n",
    "        # (L,)\n",
    "        out_dict['candidate_ids'] = self.candidate_iids\n",
    "        batch_wise = False\n",
    "        \n",
    "    # action prob (B,L)\n",
    "    action_prob = policy_model.score(out_dict['action_emb'], \n",
    "                                     out_dict['candidate_features'], \n",
    "                                     do_softmax = do_softmax)\n",
    "\n",
    "    # two types of greedy selection\n",
    "    if np.random.rand() >= self.topk_rate:\n",
    "        # greedy random: categorical sampling\n",
    "        action, indices = utils.sample_categorical_action(action_prob, out_dict['candidate_ids'], \n",
    "                                                          self.slate_size, with_replacement = False, \n",
    "                                                          batch_wise = batch_wise, return_idx = True)\n",
    "    else:\n",
    "        # indices on action_prob\n",
    "        _, indices = torch.topk(action_prob, k = self.slate_size, dim = 1)\n",
    "        # topk action\n",
    "        if batch_wise:\n",
    "            action = torch.gather(out_dict['candidate_ids'], 1, indices).detach() # (B, slate_size)\n",
    "        else:\n",
    "            action = out_dict['candidate_ids'][indices].detach() # (B, slate_size)\n",
    "    # (B,K)\n",
    "    out_dict['action'] = action \n",
    "    # (B,K,item_dim)\n",
    "    out_dict['action_features'] = self.candidate_features[action-1]\n",
    "    # (B,K)\n",
    "    out_dict['action_prob'] = torch.gather(action_prob, 1, indices) \n",
    "    # (B,L)\n",
    "    out_dict['candidate_prob'] = action_prob\n",
    "    return out_dict\n",
    "\n",
    "  def sample_buffer(self, batch_size):\n",
    "    '''\n",
    "    @output:\n",
    "    - observation\n",
    "    - policy output\n",
    "    - reward\n",
    "    - done_mask\n",
    "    - next_observation\n",
    "    '''\n",
    "    indices = np.random.randint(0, self.current_buffer_size, size = batch_size)\n",
    "    U, H, N, S, HA, A, R, F, D, MR = self.read_buffer(indices)\n",
    "    observation = {\n",
    "        'user_profile': U,\n",
    "        'history_features': H,\n",
    "        'min_reward': MR\n",
    "    }\n",
    "    policy_output = {\n",
    "        'state_emb': S,\n",
    "        'action_emb': HA,\n",
    "        'action': A\n",
    "    }\n",
    "    reward = R\n",
    "    done_mask = D\n",
    "    next_observation = {\n",
    "        'user_profile': U,\n",
    "        'history_features': N,\n",
    "        'min_reward': MR,\n",
    "        'previous_feedback': F\n",
    "    }\n",
    "    return observation, policy_output, reward, done_mask, next_observation\n",
    "\n",
    "  # def sample_raw_data(self, batch_size):\n",
    "  #   '''\n",
    "  #   Sample supervise data from raw training data\n",
    "  #   '''\n",
    "  #   batch = self.env.sample_user(batch_size)\n",
    "\n",
    "  def update_buffer(self, observation, policy_output, reward, done_mask,\n",
    "                    next_observation, info):\n",
    "    # Overwrite old entries in buffer\n",
    "    if self.buffer_head + reward.shape[0] >= self.buffer_size:\n",
    "      tail = self.buffer_size - self.buffer_head\n",
    "      indices = [self.buffer_head + i for i in range(tail)] + \\\n",
    "       [i for i in range(reward.shape[0] - tail)]\n",
    "    else:\n",
    "      indices = [self.buffer_head  + i for i in range(reward.shape[0])]\n",
    "\n",
    "    # update buffer\n",
    "    self.buffer[\"user_profile\"][indices] = observation['user_profile']\n",
    "    self.buffer[\"history\"][indices] = observation['history']\n",
    "    self.buffer[\"min_reward\"][indices] = observation['min_reward']\n",
    "    self.buffer[\"next_history\"][indices] = next_observation['history']\n",
    "    self.buffer[\"state_emb\"][indices] = policy_output['state_emb']\n",
    "    self.buffer[\"action\"][indices] = policy_output['action']\n",
    "    self.buffer[\"action_emb\"][indices] = policy_output['action_emb']\n",
    "    self.buffer[\"reward\"][indices] = reward\n",
    "    self.buffer[\"feedback\"][indices] = info['response']\n",
    "    self.buffer[\"done\"][indices] = done_mask\n",
    "\n",
    "    # update buffer pointer\n",
    "    self.buffer_head = (self.buffer_head + reward.shape[0]) % self.buffer_size\n",
    "    self.n_stream_record += reward.shape[0]\n",
    "    self.current_buffer_size = min(self.n_stream_record, self.buffer_size)\n",
    "\n",
    "    # available training when sufficient sample buffer\n",
    "    if self.n_stream_record >= self.start_timestamp:\n",
    "      self.is_training_available = True\n",
    "  def read_buffer(self, indices):\n",
    "    U = self.buffer['user_profile'][indices]\n",
    "    # (L, item_dim)\n",
    "    H = self.candidate_features[self.buffer[\"history\"][indices] - 1]\n",
    "    N = self.candidate_features[self.buffer[\"next_history\"][indices] - 1]\n",
    "    S = self.buffer[\"state_emb\"][indices]\n",
    "    HA = self.buffer[\"action_emb\"][indices]\n",
    "    A = self.buffer[\"action\"][indices]\n",
    "    R = self.buffer[\"reward\"][indices]\n",
    "    F = self.buffer[\"feedback\"][indices]\n",
    "    D = self.buffer[\"done\"][indices]\n",
    "    MR = self.buffer['min_reward'][indices]\n",
    "    return U, H, N, S, HA, A, R, F, D, MR\n",
    "\n",
    "  def extract_behavior_data(self, observation, policy_output, next_observation):\n",
    "    '''\n",
    "    Extract supervised data from RL samples\n",
    "    '''\n",
    "    observation = {\n",
    "        \"user_profile\": observation['user_profile'],\n",
    "        \"history_features\": observation['history_features']\n",
    "    }\n",
    "    exposed_items = policy_output['action']\n",
    "    exposure = {\n",
    "        \"ids\": exposed_items,\n",
    "        \"features\": self.candidate_features[exposed_items - 1]\n",
    "    }\n",
    "    user_feedback = next_observation[\"previous_feedback\"]\n",
    "    return observation, exposure, user_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c6582ea",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:38.502475Z",
     "iopub.status.busy": "2025-07-10T12:48:38.502182Z",
     "iopub.status.idle": "2025-07-10T12:48:38.511498Z",
     "shell.execute_reply": "2025-07-10T12:48:38.510927Z"
    },
    "id": "_H8nHNkrZdnk",
    "papermill": {
     "duration": 0.247641,
     "end_time": "2025-07-10T12:48:38.512503",
     "exception": false,
     "start_time": "2025-07-10T12:48:38.264862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title One Stage Facade with Hyper Action\n",
    "\n",
    "class OneStageFacade_HyperAction(OneStageFacade):\n",
    "  def __init__(self, environment, actor, critic, params):\n",
    "    super().__init__(environment, actor, critic, params)\n",
    "\n",
    "  def apply_policy(self, observation, policy_model, epsilon = 0,\n",
    "                   do_explore = False, do_softmax = True):\n",
    "    feed_dict = wrap_batch(observation, device=device)\n",
    "    # print(feed_dict.device)\n",
    "    out_dict = policy_model(feed_dict)\n",
    "    if do_explore:\n",
    "      action_emb = out_dict['action_emb']\n",
    "      # explore and exploit + clamping\n",
    "      if np.random.rand() < epsilon:\n",
    "        action_emb = torch.clamp(torch.rand_like(action_emb) * self.noise_var, -1, 1)\n",
    "      else:\n",
    "        action_emb = action_emb + torch.clamp(torch.rand_like(action_emb) * self.noise_var, -1, 1)\n",
    "\n",
    "      out_dict['action_emb'] = action_emb\n",
    "\n",
    "    # Z latent space\n",
    "    out_dict['Z'] = out_dict['action_emb']\n",
    "\n",
    "    if 'candidate_ids' in feed_dict:\n",
    "      # (B, L, item_dim)\n",
    "      out_dict['candidate_features']  = feed_dict['candidate_features']\n",
    "      # (B, L)\n",
    "      out_dict['candidate_ids'] = feed_dict['candidate_ids']\n",
    "      batch_wise = True\n",
    "    else:\n",
    "      # (1, L, item_dim)\n",
    "      out_dict['candidate_features'] = self.candidate_features.unsqueeze(0)\n",
    "      #(L, )\n",
    "      out_dict['candidate_ids'] = self.candidate_iids\n",
    "      batch_wise = False\n",
    "\n",
    "    # action pron (B, L)\n",
    "    action_prob = policy_model.score(out_dict['action_emb'],\n",
    "                                      out_dict['candidate_features'],\n",
    "                                      do_softmax=do_softmax)\n",
    "\n",
    "    # two types of greedy selection\n",
    "    if np.random.rand() >= self.topk_rate:\n",
    "      # greedy random\n",
    "      action, indices = sample_categorical_action(action_prob, out_dict['candidate_ids'],\n",
    "                                                  self.slate_size, with_replacement=False,\n",
    "                                                  batch_wise=batch_wise,\n",
    "                                                  return_idx=True)\n",
    "    else:\n",
    "      # indices on action_prob\n",
    "      _, indices = torch.topk(action_prob, k = self.slate_size, dim = 1)\n",
    "      # print(indices.shape)\n",
    "      # print(self.candidate_features.shape)\n",
    "      # top k action:\n",
    "      # (B, slate_size)\n",
    "      if batch_wise:\n",
    "        action = torch.gather(out_dict['candidate_ids'], 1, indices).detach()\n",
    "      else:\n",
    "        action = out_dict['candidate_ids'][indices].detach()\n",
    "\n",
    "    # (B, K)\n",
    "    out_dict['action'] = action\n",
    "    # (B, K, item_dim)\n",
    "    out_dict['action_features'] = self.candidate_features[indices]\n",
    "    # (B, K)\n",
    "    out_dict['action_prob'] = torch.gather(action_prob, 1, indices)\n",
    "    # (B, L)\n",
    "    out_dict['candidate_prob'] = action_prob\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "  def infer_hyper_action(self, observation, policy_output, actor):\n",
    "    '''\n",
    "    Inverse function A -> Z\n",
    "    '''\n",
    "    # (B, K)\n",
    "    A = policy_output['action']\n",
    "\n",
    "    # (B, K, item_dim)\n",
    "    item_embs = self.candidate_features[A - 1]\n",
    "\n",
    "    # (B, K, kernel_dim)\n",
    "    Z = torch.mean(actor.item_map(item_embs).view(A.shape[0], A.shape[1], -1), dim = 1)\n",
    "    return {\n",
    "        'Z': Z,\n",
    "        'action_emb': Z,\n",
    "        'state_emb': policy_output['state_emb']\n",
    "    }\n",
    "\n",
    "  def apply_critic(self, observation, policy_output, critic_model):\n",
    "    feed_dict = {\n",
    "        'state_emb': policy_output['state_emb'],\n",
    "        'action_emb': policy_output['action_emb']\n",
    "    }\n",
    "    critic_output = critic_model(feed_dict)\n",
    "    return critic_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbd06e5a",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:38.990301Z",
     "iopub.status.busy": "2025-07-10T12:48:38.990032Z",
     "iopub.status.idle": "2025-07-10T12:48:39.000901Z",
     "shell.execute_reply": "2025-07-10T12:48:39.000323Z"
    },
    "id": "wJKb3K_326B5",
    "papermill": {
     "duration": 0.255359,
     "end_time": "2025-07-10T12:48:39.001941",
     "exception": false,
     "start_time": "2025-07-10T12:48:38.746582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Base RL Agent\n",
    "\n",
    "\n",
    "\n",
    "class BaseRLAgent():\n",
    "  def __init__(self, facade, params):\n",
    "    self.device = params['device']\n",
    "    self.gamma = params['gamma']\n",
    "    self.n_iter = [0] + params['n_iter']\n",
    "    self.train_every_n_step = params['train_every_n_step']\n",
    "    self.check_episode = params['check_episode']\n",
    "    self.save_path = params['save_path']\n",
    "    self.facade = facade\n",
    "    self.check_episode = params['check_episode']\n",
    "    self.exploration_scheduler = LinearScheduler(int(sum(self.n_iter) * params['elbow_greedy']),\n",
    "                                                 params['final_greedy_epsilon'],\n",
    "                                                 params['initial_greedy_epsilon'])\n",
    "    # if len(self.n_iter) == 2:\n",
    "    #   with open(self.save_path + \".report\", 'w') as outfile:\n",
    "    #     outfile.write()\n",
    "\n",
    "  def train(self):\n",
    "    if len(self.n_iter) > 2:\n",
    "      self.load()\n",
    "\n",
    "    t = time()\n",
    "    start_time = t\n",
    "    print(\"Run procedure before training\")\n",
    "    self.action_before_train()\n",
    "\n",
    "    print(\"Start training\")\n",
    "    observation = self.facade.reset_env({\n",
    "        'batch_size': self.episode_batch_size,\n",
    "    })\n",
    "    step_offset = sum(self.n_iter[:-1])\n",
    "    for i in tqdm(range(step_offset, step_offset + self.n_iter[-1])):\n",
    "      observation = self.run_episode_step(i, self.exploration_scheduler.value(i),\n",
    "                                          observation, True)\n",
    "      if i % self.train_every_n_step == 0:\n",
    "        self.step_train()\n",
    "\n",
    "      if i % self.check_episode == 0:\n",
    "        t_ = time()\n",
    "        # print(f\"Episode step {i}, time diff {t_ - t}, total time dif {t - start_time})\")\n",
    "        self.log_iteration(i)\n",
    "        t = t_\n",
    "        if i % (3*self.check_episode) == 0:\n",
    "            self.save()\n",
    "\n",
    "    self.action_after_train()\n",
    "\n",
    "\n",
    "  def action_before_train(self):\n",
    "    pass\n",
    "\n",
    "  def action_after_train(self):\n",
    "    self.facade.stop_env()\n",
    "\n",
    "\n",
    "  def get_report(self):\n",
    "    episode_report = self.facade.get_episode_report(10)\n",
    "    train_report = {k: np.mean(v[-10:]) for k, v in self.training_history.items()}\n",
    "    return episode_report, train_report\n",
    "\n",
    "  def log_iteration(self, step):\n",
    "    episode_report, train_report = self.get_report()\n",
    "    run.log(episode_report | train_report)\n",
    "    log_str = f\"step: {step} @ episode report: {episode_report} @ step loss: {train_report}\\n\"\n",
    "    with open(self.save_path + \".report\", 'a') as outfile:\n",
    "        outfile.write(log_str)\n",
    "    return log_str\n",
    "\n",
    "  def test(self):\n",
    "    self.load()\n",
    "    self.facade.initialize_train()\n",
    "\n",
    "    t = time()\n",
    "    start_time = t\n",
    "\n",
    "    print(\"Start testing\")\n",
    "    observation = self.facade.reset_env({\n",
    "        'batch_size': self.episode_batch_size,\n",
    "    })\n",
    "    step_offset = sum(self.n_iter[:-1])\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(step_offset, step_offset + self.n_iter[-1])):\n",
    "          observation = self.run_episode_step(i, self.exploration_scheduler.value(i),\n",
    "                                              observation, True)\n",
    "          if i % self.check_episode == 0:\n",
    "            t_ = time()\n",
    "            episode_report = self.facade.get_episode_report(10)\n",
    "            log_str = f\"step: {i} @ episode report: {episode_report}\\n\"\n",
    "            run.log(episode_report)\n",
    "            with open(self.save_path + \"_eval.report\", 'a') as outfile:\n",
    "              outfile.write(log_str)\n",
    "            # print(f\"Episode step {i}, time diff {t_ - t}, total time dif {t - start_time})\")\n",
    "            # print(log_str)\n",
    "            t = t_\n",
    "    \n",
    "\n",
    "  #######################################\n",
    "  #           Abstract function         #\n",
    "  #######################################\n",
    "  def run_episode_step(self, *episode_args):\n",
    "    pass\n",
    "\n",
    "  def step_train(self):\n",
    "    pass\n",
    "\n",
    "  def save(self):\n",
    "    pass\n",
    "\n",
    "  def load(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c868ab90",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:39.527095Z",
     "iopub.status.busy": "2025-07-10T12:48:39.526810Z",
     "iopub.status.idle": "2025-07-10T12:48:39.541920Z",
     "shell.execute_reply": "2025-07-10T12:48:39.541194Z"
    },
    "id": "VBbJXf-KfvDA",
    "papermill": {
     "duration": 0.250904,
     "end_time": "2025-07-10T12:48:39.542973",
     "exception": false,
     "start_time": "2025-07-10T12:48:39.292069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Deep Deterministic Policy Gradient\n",
    "\n",
    "\n",
    "class DDPG(BaseRLAgent):\n",
    "  def __init__(self, facade, params):\n",
    "    super().__init__(facade, params)\n",
    "    self.actor = facade.actor\n",
    "    self.actor_target = copy.deepcopy(self.actor)\n",
    "    self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr = params['actor_lr'], weight_decay = params['actor_decay'])\n",
    "\n",
    "    self.critic = facade.critic\n",
    "    self.critic_target = copy.deepcopy(self.critic)\n",
    "    self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr = params['critic_lr'], weight_decay = params['critic_decay'])\n",
    "\n",
    "    self.episode_batch_size = params['episode_batch_size']\n",
    "    self.tau = params['target_mitigate_coef']\n",
    "    self.actor_lr = params['actor_lr']\n",
    "    self.critic_lr = params['critic_lr']\n",
    "    self.actor_decay = params['actor_decay']\n",
    "    self.critic_decay = params['critic_decay']\n",
    "\n",
    "    self.batch_size = params['batch_size']\n",
    "\n",
    "    with open(self.save_path + \".report\", 'w') as outfile:\n",
    "      pass\n",
    "\n",
    "  def action_before_train(self):\n",
    "    '''\n",
    "    - facade setup\n",
    "      - buffer setup\n",
    "    - run random episodes to build-up the initial buffer\n",
    "    '''\n",
    "    self.facade.initialize_train()\n",
    "    # print(\"Facade Parameters:\")\n",
    "    # for param, value in vars(self.facade).items():\n",
    "    #     print(f\"{param}: {value}\")\n",
    "    prepare_step = 0\n",
    "    # random explore before training\n",
    "    initial_epsilon = 1.0\n",
    "    observation = self.facade.reset_env({\n",
    "        'batch_size': self.episode_batch_size,\n",
    "    })\n",
    "    while not self.facade.is_training_available:\n",
    "      observation = self.run_episode_step(0, initial_epsilon, observation, True)\n",
    "      # print(observation)\n",
    "      prepare_step += 1\n",
    "\n",
    "    # training records\n",
    "    self.training_history = {\"critic_loss\": [], \"actor_loss\": []}\n",
    "\n",
    "    print(f\"Total {prepare_step} prepare steps\")\n",
    "\n",
    "  def run_episode_step(self, *episode_args):\n",
    "    '''\n",
    "    One step of interaction\n",
    "    '''\n",
    "    episode_iter, epsilon, observation, do_buffer_update = episode_args\n",
    "    with torch.no_grad():\n",
    "      # sample action\n",
    "      policy_output = self.facade.apply_policy(observation, self.actor, epsilon,\n",
    "                                               do_explore=True)\n",
    "\n",
    "      # apply action on environment and update replay buffer\n",
    "      next_observation, reward, done, info = self.facade.env_step(policy_output)\n",
    "\n",
    "      # update replay buffer\n",
    "      if do_buffer_update:\n",
    "        self.facade.update_buffer(observation, policy_output, reward, done,\n",
    "                                  next_observation, info)\n",
    "    return next_observation\n",
    "\n",
    "  def step_train(self):\n",
    "    observation , policy_output, reward, done_mask, next_observation = self.facade.sample_buffer(params['batch_size'])\n",
    "      \n",
    "    critic_loss, actor_loss = self.get_ddpg_loss(observation, policy_output, reward,\n",
    "                                                  done_mask, next_observation)\n",
    "    self.training_history[\"critic_loss\"].append(critic_loss.item())\n",
    "    self.training_history[\"actor_loss\"].append(actor_loss.item())\n",
    "\n",
    "    # Update the frozen target models\n",
    "    for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "      target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
    "\n",
    "    for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "      target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
    "\n",
    "    return {'step_loss': (self.training_history['actor_loss'][-1],\n",
    "                          self.training_history['critic_loss'][-1])}\n",
    "\n",
    "  def get_ddpg_loss(self, observation, policy_output, reward, done_mask, next_observation,\n",
    "                    do_actor_update = True, do_critic_update = True):\n",
    "    # Get current Q estimate\n",
    "    current_critic_output = self.facade.apply_critic(observation,\n",
    "                                                     wrap_batch(policy_output, device=self.device),\n",
    "                                                     self.critic)\n",
    "    current_Q = current_critic_output['q']\n",
    "\n",
    "    # Compute the target Q value\n",
    "    next_policy_output = self.facade.apply_policy(next_observation, self.actor_target)\n",
    "    target_critic_output = self.facade.apply_critic(next_observation, next_policy_output,\n",
    "                                                    self.critic_target)\n",
    "\n",
    "    target_Q = target_critic_output['q']\n",
    "    target_Q = reward + self.gamma * (done_mask * target_Q).detach()\n",
    "\n",
    "    # compute critic loss\n",
    "    # minimize current_Q predict and target_Q predict\n",
    "    critic_loss = F.mse_loss(current_Q, target_Q).mean()\n",
    "\n",
    "    if do_critic_update and self.critic_lr > 0:\n",
    "      # Optimize the critic\n",
    "      self.critic_optimizer.zero_grad()\n",
    "      critic_loss.backward()\n",
    "      self.critic_optimizer.step()\n",
    "\n",
    "    # compute actor loss\n",
    "    policy_output = self.facade.apply_policy(observation, self.actor)\n",
    "    critic_output = self.facade.apply_critic(observation, policy_output, self.critic)\n",
    "\n",
    "    # Maximize Q value\n",
    "    actor_loss = -critic_output['q'].mean()\n",
    "\n",
    "    if do_actor_update and self.actor_lr > 0:\n",
    "      # Optimize the actor\n",
    "      self.actor_optimizer.zero_grad()\n",
    "      actor_loss.backward()\n",
    "      self.actor_optimizer.step()\n",
    "    return critic_loss, actor_loss\n",
    "\n",
    "  def save(self):\n",
    "    torch.save(self.critic.state_dict(), self.save_path + \"_critic\")\n",
    "    torch.save(self.critic_optimizer.state_dict(), self.save_path + \"_critic_optimizer\")\n",
    "    torch.save(self.actor.state_dict(), self.save_path + \"_actor\")\n",
    "    torch.save(self.actor_optimizer.state_dict(), self.save_path + \"_actor_optimizer\")\n",
    "\n",
    "  def load(self):\n",
    "    self.critic.load_state_dict(torch.load(self.save_path + \"_critic\", map_location=self.device))\n",
    "    self.critic_optimizer.load_state_dict(torch.load(self.save_path + \"_critic_optimizer\", map_location=self.device))\n",
    "    self.critic_target = copy.deepcopy(self.critic)\n",
    "\n",
    "    self.actor.load_state_dict(torch.load(self.save_path + \"_actor\", map_location=self.device))\n",
    "    self.actor_optimizer.load_state_dict(torch.load(self.save_path + \"_actor_optimizer\", map_location=self.device))\n",
    "    self.actor_target = copy.deepcopy(self.actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb50e49e",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:40.016748Z",
     "iopub.status.busy": "2025-07-10T12:48:40.016439Z",
     "iopub.status.idle": "2025-07-10T12:48:40.031183Z",
     "shell.execute_reply": "2025-07-10T12:48:40.030618Z"
    },
    "id": "HLBYcDpMSfuw",
    "papermill": {
     "duration": 0.253665,
     "end_time": "2025-07-10T12:48:40.032181",
     "exception": false,
     "start_time": "2025-07-10T12:48:39.778516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# @title Hyper - Actor Critic\n",
    "class HAC(DDPG):\n",
    "  def __init__(self, facade, params):\n",
    "    super().__init__(facade, params)\n",
    "    self.behavior_lr = params['behavior_lr']\n",
    "    self.behavior_decay = params['behavior_decay']\n",
    "    self.hyper_actor_coef = params['hyper_actor_coef']\n",
    "    self.actor_behavior_optimizer = torch.optim.Adam(self.actor.parameters(),\n",
    "                                                     lr=params['behavior_lr'],\n",
    "                                                     weight_decay=params['behavior_decay'])\n",
    "\n",
    "  def action_before_train(self):\n",
    "    super().action_before_train()\n",
    "    self.training_history['hyper_actor_loss'] = []\n",
    "    self.training_history['behavior_loss'] = []\n",
    "\n",
    "  def run_episode_step(self, *episode_args):\n",
    "    '''\n",
    "    One step of interaction\n",
    "    '''\n",
    "    episode_iter, epsilon, observation, do_buffer_update = episode_args\n",
    "    with torch.no_grad():\n",
    "      # sample action\n",
    "      policy_output = self.facade.apply_policy(observation, self.actor, epsilon,\n",
    "                                               do_explore=True)\n",
    "\n",
    "      # apply action on environment and update replay buffer\n",
    "      next_observation, reward, done, info = self.facade.env_step(policy_output)\n",
    "\n",
    "      # update replay buffer\n",
    "      if do_buffer_update:\n",
    "        self.facade.update_buffer(observation, policy_output, reward, done,\n",
    "                                  next_observation, info)\n",
    "    return next_observation\n",
    "\n",
    "  def step_train(self):\n",
    "    observation , policy_output, reward, done_mask, next_observation = self.facade.sample_buffer(params['batch_size'])\n",
    "    # reward  = torch.FloatTensor(reward)\n",
    "    # done_mask = torch.FloatTensor(done_mask)\n",
    "\n",
    "    critic_loss, actor_loss, hyper_actor_loss = self.get_hac_loss(observation, policy_output, reward,\n",
    "                                                  done_mask, next_observation)\n",
    "    behavior_loss = self.get_behavior_loss(observation, policy_output, next_observation)\n",
    "\n",
    "    self.training_history[\"critic_loss\"].append(critic_loss.item())\n",
    "    self.training_history[\"actor_loss\"].append(actor_loss.item())\n",
    "    self.training_history['hyper_actor_loss'].append(hyper_actor_loss.item())\n",
    "    self.training_history['behavior_loss'].append(behavior_loss.item())\n",
    "\n",
    "    # Update frozen target models\n",
    "    for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "      target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
    "\n",
    "    for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "      target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
    "\n",
    "    return {\"step_loss\": (self.training_history['actor_loss'][-1],\n",
    "                          self.training_history['critic_loss'][-1],\n",
    "                          self.training_history['hyper_actor_loss'][-1],\n",
    "                          self.training_history['behavior_loss'][-1])}\n",
    "\n",
    "  def get_hac_loss(self, observation, policy_output, reward, done_mask, next_observation,\n",
    "                    do_actor_update = True, do_critic_update = True):\n",
    "\n",
    "\n",
    "    # nsw reward\n",
    "    cummulative_r = reward\n",
    "    min_r = observation['min_reward']\n",
    "    min_r = torch.where(torch.isinf(min_r), torch.zeros_like(min_r), min_r)\n",
    "      \n",
    "    # Current Q estimate\n",
    "    hyper_output = self.facade.infer_hyper_action(observation, policy_output, self.actor)\n",
    "    current_critic_output = self.facade.apply_critic(observation, hyper_output, self.critic)\n",
    "    current_Q = current_critic_output['q']\n",
    "\n",
    "    # Compute target Q value\n",
    "    next_policy_output = self.facade.apply_policy(next_observation, self.actor_target)\n",
    "    target_critic_output = self.facade.apply_critic(next_observation, next_policy_output, self.critic_target)\n",
    "\n",
    "    target_Q = target_critic_output['q']\n",
    "    target_Q = reward + self.gamma * (done_mask * target_Q).detach()\n",
    "\n",
    "    assert not torch.isnan(current_Q).any(), \"NaN in current_Q!\"\n",
    "    assert not torch.isnan(target_Q).any(), \"NaN in target_Q!\"\n",
    "    assert not torch.isnan(reward).any(), \"NaN in reward!\"\n",
    "\n",
    "    critic_loss = F.mse_loss(current_Q, target_Q).mean()\n",
    "    if do_critic_update and self.critic_lr > 0:\n",
    "      self.critic_optimizer.zero_grad()\n",
    "      critic_loss.backward()\n",
    "      self.critic_optimizer.step()\n",
    "\n",
    "    # actor loss\n",
    "\n",
    "    if do_actor_update and self.actor_lr > 0:\n",
    "      self.actor_optimizer.zero_grad()\n",
    "      policy_output = self.facade.apply_policy(observation, self.actor)\n",
    "      critic_output = self.facade.apply_critic(observation, policy_output, self.critic)\n",
    "      actor_loss = -nsw(critic_output['q'], min_r).mean()\n",
    "      actor_loss.backward()\n",
    "      self.actor_optimizer.step()\n",
    "\n",
    "    # hyper actor loss\n",
    "\n",
    "    if do_actor_update and self.hyper_actor_coef > 0:\n",
    "      self.actor_optimizer.zero_grad()\n",
    "      policy_output = self.facade.apply_policy(observation, self.actor)\n",
    "      inferred_hyper_output = self.facade.infer_hyper_action(observation, policy_output, self.actor)\n",
    "      hyper_actor_loss = self.hyper_actor_coef * F.mse_loss(inferred_hyper_output['Z'],\n",
    "                                                            policy_output['Z']).mean()\n",
    "\n",
    "      hyper_actor_loss.backward()\n",
    "      self.actor_optimizer.step()\n",
    "\n",
    "    return critic_loss, actor_loss, hyper_actor_loss\n",
    "\n",
    "  def get_behavior_loss(self, observation, policy_output, next_observation, do_update = True):\n",
    "    observation, exposure, feedback = self.facade.extract_behavior_data(observation, policy_output, next_observation)\n",
    "    observation['candidate_ids'] = exposure['ids']\n",
    "    observation['candidate_features'] = exposure['features']\n",
    "    policy_output = self.facade.apply_policy(observation, self.actor, do_softmax=False)\n",
    "    action_prob = torch.sigmoid(policy_output['candidate_prob'])\n",
    "    behavior_loss = F.binary_cross_entropy(action_prob, feedback)\n",
    "\n",
    "    if do_update and self.behavior_lr > 0:\n",
    "      self.actor_behavior_optimizer.zero_grad()\n",
    "      behavior_loss.backward()\n",
    "      self.actor_behavior_optimizer.step()\n",
    "\n",
    "    return behavior_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5840bea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T12:48:40.559587Z",
     "iopub.status.busy": "2025-07-10T12:48:40.559021Z",
     "iopub.status.idle": "2025-07-10T14:14:56.970319Z",
     "shell.execute_reply": "2025-07-10T14:14:56.969458Z"
    },
    "papermill": {
     "duration": 5178.254804,
     "end_time": "2025-07-10T14:14:58.522015",
     "exception": false,
     "start_time": "2025-07-10T12:48:40.267211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m23020082\u001b[0m (\u001b[33m23020082-uet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250710_124840-6vojxq4t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdeft-flower-78\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC/runs/6vojxq4t\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load item meta data\n",
      "Run procedure before training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1962072114.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(params['model_path'] + \".checkpoint\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 63 prepare steps\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50000/50000 [1:26:02<00:00,  9.69it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           actor_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       average_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: average_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        behavior_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          buffer_size \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          critic_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     hyper_actor_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           max_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     max_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           min_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     min_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      reward_variance \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           actor_loss 0.64489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       average_n_step 16.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: average_total_reward 16.51889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        behavior_loss 0.03498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          buffer_size 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          critic_loss 0.05185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     hyper_actor_loss 0.00747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           max_n_step 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     max_total_reward 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           min_n_step 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     min_total_reward 13.38889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      reward_variance 3.64133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mdeft-flower-78\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC/runs/6vojxq4t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at: \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250710_124840-6vojxq4t/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "params['n_worker'] = 4\n",
    "params['max_seq_len'] = 50\n",
    "\n",
    "params['loss_type'] = 'bce'\n",
    "params['device'] = device\n",
    "params['l2_coef'] = 0.001\n",
    "params['lr'] = 0.0003\n",
    "params['feature_dim'] = 16\n",
    "params['hidden_dims'] = [256]\n",
    "params['attn_n_head'] = 2\n",
    "params['batch_size'] = 128\n",
    "params['epoch'] = 2\n",
    "params['dropout_rate'] = 0.2\n",
    "params['max_step'] = 20\n",
    "params['initial_temper'] = 20\n",
    "params['reward_function'] = mean_with_cost\n",
    "params['sasrec_n_layer'] = 2\n",
    "params['sasrec_d_model'] = 32\n",
    "params['sasrec_n_head'] = 4\n",
    "params['sasrec_dropout'] = 0.1\n",
    "params['sasrec_d_forward'] = 64\n",
    "params['critic_hidden_dims'] = [256, 64]\n",
    "params['critic_dropout_rate'] = 0.2\n",
    "params['n_iter']= [50000]\n",
    "params['slate_size'] = 9\n",
    "params['noise_var'] = 0.1\n",
    "params['q_laplace_smoothness'] = 0.5\n",
    "params['topk_rate'] = 1\n",
    "params['empty_start_rate'] = 0\n",
    "params['buffer_size'] = 100000\n",
    "params['start_timestamp'] = 2000\n",
    "params['gamma'] = 0.9\n",
    "params['train_every_n_step']= 1\n",
    "params['initial_greedy_epsilon'] = 0\n",
    "params['final_greedy_epsilon'] = 0\n",
    "params['elbow_greedy'] = 0.1\n",
    "params['check_episode'] = 10\n",
    "params['with_eval'] = False\n",
    "\n",
    "params['episode_batch_size'] = 32\n",
    "params['batch_size'] = 64\n",
    "params['actor_lr'] = 0.00001\n",
    "params['critic_lr'] = 0.001\n",
    "params['actor_decay'] = 0.00001\n",
    "params['critic_decay'] = 0.00001\n",
    "params['target_mitigate_coef'] = 0.01\n",
    "params['behavior_lr'] = 0.00005\n",
    "params['behavior_decay'] = 0.00001\n",
    "params['hyper_actor_coef'] = 0.1\n",
    "params['advantage_bias'] = 0\n",
    "params['entropy_coef'] = 0.0001\n",
    "\n",
    "config = params.copy()\n",
    "config.pop(\"train\", None)\n",
    "config.pop(\"val\", None)\n",
    "config.pop(\"item_meta\", None)\n",
    "config.pop(\"user_meta\", None)\n",
    "\n",
    "for seed in [9]:\n",
    "    run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"23020082-uet\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"HAC\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config=config\n",
    "    )\n",
    "    params['seed'] = seed\n",
    "    set_random_seed(params['seed'])\n",
    "    params['save_path'] = os.path.join(path_to_output, f\"agent/rl4rs_model_seed{params['seed']}\")\n",
    "    os.makedirs(os.path.dirname(params['save_path']), exist_ok=True)\n",
    "    \n",
    "    env = RL4RSEnvironment(params)\n",
    "    \n",
    "    policy = SASRec(env, params)\n",
    "    policy.to(device)\n",
    "    \n",
    "    \n",
    "    critic = GeneralCritic(policy, params)\n",
    "    critic.to(device)\n",
    "    \n",
    "    facade = OneStageFacade_HyperAction(env, policy, critic, params)\n",
    "    \n",
    "    agent = HAC(facade, params)\n",
    "    \n",
    "    agent.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a7e654",
   "metadata": {
    "papermill": {
     "duration": 1.448381,
     "end_time": "2025-07-10T14:15:01.362093",
     "exception": false,
     "start_time": "2025-07-10T14:14:59.913712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a5c9e26",
   "metadata": {
    "papermill": {
     "duration": 1.392997,
     "end_time": "2025-07-10T14:15:04.311326",
     "exception": false,
     "start_time": "2025-07-10T14:15:02.918329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bc64537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T14:15:07.386855Z",
     "iopub.status.busy": "2025-07-10T14:15:07.386311Z",
     "iopub.status.idle": "2025-07-10T14:16:01.512296Z",
     "shell.execute_reply": "2025-07-10T14:16:01.511561Z"
    },
    "papermill": {
     "duration": 57.063405,
     "end_time": "2025-07-10T14:16:02.895805",
     "exception": false,
     "start_time": "2025-07-10T14:15:05.832400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>exposed_items</th>\n",
       "      <th>user_feedback</th>\n",
       "      <th>user_seqfeature</th>\n",
       "      <th>user_protrait</th>\n",
       "      <th>item_feature</th>\n",
       "      <th>behavior_policy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>442720</td>\n",
       "      <td>348225</td>\n",
       "      <td>2</td>\n",
       "      <td>29,25,16,106,114,45,213,196,148</td>\n",
       "      <td>1,1,1,1,1,1,1,1,0</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458306</td>\n",
       "      <td>348226</td>\n",
       "      <td>1</td>\n",
       "      <td>5,6,36,110,61,127,172,239,199</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1352,1.3293,-0.7099...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458307</td>\n",
       "      <td>348226</td>\n",
       "      <td>2</td>\n",
       "      <td>1,4,26,107,61,79,199,164,235</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.0489,-0.3633,-0.1349,1.8061,0.4482,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476558</td>\n",
       "      <td>348227</td>\n",
       "      <td>1</td>\n",
       "      <td>26,14,4,79,113,96,235,199,172</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>0.6758,0.3057,-0.3633,-0.143,1.3991,-0.3773,-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>476559</td>\n",
       "      <td>348227</td>\n",
       "      <td>2</td>\n",
       "      <td>4,14,26,61,113,127,212,239,164</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1423,1.7014,-0.2719...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  session_id  sequence_id                    exposed_items  \\\n",
       "0     442720      348225            2  29,25,16,106,114,45,213,196,148   \n",
       "1     458306      348226            1    5,6,36,110,61,127,172,239,199   \n",
       "2     458307      348226            2     1,4,26,107,61,79,199,164,235   \n",
       "3     476558      348227            1    26,14,4,79,113,96,235,199,172   \n",
       "4     476559      348227            2   4,14,26,61,113,127,212,239,164   \n",
       "\n",
       "       user_feedback                                    user_seqfeature  \\\n",
       "0  1,1,1,1,1,1,1,1,0  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "1  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "2  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "3  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "4  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "\n",
       "                                       user_protrait  \\\n",
       "0  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "1  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "2  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "3  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "4  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "\n",
       "                                        item_feature  behavior_policy_id  \n",
       "0  1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...                   1  \n",
       "1  -0.2137,-0.7579,-0.3633,-0.1352,1.3293,-0.7099...                   1  \n",
       "2  -0.2137,-0.0489,-0.3633,-0.1349,1.8061,0.4482,...                   1  \n",
       "3  0.6758,0.3057,-0.3633,-0.143,1.3991,-0.3773,-1...                   1  \n",
       "4  -0.2137,-0.7579,-0.3633,-0.1423,1.7014,-0.2719...                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>exposed_items</th>\n",
       "      <th>user_feedback</th>\n",
       "      <th>user_seqfeature</th>\n",
       "      <th>user_protrait</th>\n",
       "      <th>item_feature</th>\n",
       "      <th>behavior_policy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>530551</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28,32,5,77,130,76,196,199,172</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>0</td>\n",
       "      <td>64054,2901,63021,88510,10205,7615,54240,37294,...</td>\n",
       "      <td>1.5653,0.6602,-0.3633,-0.1267,1.8759,-0.856,-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>531709</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30,28,21,77,73,130,235,196,172</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>0</td>\n",
       "      <td>64054,2901,63021,88510,10205,7615,54240,37294,...</td>\n",
       "      <td>1.5653,2.0783,-0.3633,-0.1426,0.9766,-0.5926,-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550062</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15,36,35,134,128,40,200,219,165</td>\n",
       "      <td>1,1,1,1,1,1,0,1,0</td>\n",
       "      <td>28,32,5,77,130,76,196,172,199,28,30,21,130,73,...</td>\n",
       "      <td>64054,38043,93755,88510,10205,7615,54240,37294...</td>\n",
       "      <td>0.6758,-0.0489,-0.3633,-0.1389,1.8565,-0.0384,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568391</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29,30,34,132,81,57,164,192,212</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>28,32,5,77,130,76,196,172,199,28,30,21,130,73,...</td>\n",
       "      <td>64054,50212,93755,88510,10205,7615,54240,37294...</td>\n",
       "      <td>1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595031</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2,18,21,60,75,85,167,196,237</td>\n",
       "      <td>1,1,1,1,1,1,0,1,1</td>\n",
       "      <td>28,32,5,77,130,76,196,172,199,28,30,21,130,73,...</td>\n",
       "      <td>64054,50212,93755,88510,10205,7615,54240,37294...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1377,1.5852,-0.9129...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  session_id  sequence_id                    exposed_items  \\\n",
       "0     530551           1            1    28,32,5,77,130,76,196,199,172   \n",
       "1     531709           1            2   30,28,21,77,73,130,235,196,172   \n",
       "2     550062           2            1  15,36,35,134,128,40,200,219,165   \n",
       "3     568391           3            1   29,30,34,132,81,57,164,192,212   \n",
       "4     595031           4            1     2,18,21,60,75,85,167,196,237   \n",
       "\n",
       "       user_feedback                                    user_seqfeature  \\\n",
       "0  1,1,1,1,1,1,1,1,1                                                  0   \n",
       "1  1,1,1,1,1,1,1,1,1                                                  0   \n",
       "2  1,1,1,1,1,1,0,1,0  28,32,5,77,130,76,196,172,199,28,30,21,130,73,...   \n",
       "3  1,1,1,1,1,1,1,1,1  28,32,5,77,130,76,196,172,199,28,30,21,130,73,...   \n",
       "4  1,1,1,1,1,1,0,1,1  28,32,5,77,130,76,196,172,199,28,30,21,130,73,...   \n",
       "\n",
       "                                       user_protrait  \\\n",
       "0  64054,2901,63021,88510,10205,7615,54240,37294,...   \n",
       "1  64054,2901,63021,88510,10205,7615,54240,37294,...   \n",
       "2  64054,38043,93755,88510,10205,7615,54240,37294...   \n",
       "3  64054,50212,93755,88510,10205,7615,54240,37294...   \n",
       "4  64054,50212,93755,88510,10205,7615,54240,37294...   \n",
       "\n",
       "                                        item_feature  behavior_policy_id  \n",
       "0  1.5653,0.6602,-0.3633,-0.1267,1.8759,-0.856,-1...                   1  \n",
       "1  1.5653,2.0783,-0.3633,-0.1426,0.9766,-0.5926,-...                   1  \n",
       "2  0.6758,-0.0489,-0.3633,-0.1389,1.8565,-0.0384,...                   1  \n",
       "3  1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...                   1  \n",
       "4  -0.2137,-0.7579,-0.3633,-0.1377,1.5852,-0.9129...                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(283, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Load data\n",
    "item_info = pd.read_csv(os.path.join(path_to_data, \"item_info.csv\"), sep = \" \")\n",
    "test = pd.read_csv(os.path.join(path_to_data, \"test.csv\"), sep=\"@\")\n",
    "train = pd.read_csv(os.path.join(path_to_data, \"all.csv\"), sep=\"@\")\n",
    "\n",
    "display(test.head())\n",
    "display(train.head())\n",
    "display(item_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b11324b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T14:16:05.856274Z",
     "iopub.status.busy": "2025-07-10T14:16:05.855992Z",
     "iopub.status.idle": "2025-07-10T14:16:05.929389Z",
     "shell.execute_reply": "2025-07-10T14:16:05.928665Z"
    },
    "papermill": {
     "duration": 1.581338,
     "end_time": "2025-07-10T14:16:05.930663",
     "exception": false,
     "start_time": "2025-07-10T14:16:04.349325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>behavior_policy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>781367.00000</td>\n",
       "      <td>781367.000000</td>\n",
       "      <td>781367.000000</td>\n",
       "      <td>781367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>440702.54989</td>\n",
       "      <td>214784.801872</td>\n",
       "      <td>1.509714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>111566.96685</td>\n",
       "      <td>127162.359285</td>\n",
       "      <td>0.644307</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>255612.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>347406.00000</td>\n",
       "      <td>104186.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>440263.00000</td>\n",
       "      <td>211988.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>533090.00000</td>\n",
       "      <td>326244.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>650957.00000</td>\n",
       "      <td>439131.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp     session_id    sequence_id  behavior_policy_id\n",
       "count  781367.00000  781367.000000  781367.000000            781367.0\n",
       "mean   440702.54989  214784.801872       1.509714                 1.0\n",
       "std    111566.96685  127162.359285       0.644307                 0.0\n",
       "min    255612.00000       1.000000       1.000000                 1.0\n",
       "25%    347406.00000  104186.000000       1.000000                 1.0\n",
       "50%    440263.00000  211988.000000       1.000000                 1.0\n",
       "75%    533090.00000  326244.500000       2.000000                 1.0\n",
       "max    650957.00000  439131.000000       4.000000                 1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2a5cd04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T14:16:08.925950Z",
     "iopub.status.busy": "2025-07-10T14:16:08.925690Z",
     "iopub.status.idle": "2025-07-10T14:16:08.932381Z",
     "shell.execute_reply": "2025-07-10T14:16:08.931662Z"
    },
    "papermill": {
     "duration": 1.553026,
     "end_time": "2025-07-10T14:16:08.933578",
     "exception": false,
     "start_time": "2025-07-10T14:16:07.380552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['train'] = train\n",
    "params['val'] = test\n",
    "params['item_meta'] = item_info\n",
    "params['n_worker'] = 4\n",
    "params['max_seq_len'] = 50\n",
    "\n",
    "params['loss_type'] = 'bce'\n",
    "params['device'] = device\n",
    "params['l2_coef'] = 0.001\n",
    "params['lr'] = 0.0003\n",
    "params['feature_dim'] = 16\n",
    "params['hidden_dims'] = [256]\n",
    "params['attn_n_head'] = 2\n",
    "params['batch_size'] = 128\n",
    "params['seed'] = 11\n",
    "params['epoch'] = 1\n",
    "params['dropout_rate'] = 0.2\n",
    "params['model_path'] = os.path.join(path_to_output, \n",
    "                          f\"env/rl4rs_user_env_lr{params['lr']}_reg{params['l2_coef']}_eval.model\")\n",
    "set_random_seed(params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bacbd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T14:16:11.870890Z",
     "iopub.status.busy": "2025-07-10T14:16:11.870620Z",
     "iopub.status.idle": "2025-07-10T14:58:55.633603Z",
     "shell.execute_reply": "2025-07-10T14:58:55.632707Z"
    },
    "papermill": {
     "duration": 2565.327651,
     "end_time": "2025-07-10T14:58:55.634764",
     "exception": false,
     "start_time": "2025-07-10T14:16:10.307113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load item meta data\n",
      "epoch 0 is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "781440it [35:47, 363.94it/s]                            \n",
      "156288it [06:56, 375.39it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 validating; auc: 0.7749\n"
     ]
    }
   ],
   "source": [
    "# @title Train user response\n",
    "reader = RL4RSDataReader(params)\n",
    "model = RL4RSUserResponse(reader, params).to(device)\n",
    "\n",
    "\n",
    "# reader = RL4RSDataReader(params)\n",
    "# model = RL4RSUserResponse(reader, params).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "model.optimizer = optimizer\n",
    "\n",
    "\n",
    "epo = 0\n",
    "while epo < params['epoch']:\n",
    "  print(f\"epoch {epo} is training\")\n",
    "  epo += 1\n",
    "\n",
    "  model.train()\n",
    "  reader.set_phase(\"train\")\n",
    "  train_loader = DataLoader(reader, params['batch_size'], shuffle = True, pin_memory = True,\n",
    "                            num_workers= params['n_worker'])\n",
    "\n",
    "  t1 = time()\n",
    "  pbar = tqdm(total=len(train_loader.dataset))\n",
    "  step_loss = []\n",
    "  for i, batch_data in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    wrapped_batch = wrap_batch(batch_data, device)\n",
    "\n",
    "    out_dict = model.do_forward_and_loss(wrapped_batch)\n",
    "    loss = out_dict['loss']\n",
    "    loss.backward()\n",
    "    step_loss.append(loss.item())\n",
    "    optimizer.step()\n",
    "    pbar.update(params['batch_size'])\n",
    "    # print(model.loss)\n",
    "    # if (i + 1) % 10 == 0:\n",
    "      # print(f\"Iteration {i + 1}, loss {np.mean(step_loss[-100:])}\")\n",
    "  pbar.close()\n",
    "    # print(\"Epoch {}; time {:.4f}\".format(epo, time() - t1))\n",
    "\n",
    "  # validation\n",
    "  t2 = time()\n",
    "  reader.set_phase(\"val\")\n",
    "  val_loader = DataLoader(reader, params['batch_size'], shuffle = False, pin_memory = False,\n",
    "                          num_workers= params['n_worker'])\n",
    "  valid_probs, valid_true =  [], []\n",
    "  pbar = tqdm(total = len(val_loader.dataset))\n",
    "  with torch.no_grad():\n",
    "    for i, batch_data in enumerate(val_loader):\n",
    "      wrapped_batch = wrap_batch(batch_data, device)\n",
    "      out_dict = model.forward(wrapped_batch)\n",
    "      valid_probs.append(out_dict['probs'].cpu().numpy())\n",
    "      valid_true.append(batch_data['feedback'].cpu().numpy())\n",
    "      pbar.update(params['batch_size'])\n",
    "  pbar.close()\n",
    "  auc = roc_auc_score(np.concatenate(valid_true), np.concatenate(valid_probs))\n",
    "  print(f\"epoch {epo} validating\" + \"; auc: {:.4f}\".format(np.mean(auc)))\n",
    "  model.save_checkpoint()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e45e5cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T14:58:58.953709Z",
     "iopub.status.busy": "2025-07-10T14:58:58.953035Z",
     "iopub.status.idle": "2025-07-10T14:59:10.472851Z",
     "shell.execute_reply": "2025-07-10T14:59:10.472115Z"
    },
    "papermill": {
     "duration": 13.229278,
     "end_time": "2025-07-10T14:59:10.474026",
     "exception": false,
     "start_time": "2025-07-10T14:58:57.244748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>exposed_items</th>\n",
       "      <th>user_feedback</th>\n",
       "      <th>user_seqfeature</th>\n",
       "      <th>user_protrait</th>\n",
       "      <th>item_feature</th>\n",
       "      <th>behavior_policy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>442720</td>\n",
       "      <td>348225</td>\n",
       "      <td>2</td>\n",
       "      <td>29,25,16,106,114,45,213,196,148</td>\n",
       "      <td>1,1,1,1,1,1,1,1,0</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458306</td>\n",
       "      <td>348226</td>\n",
       "      <td>1</td>\n",
       "      <td>5,6,36,110,61,127,172,239,199</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1352,1.3293,-0.7099...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458307</td>\n",
       "      <td>348226</td>\n",
       "      <td>2</td>\n",
       "      <td>1,4,26,107,61,79,199,164,235</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.0489,-0.3633,-0.1349,1.8061,0.4482,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476558</td>\n",
       "      <td>348227</td>\n",
       "      <td>1</td>\n",
       "      <td>26,14,4,79,113,96,235,199,172</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>0.6758,0.3057,-0.3633,-0.143,1.3991,-0.3773,-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>476559</td>\n",
       "      <td>348227</td>\n",
       "      <td>2</td>\n",
       "      <td>4,14,26,61,113,127,212,239,164</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1423,1.7014,-0.2719...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  session_id  sequence_id                    exposed_items  \\\n",
       "0     442720      348225            2  29,25,16,106,114,45,213,196,148   \n",
       "1     458306      348226            1    5,6,36,110,61,127,172,239,199   \n",
       "2     458307      348226            2     1,4,26,107,61,79,199,164,235   \n",
       "3     476558      348227            1    26,14,4,79,113,96,235,199,172   \n",
       "4     476559      348227            2   4,14,26,61,113,127,212,239,164   \n",
       "\n",
       "       user_feedback                                    user_seqfeature  \\\n",
       "0  1,1,1,1,1,1,1,1,0  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "1  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "2  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "3  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "4  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "\n",
       "                                       user_protrait  \\\n",
       "0  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "1  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "2  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "3  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "4  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "\n",
       "                                        item_feature  behavior_policy_id  \n",
       "0  1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...                   1  \n",
       "1  -0.2137,-0.7579,-0.3633,-0.1352,1.3293,-0.7099...                   1  \n",
       "2  -0.2137,-0.0489,-0.3633,-0.1349,1.8061,0.4482,...                   1  \n",
       "3  0.6758,0.3057,-0.3633,-0.143,1.3991,-0.3773,-1...                   1  \n",
       "4  -0.2137,-0.7579,-0.3633,-0.1423,1.7014,-0.2719...                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>exposed_items</th>\n",
       "      <th>user_feedback</th>\n",
       "      <th>user_seqfeature</th>\n",
       "      <th>user_protrait</th>\n",
       "      <th>item_feature</th>\n",
       "      <th>behavior_policy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>442720</td>\n",
       "      <td>348225</td>\n",
       "      <td>2</td>\n",
       "      <td>29,25,16,106,114,45,213,196,148</td>\n",
       "      <td>1,1,1,1,1,1,1,1,0</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458306</td>\n",
       "      <td>348226</td>\n",
       "      <td>1</td>\n",
       "      <td>5,6,36,110,61,127,172,239,199</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1352,1.3293,-0.7099...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458307</td>\n",
       "      <td>348226</td>\n",
       "      <td>2</td>\n",
       "      <td>1,4,26,107,61,79,199,164,235</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.0489,-0.3633,-0.1349,1.8061,0.4482,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476558</td>\n",
       "      <td>348227</td>\n",
       "      <td>1</td>\n",
       "      <td>26,14,4,79,113,96,235,199,172</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>0.6758,0.3057,-0.3633,-0.143,1.3991,-0.3773,-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>476559</td>\n",
       "      <td>348227</td>\n",
       "      <td>2</td>\n",
       "      <td>4,14,26,61,113,127,212,239,164</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1</td>\n",
       "      <td>32,28,2,77,126,127,200,199,32,25,35,130,77,127...</td>\n",
       "      <td>92265,58584,6599,16721,6344,7615,54240,11606,7...</td>\n",
       "      <td>-0.2137,-0.7579,-0.3633,-0.1423,1.7014,-0.2719...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  session_id  sequence_id                    exposed_items  \\\n",
       "0     442720      348225            2  29,25,16,106,114,45,213,196,148   \n",
       "1     458306      348226            1    5,6,36,110,61,127,172,239,199   \n",
       "2     458307      348226            2     1,4,26,107,61,79,199,164,235   \n",
       "3     476558      348227            1    26,14,4,79,113,96,235,199,172   \n",
       "4     476559      348227            2   4,14,26,61,113,127,212,239,164   \n",
       "\n",
       "       user_feedback                                    user_seqfeature  \\\n",
       "0  1,1,1,1,1,1,1,1,0  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "1  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "2  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "3  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "4  1,1,1,1,1,1,1,1,1  32,28,2,77,126,127,200,199,32,25,35,130,77,127...   \n",
       "\n",
       "                                       user_protrait  \\\n",
       "0  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "1  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "2  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "3  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "4  92265,58584,6599,16721,6344,7615,54240,11606,7...   \n",
       "\n",
       "                                        item_feature  behavior_policy_id  \n",
       "0  1.5653,-0.0489,-0.3633,-0.1337,1.7984,-0.4087,...                   1  \n",
       "1  -0.2137,-0.7579,-0.3633,-0.1352,1.3293,-0.7099...                   1  \n",
       "2  -0.2137,-0.0489,-0.3633,-0.1349,1.8061,0.4482,...                   1  \n",
       "3  0.6758,0.3057,-0.3633,-0.143,1.3991,-0.3773,-1...                   1  \n",
       "4  -0.2137,-0.7579,-0.3633,-0.1423,1.7014,-0.2719...                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(283, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Load data\n",
    "item_info = pd.read_csv(os.path.join(path_to_data, \"item_info.csv\"), sep = \" \")\n",
    "test = pd.read_csv(os.path.join(path_to_data, \"test.csv\"), sep=\"@\")\n",
    "train = pd.read_csv(os.path.join(path_to_data, \"test.csv\"), sep=\"@\")\n",
    "\n",
    "display(test.head())\n",
    "display(train.head())\n",
    "display(item_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b54444f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T14:59:13.717173Z",
     "iopub.status.busy": "2025-07-10T14:59:13.716920Z",
     "iopub.status.idle": "2025-07-10T16:12:42.095931Z",
     "shell.execute_reply": "2025-07-10T16:12:42.095073Z"
    },
    "papermill": {
     "duration": 4410.087437,
     "end_time": "2025-07-10T16:12:42.097111",
     "exception": false,
     "start_time": "2025-07-10T14:59:12.009674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250710_145913-kjuwiph3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchocolate-armadillo-79\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC/runs/kjuwiph3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load item meta data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1962072114.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(params['model_path'] + \".checkpoint\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/768539544.py:137: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.critic.load_state_dict(torch.load(self.save_path + \"_critic\", map_location=self.device))\n",
      "/tmp/ipykernel_19/768539544.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.critic_optimizer.load_state_dict(torch.load(self.save_path + \"_critic_optimizer\", map_location=self.device))\n",
      "/tmp/ipykernel_19/768539544.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.actor.load_state_dict(torch.load(self.save_path + \"_actor\", map_location=self.device))\n",
      "/tmp/ipykernel_19/768539544.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.actor_optimizer.load_state_dict(torch.load(self.save_path + \"_actor_optimizer\", map_location=self.device))\n",
      "100%|| 50000/50000 [1:13:22<00:00, 11.36it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       average_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: average_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          buffer_size \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           max_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     max_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           min_n_step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     min_total_reward \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      reward_variance \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       average_n_step 13.8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: average_total_reward 13.14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          buffer_size 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           max_n_step 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     max_total_reward 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           min_n_step 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     min_total_reward 4.28889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      reward_variance 26.44294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mchocolate-armadillo-79\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC/runs/kjuwiph3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at: \u001b[34m\u001b[4mhttps://wandb.ai/23020082-uet/HAC\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250710_145913-kjuwiph3/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "params['n_worker'] = 4\n",
    "params['max_seq_len'] = 50\n",
    "\n",
    "params['loss_type'] = 'bce'\n",
    "params['device'] = device\n",
    "params['l2_coef'] = 0.001\n",
    "params['lr'] = 0.0003\n",
    "params['feature_dim'] = 16\n",
    "params['hidden_dims'] = [256]\n",
    "params['attn_n_head'] = 2\n",
    "params['batch_size'] = 128\n",
    "params['epoch'] = 2\n",
    "params['dropout_rate'] = 0.2\n",
    "params['max_step'] = 20\n",
    "params['initial_temper'] = 20\n",
    "params['reward_function'] = mean_with_cost\n",
    "params['sasrec_n_layer'] = 2\n",
    "params['sasrec_d_model'] = 32\n",
    "params['sasrec_n_head'] = 4\n",
    "params['sasrec_dropout'] = 0.1\n",
    "params['sasrec_d_forward'] = 64\n",
    "params['critic_hidden_dims'] = [256, 64]\n",
    "params['critic_dropout_rate'] = 0.2\n",
    "params['n_iter']= [50000]\n",
    "params['slate_size'] = 9\n",
    "params['noise_var'] = 0.1\n",
    "params['q_laplace_smoothness'] = 0.5\n",
    "params['topk_rate'] = 1\n",
    "params['empty_start_rate'] = 0\n",
    "params['buffer_size'] = 100000\n",
    "params['start_timestamp'] = 2000\n",
    "params['gamma'] = 0.9\n",
    "params['train_every_n_step']= 1\n",
    "params['initial_greedy_epsilon'] = 0\n",
    "params['final_greedy_epsilon'] = 0\n",
    "params['elbow_greedy'] = 0.1\n",
    "params['check_episode'] = 10\n",
    "params['with_eval'] = False\n",
    "\n",
    "params['episode_batch_size'] = 32\n",
    "params['batch_size'] = 64\n",
    "params['actor_lr'] = 0.00001\n",
    "params['critic_lr'] = 0.001\n",
    "params['actor_decay'] = 0.00001\n",
    "params['critic_decay'] = 0.00001\n",
    "params['target_mitigate_coef'] = 0.01\n",
    "params['behavior_lr'] = 0.00005\n",
    "params['behavior_decay'] = 0.00001\n",
    "params['hyper_actor_coef'] = 0.1\n",
    "params['advantage_bias'] = 0\n",
    "params['entropy_coef'] = 0.0001\n",
    "\n",
    "config = params.copy()\n",
    "config.pop(\"train\", None)\n",
    "config.pop(\"val\", None)\n",
    "config.pop(\"item_meta\", None)\n",
    "config.pop(\"user_meta\", None)\n",
    "\n",
    "for seed in [9]:\n",
    "    run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"23020082-uet\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"HAC\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config=config\n",
    "    )\n",
    "    params['seed'] = seed\n",
    "    set_random_seed(params['seed'])\n",
    "    params['save_path'] = os.path.join(path_to_output, f\"agent/rl4rs_model_seed{params['seed']}\")\n",
    "    os.makedirs(os.path.dirname(params['save_path']), exist_ok=True)\n",
    "    \n",
    "    env = RL4RSEnvironment(params)\n",
    "    \n",
    "    policy = SASRec(env, params)\n",
    "    policy.to(device)\n",
    "    \n",
    "    \n",
    "    critic = GeneralCritic(policy, params)\n",
    "    critic.to(device)\n",
    "    \n",
    "    facade = OneStageFacade_HyperAction(env, policy, critic, params)\n",
    "    \n",
    "    agent = HAC(facade, params)\n",
    "    \n",
    "    agent.test()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76715db0",
   "metadata": {
    "id": "JhQPZR_yXqHk",
    "outputId": "cce3f497-89a7-415f-da30-173f195aa5ae",
    "papermill": {
     "duration": 2.518043,
     "end_time": "2025-07-10T16:12:47.240596",
     "exception": false,
     "start_time": "2025-07-10T16:12:44.722553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6da2f325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T16:12:52.369912Z",
     "iopub.status.busy": "2025-07-10T16:12:52.369546Z",
     "iopub.status.idle": "2025-07-10T16:12:52.374637Z",
     "shell.execute_reply": "2025-07-10T16:12:52.373870Z"
    },
    "papermill": {
     "duration": 2.636113,
     "end_time": "2025-07-10T16:12:52.375859",
     "exception": false,
     "start_time": "2025-07-10T16:12:49.739746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # @title Test with environment from Eval User respond\n",
    "# params['seed'] = 12\n",
    "# params['save_path'] = os.path.join(path_to_output, f\"agent/model_seed{params['seed']}\")\n",
    "# env = KREnvironment(params)\n",
    "\n",
    "# policy = SASRec(env, params)\n",
    "# policy.to(device)\n",
    "\n",
    "\n",
    "# critic = GeneralCritic(policy, params)\n",
    "# critic.to(device)\n",
    "\n",
    "# facade = OneStageFacade_HyperAction(env, policy, critic, params)\n",
    "\n",
    "# agent = HAC(facade, params)\n",
    "\n",
    "# agent.test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7180976,
     "sourceId": 11467375,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 300659,
     "modelInstanceId": 279738,
     "sourceId": 334090,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16489.185633,
   "end_time": "2025-07-10T16:12:58.252870",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-10T11:38:09.067237",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
